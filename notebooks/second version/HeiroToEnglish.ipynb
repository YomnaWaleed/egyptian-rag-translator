{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42ed64e5fa4947e7b897d296ce226bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f41c76787e4027a1ea0c3780fdf725",
              "IPY_MODEL_5bd13a48d41346fab763940a55a0dfd2",
              "IPY_MODEL_bde1b709c5464784b5f00772455b0be4"
            ],
            "layout": "IPY_MODEL_722a083dbc6d47568dd88736fb54595c"
          }
        },
        "c6f41c76787e4027a1ea0c3780fdf725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4cd6f15b34d433abebf1d50e0294aee",
            "placeholder": "​",
            "style": "IPY_MODEL_b6805fbc08294099b830ab7d2b7d3609",
            "value": "Generating embeddings: 100%"
          }
        },
        "5bd13a48d41346fab763940a55a0dfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7faa8b74b564e159a5828f6a2adce3c",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_283ce8c3331249c09cbd18c50bc6c185",
            "value": 282
          }
        },
        "bde1b709c5464784b5f00772455b0be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b40d1ddd71a4dd7a59ccaf3948f371d",
            "placeholder": "​",
            "style": "IPY_MODEL_a6d7106fbf4243e38913d4c9e30da421",
            "value": " 282/282 [02:00&lt;00:00,  2.55it/s]"
          }
        },
        "722a083dbc6d47568dd88736fb54595c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cd6f15b34d433abebf1d50e0294aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6805fbc08294099b830ab7d2b7d3609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7faa8b74b564e159a5828f6a2adce3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283ce8c3331249c09cbd18c50bc6c185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b40d1ddd71a4dd7a59ccaf3948f371d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d7106fbf4243e38913d4c9e30da421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7216cd5fae6e4d768b8f071ec1c25b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c009d46d4dd14113ba46e2ab6df0f22a",
              "IPY_MODEL_ce4f618a91f647ac99be8d437b797c4f",
              "IPY_MODEL_a9a8f14b1744404c83ad325a23fb754f"
            ],
            "layout": "IPY_MODEL_446b74318c4a4adc82198a377e905fa5"
          }
        },
        "c009d46d4dd14113ba46e2ab6df0f22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa92cdc49bd347149f893363e94a75c7",
            "placeholder": "​",
            "style": "IPY_MODEL_73badaa2cf61418bbbc4bb5bdb0a9526",
            "value": "Preparing points: 100%"
          }
        },
        "ce4f618a91f647ac99be8d437b797c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd4a8a346f14e7fb8abde63715395c4",
            "max": 8997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9c2f36cfb514423b4a159d13f8e9312",
            "value": 8997
          }
        },
        "a9a8f14b1744404c83ad325a23fb754f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f37bc16b4b364d358c068e24c1512e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_cc47f023ce44468c97a72769f081b0d4",
            "value": " 8997/8997 [00:01&lt;00:00, 8637.21it/s]"
          }
        },
        "446b74318c4a4adc82198a377e905fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa92cdc49bd347149f893363e94a75c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73badaa2cf61418bbbc4bb5bdb0a9526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cd4a8a346f14e7fb8abde63715395c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c2f36cfb514423b4a159d13f8e9312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f37bc16b4b364d358c068e24c1512e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc47f023ce44468c97a72769f081b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be96d8795cd422db61efdd84fc2fdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_059994550c2a49d38af469798f208416",
              "IPY_MODEL_d55a3d02c9c04c87b02593390e86f05e",
              "IPY_MODEL_667b9372f0694cf780283b6c5bb9be50"
            ],
            "layout": "IPY_MODEL_aaac75a5b1c24feda77205f0c49b6ccf"
          }
        },
        "059994550c2a49d38af469798f208416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e178421dcae454396d03a7f7ba8f1a9",
            "placeholder": "​",
            "style": "IPY_MODEL_78c2337aab0b4b0cb4c2573a32f29494",
            "value": "Uploading batches: 100%"
          }
        },
        "d55a3d02c9c04c87b02593390e86f05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6386f8a676d84c7b871dd38a75e40112",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fcf926a6ced4320a8fd9cd2d30a616b",
            "value": 90
          }
        },
        "667b9372f0694cf780283b6c5bb9be50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6c760628344d6087c40e630e699cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_579099cc53f345c889b662c402846894",
            "value": " 90/90 [01:03&lt;00:00,  1.32it/s]"
          }
        },
        "aaac75a5b1c24feda77205f0c49b6ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e178421dcae454396d03a7f7ba8f1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c2337aab0b4b0cb4c2573a32f29494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6386f8a676d84c7b871dd38a75e40112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fcf926a6ced4320a8fd9cd2d30a616b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b6c760628344d6087c40e630e699cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579099cc53f345c889b662c402846894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f2a80b2760942b285c45c11a53e7570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5525fa234ecc41fea6be00d4356d332c",
              "IPY_MODEL_a5a26da884ac40fabb6c494e76ce852b",
              "IPY_MODEL_baeb4497d5114da3a450404f057ad6ce"
            ],
            "layout": "IPY_MODEL_6888a4ebc9754312974e8b4e3a30319f"
          }
        },
        "5525fa234ecc41fea6be00d4356d332c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaee7f5d2d3d45d2a7705e6816f00b75",
            "placeholder": "​",
            "style": "IPY_MODEL_9381aeb2923247f28bee4542e75e5037",
            "value": "Translating: 100%"
          }
        },
        "a5a26da884ac40fabb6c494e76ce852b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a623991c5b74a239580be2ce050240b",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee2f03e9e17948f598b38ce81b21f778",
            "value": 10
          }
        },
        "baeb4497d5114da3a450404f057ad6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a880618972b8418f90624c47297aaaab",
            "placeholder": "​",
            "style": "IPY_MODEL_bef7b7b21c054670b5662ded63ffa53f",
            "value": " 10/10 [02:34&lt;00:00, 14.42s/it]"
          }
        },
        "6888a4ebc9754312974e8b4e3a30319f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaee7f5d2d3d45d2a7705e6816f00b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9381aeb2923247f28bee4542e75e5037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a623991c5b74a239580be2ce050240b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2f03e9e17948f598b38ce81b21f778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a880618972b8418f90624c47297aaaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef7b7b21c054670b5662ded63ffa53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aaf464ca4a844c489eeb16164b917c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53df6c7e59ba474d812bedab4d8f5eaf",
              "IPY_MODEL_95eab9f963d44e0dbf4e37368e0ef7f0",
              "IPY_MODEL_fbffbd5b50144eea996afbb0e53c4cef"
            ],
            "layout": "IPY_MODEL_b97ee139f3c1459690ba5059236193a5"
          }
        },
        "53df6c7e59ba474d812bedab4d8f5eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd514239b774cc6bcf6bd309c13dba1",
            "placeholder": "​",
            "style": "IPY_MODEL_340e476832bb403d8fb2fc9c3f8cf59c",
            "value": "RAG Translation: 100%"
          }
        },
        "95eab9f963d44e0dbf4e37368e0ef7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013d3780cf11429fb82c8cc521133abc",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f6081fcc654bac81dc29aaed0c2f3c",
            "value": 25
          }
        },
        "fbffbd5b50144eea996afbb0e53c4cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa5b22b1e7d4449b7580b530a533a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_978cefc8b3db43738981161bf3a212fd",
            "value": " 25/25 [02:09&lt;00:00,  4.11s/it]"
          }
        },
        "b97ee139f3c1459690ba5059236193a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd514239b774cc6bcf6bd309c13dba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340e476832bb403d8fb2fc9c3f8cf59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "013d3780cf11429fb82c8cc521133abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f6081fcc654bac81dc29aaed0c2f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa5b22b1e7d4449b7580b530a533a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978cefc8b3db43738981161bf3a212fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff83f943d10b4b019409f34ff40373b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d91e8dfa39f420cbc4223df32369d18",
              "IPY_MODEL_80c9d6af823747059491dac9b0cdddc5",
              "IPY_MODEL_84e41a3499664d3988df18a7344a3823"
            ],
            "layout": "IPY_MODEL_31992ad1a9874314a5c363949dfa7740"
          }
        },
        "0d91e8dfa39f420cbc4223df32369d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95be3833e232409988a1b057d39b9146",
            "placeholder": "​",
            "style": "IPY_MODEL_c700919ea6ae42e3bde5b806cfe295e2",
            "value": "Computing all metrics: 100%"
          }
        },
        "80c9d6af823747059491dac9b0cdddc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e931f8984b4a269b271566d5559425",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e4c5111ea784c04b210907f2d34759e",
            "value": 25
          }
        },
        "84e41a3499664d3988df18a7344a3823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51224411c1b14a2085f3f94d64f5c5e4",
            "placeholder": "​",
            "style": "IPY_MODEL_d7beb56fe50248b19dbf7afc5ed0279d",
            "value": " 25/25 [00:00&lt;00:00, 409.30it/s]"
          }
        },
        "31992ad1a9874314a5c363949dfa7740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95be3833e232409988a1b057d39b9146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c700919ea6ae42e3bde5b806cfe295e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e931f8984b4a269b271566d5559425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4c5111ea784c04b210907f2d34759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51224411c1b14a2085f3f94d64f5c5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7beb56fe50248b19dbf7afc5ed0279d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39aff42a1e1b4f21a37cba5381de92eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f92bb13c75fc473dbd41ff1b1f7f2bac",
              "IPY_MODEL_5ca2533e339041a096a45f927f30527e",
              "IPY_MODEL_2ae4fe4f0b7c4f298af39b92ebe4dd2a"
            ],
            "layout": "IPY_MODEL_b880c832f55a461dbd8a7ecd33695f2f"
          }
        },
        "f92bb13c75fc473dbd41ff1b1f7f2bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c594116772a84ab1b083a34374500352",
            "placeholder": "​",
            "style": "IPY_MODEL_7ec9f0ee155e4347b9d962a679017ecc",
            "value": "LLM-only translation: 100%"
          }
        },
        "5ca2533e339041a096a45f927f30527e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374710c89c4948989e8b423fbc776240",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c64358084cb43d3b47114d39f1b7d3e",
            "value": 25
          }
        },
        "2ae4fe4f0b7c4f298af39b92ebe4dd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_785c3d5263774df591c46a2ea95c8334",
            "placeholder": "​",
            "style": "IPY_MODEL_1bca6ba1c2594d2faf94995da066e63d",
            "value": " 25/25 [01:00&lt;00:00,  2.07s/it]"
          }
        },
        "b880c832f55a461dbd8a7ecd33695f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c594116772a84ab1b083a34374500352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec9f0ee155e4347b9d962a679017ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374710c89c4948989e8b423fbc776240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c64358084cb43d3b47114d39f1b7d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "785c3d5263774df591c46a2ea95c8334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bca6ba1c2594d2faf94995da066e63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fd8ef9932b54a1a9f16282facfc14c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce50e51071a64943905f6dfceb3a82c6",
              "IPY_MODEL_4fcd51d78d904125bf2ca1afa42249eb",
              "IPY_MODEL_74483e11128b403fb172b3e70282a4f7"
            ],
            "layout": "IPY_MODEL_7dab95e55cd647b6a6d35bfd06db097d"
          }
        },
        "ce50e51071a64943905f6dfceb3a82c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfdf71a8bd7a4dd6bda3c8699c9b009b",
            "placeholder": "​",
            "style": "IPY_MODEL_17dc8c86cf494479b25a71f5dd8a0d77",
            "value": "Computing LLM-only metrics: 100%"
          }
        },
        "4fcd51d78d904125bf2ca1afa42249eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b417d5533f7846fda6d8a29c4382394a",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26bd0886a44e4e80a0900d9bebe7ca38",
            "value": 25
          }
        },
        "74483e11128b403fb172b3e70282a4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffc220c5e0d43c28f92f9e6daa129c4",
            "placeholder": "​",
            "style": "IPY_MODEL_a347de97d2e846139e30031fd908f51e",
            "value": " 25/25 [00:00&lt;00:00, 421.39it/s]"
          }
        },
        "7dab95e55cd647b6a6d35bfd06db097d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfdf71a8bd7a4dd6bda3c8699c9b009b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dc8c86cf494479b25a71f5dd8a0d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b417d5533f7846fda6d8a29c4382394a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bd0886a44e4e80a0900d9bebe7ca38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ffc220c5e0d43c28f92f9e6daa129c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a347de97d2e846139e30031fd908f51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🏛️ TLA Dataset Preparation for Egyptian Transliteration RAG System\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 1: Install & Import Libraries"
      ],
      "metadata": {
        "id": "G8IS7D22A4pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Upgrade pip first\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# 🔹 Core Dependencies\n",
        "!pip install datasets>=2.18.0 --quiet\n",
        "!pip install transformers>=4.38.0 --quiet\n",
        "!pip install torch>=2.2.0 --quiet\n",
        "!pip install pandas>=2.2.0 --quiet\n",
        "!pip install numpy>=1.26.0 --quiet\n",
        "\n",
        "# 🔹 Translation\n",
        "!pip install sentencepiece>=0.2.0 --quiet\n",
        "\n",
        "# 🔹 Vector Database\n",
        "!pip install qdrant-client>=1.7.0 --quiet\n",
        "\n",
        "# 🔹 Ollama Cloud API\n",
        "!pip install httpx>=0.25.2,<0.26.0 --quiet\n",
        "!pip install ollama>=0.1.7 --quiet\n",
        "\n",
        "# 🔹 BM25 for Hybrid Search\n",
        "!pip install rank-bm25>=0.2.2 --quiet\n",
        "\n",
        "# 🔹 Utilities\n",
        "!pip install tqdm>=4.66.0 --quiet\n",
        "!pip install python-dotenv>=1.0.0 --quiet\n",
        "!pip install jupyter>=1.0.0 --quiet\n",
        "!pip install ipywidgets>=8.1.0 --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install matplotlib --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install nltk==3.9.2 --quiet\n",
        "!pip install rouge-score==0.1.2 --quiet\n",
        "!pip install sacrebleu==2.6.0 --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQ2QDe-BFUS",
        "outputId": "f805bd15-e851-4b96-9111-22197a68d0e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 0.26.0: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic6N9oFNBnES",
        "outputId": "34449984-d422-4a78-edfb-b96914ed2e63"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGQENGBIAMmK",
        "outputId": "1e6bca00-979d-489c-803c-1ac990cd9c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
        "import subprocess\n",
        "import json\n",
        "import ollama\n",
        "\n",
        "print(\"✅ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## configuration\n",
        "# Models\n",
        "EMBEDDING_MODEL = \"bge-m3:latest\"  # Ollama local\n",
        "\n",
        "# Settings\n",
        "VECTOR_DIM = 1024\n",
        "TRAIN_SPLIT = 0.99  # 95% for training, 5% for testing\n",
        "\n",
        "# Egyptian character mapping (uniliteral signs)\n",
        "EGYPTIAN_CHAR_MAP = {\n",
        "    # Traditional → Normalized\n",
        "    'ꜣ': 'a',      # vulture (aleph)\n",
        "    'ꞽ': 'i',      # reed (yodh)\n",
        "    'y': 'y',      # double yodh\n",
        "    'ꜥ': 'a',      # arm (ayin)\n",
        "    'w': 'w',      # quail\n",
        "    'b': 'b',      # leg\n",
        "    'p': 'p',      # stool\n",
        "    'f': 'f',      # viper\n",
        "    'm': 'm',      # owl\n",
        "    'n': 'n',      # water\n",
        "    'r': 'r',      # mouth\n",
        "    'h': 'h',      # shelter\n",
        "    'ḥ': 'h',      # wick\n",
        "    'ḫ': 'kh',     # placenta\n",
        "    'ẖ': 'kh',     # belly\n",
        "    's': 's',      # cloth\n",
        "    'š': 'sh',     # pool\n",
        "    'ḳ': 'q',      # hill\n",
        "    'q': 'q',      # hill\n",
        "    'k': 'k',      # basket\n",
        "    'g': 'g',      # stand\n",
        "    't': 't',      # bun\n",
        "    'ṯ': 'tj',     # rope\n",
        "    'd': 'd',      # hand\n",
        "    'ḏ': 'dj',     # cobra\n",
        "\n",
        "    # Additional special characters\n",
        "    'ṭ': 't',\n",
        "    'ḍ': 'd',\n",
        "    'ṣ': 's',\n",
        "    'ẓ': 'z',\n",
        "    'ḥ': 'h',\n",
        "}\n",
        "\n",
        "# Suffixes to remove (pronouns and particles)\n",
        "SUFFIXES_TO_REMOVE = [\n",
        "    '=f',   # his/him\n",
        "    '=k',   # your/you (masc)\n",
        "    '=ṯ',   # your/you (fem)\n",
        "    '=s',   # her/it\n",
        "    '=sn',  # their/them\n",
        "    '=ꞽ',   # my/me\n",
        "    '=n',   # our/us\n",
        "    '=tn',  # your/you (pl)\n",
        "    '=fꞽ',  # variant\n",
        "]\n",
        "\n",
        "print(f\"🔧 Configuration loaded\")\n",
        "print(f\"   Training split: {TRAIN_SPLIT*100}%\")\n",
        "print(f\"   Embedding model: {EMBEDDING_MODEL}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4dDTE0dAyUy",
        "outputId": "6e78e825-160a-4b23-d8c4-4fabdad47d05"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Configuration loaded\n",
            "   Training split: 99.0%\n",
            "   Embedding model: bge-m3:latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 3: Load dataset\n",
        "print(\"📥 Loading TLA dataset from HuggingFace...\")\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(f\"✅ Loaded {len(df)} records\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nSample record:\")\n",
        "print(df.iloc[0][['transliteration', 'translation', 'UPOS']].to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGgDrQdBuND",
        "outputId": "93c7908b-4731-4c70-fefa-1f1538218579"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading TLA dataset from HuggingFace...\n",
            "✅ Loaded 12773 records\n",
            "\n",
            "Columns: ['hieroglyphs', 'transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'dateNotBefore', 'dateNotAfter']\n",
            "\n",
            "Sample record:\n",
            "{'transliteration': 'nḏ (w)di̯ r =s', 'translation': '(es) werde zerrieben, (es) werde darauf gelegt.', 'UPOS': 'VERB VERB ADP PRON'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 4 : Data Cleaning\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🧹 STEP 1: Removing unwanted columns\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Remove unwanted columns\n",
        "columns_to_drop = ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
        "df_clean = df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(f\"✅ Removed columns: {columns_to_drop}\")\n",
        "print(f\"   Remaining columns: {list(df_clean.columns)}\")\n",
        "\n",
        "# Remove rows with missing critical data\n",
        "print(\"\\n🧹 STEP 2: Removing rows with missing data\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.dropna(subset=['transliteration', 'translation'])\n",
        "df_clean = df_clean[df_clean['transliteration'].str.strip() != '']\n",
        "df_clean = df_clean[df_clean['translation'].str.strip() != '']\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} rows with missing data\")\n",
        "print(f\"   Records remaining: {len(df_clean)}\")\n",
        "\n",
        "# Remove duplicates\n",
        "print(\"\\n🧹 STEP 3: Removing duplicates\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.drop_duplicates(subset=['transliteration'], keep='first')\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} duplicate records\")\n",
        "print(f\"   Unique records: {len(df_clean)}\")\n",
        "\n",
        "df_clean = df_clean.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkwYUNi4BwPK",
        "outputId": "486f51bb-aba9-4cae-d9e0-c90ed71cdeb6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🧹 STEP 1: Removing unwanted columns\n",
            "======================================================================\n",
            "✅ Removed columns: ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
            "   Remaining columns: ['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation']\n",
            "\n",
            "🧹 STEP 2: Removing rows with missing data\n",
            "✅ Removed 0 rows with missing data\n",
            "   Records remaining: 12773\n",
            "\n",
            "🧹 STEP 3: Removing duplicates\n",
            "✅ Removed 3685 duplicate records\n",
            "   Unique records: 9088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 5: Transliteration Normalization\n",
        "def normalize_transliteration(text):\n",
        "    \"\"\"\n",
        "    Normalize Egyptian transliteration:\n",
        "    1. Remove brackets\n",
        "    2. Lowercase\n",
        "    3. Map special characters\n",
        "    4. Remove suffixes\n",
        "    5. Clean spaces\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == '':\n",
        "        return \"\"\n",
        "\n",
        "    # Step 1: Remove brackets (but keep content)\n",
        "    text = re.sub(r'[()]', '', text)\n",
        "\n",
        "    # Step 2: Normalize Unicode (NFC form)\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "    # REMOVE combining marks (important for di̯, etc.)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "\n",
        "    # Step 3: Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Step 4: Map Egyptian characters\n",
        "    for egy_char, normalized in EGYPTIAN_CHAR_MAP.items():\n",
        "        text = text.replace(egy_char.lower(), normalized)\n",
        "\n",
        "    # Step 5: Remove suffixes (pronouns/particles)\n",
        "    for suffix in SUFFIXES_TO_REMOVE:\n",
        "        # Match suffix at word boundaries or before spaces/dots\n",
        "        pattern = re.escape(suffix) + r'(?=[\\s\\.]|$)'\n",
        "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Step 6: Clean up extra spaces and dots\n",
        "    text = re.sub(r'\\.+', '.', text)  # Multiple dots to single\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces to single\n",
        "    text = text.strip('. ')  # Remove leading/trailing dots and spaces\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔤 STEP 4: Normalizing transliterations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test normalization on sample\n",
        "sample_text = df_clean.iloc[0]['transliteration']\n",
        "normalized_sample = normalize_transliteration(sample_text)\n",
        "\n",
        "print(f\"\\n📝 Sample normalization:\")\n",
        "print(f\"   Original:   {sample_text}\")\n",
        "print(f\"   Normalized: {normalized_sample}\")\n",
        "\n",
        "# Apply normalization to entire dataset\n",
        "print(f\"\\n🔄 Normalizing {len(df_clean)} transliterations...\")\n",
        "\n",
        "df_clean['transliteration_normalized'] = df_clean['transliteration'].apply(\n",
        "    normalize_transliteration\n",
        ")\n",
        "\n",
        "\n",
        "# Remove empty normalizations\n",
        "df_clean = df_clean[df_clean['transliteration_normalized'].str.len() > 0]\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Normalization complete!\")\n",
        "print(f\"   Valid records: {len(df_clean)}\")\n",
        "\n",
        "# Show more examples\n",
        "print(f\"\\n📋 Sample normalizations:\")\n",
        "for i in range(min(5, len(df_clean))):\n",
        "    orig = df_clean.iloc[i]['transliteration']\n",
        "    norm = df_clean.iloc[i]['transliteration_normalized']\n",
        "    print(f\"   {i+1}. {orig[:40]:40} → {norm[:40]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXrqavRoCKQ7",
        "outputId": "10dbb3dc-6fa1-4237-c4cb-3c95a0e02b1e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🔤 STEP 4: Normalizing transliterations\n",
            "======================================================================\n",
            "\n",
            "📝 Sample normalization:\n",
            "   Original:   nḏ (w)di̯ r =s\n",
            "   Normalized: ndj wdi r\n",
            "\n",
            "🔄 Normalizing 9088 transliterations...\n",
            "✅ Normalization complete!\n",
            "   Valid records: 9088\n",
            "\n",
            "📋 Sample normalizations:\n",
            "   1. nḏ (w)di̯ r =s                           → ndj wdi r\n",
            "   2. n ṯw ꞽm =sn                              → n tjw im\n",
            "   3. ḫꜣ m tʾ ḥnq.t kꜣ(.PL) ꜣpd(.PL) n ꞽmꜣḫ ꞽm → kha m ta hnq.t ka.pl apd.pl n imakh im.i\n",
            "   4. ꜥḥꜥ                                      → ꜥhꜥ\n",
            "   5. (w)sꞽr wnꞽs m n =k ꞽr.t-ḥr.w ꞽꜥb n =k s( → wsir wnis m n ir.t-hr.w iꜥb n si ir ra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 6: Train/ test split\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"📊 STEP 5: Creating train/test split ({TRAIN_SPLIT*100}%/{(1-TRAIN_SPLIT)*100}%)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Shuffle dataset\n",
        "df_clean = df_clean.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split\n",
        "split_idx = int(len(df_clean) * TRAIN_SPLIT)\n",
        "df_train = df_clean.iloc[:split_idx].copy()\n",
        "df_test = df_clean.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"✅ Split complete!\")\n",
        "print(f\"   Training set: {len(df_train)} records ({len(df_train)/len(df_clean)*100:.1f}%)\")\n",
        "print(f\"   Test set:     {len(df_test)} records ({len(df_test)/len(df_clean)*100:.1f}%)\")\n",
        "\n",
        "# Save test set for later evaluation\n",
        "df_test.to_csv('tla_test_set.csv', index=False)\n",
        "print(f\"\\n💾 Test set saved to: tla_test_set.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axmvNF_5CQqq",
        "outputId": "306a65c1-b515-4ee0-8620-b272ebb965a5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 STEP 5: Creating train/test split (99.0%/1.0000000000000009%)\n",
            "======================================================================\n",
            "✅ Split complete!\n",
            "   Training set: 8997 records (99.0%)\n",
            "   Test set:     91 records (1.0%)\n",
            "\n",
            "💾 Test set saved to: tla_test_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 7: Generate Embedding\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"\\n📥 Loading embedding model...\")\n",
        "# Load model (do this ONCE before the loop)\n",
        "embedding_model = SentenceTransformer('BAAI/bge-m3')\n",
        "print(f\"✅ Model loaded: BAAI/bge-m3\")\n",
        "\n",
        "def get_embedding_fast(text):\n",
        "    \"\"\"Generate embedding using sentence-transformers\"\"\"\n",
        "    try:\n",
        "        # Generate embedding\n",
        "        embedding = embedding_model.encode(text, normalize_embeddings=True)\n",
        "        return embedding.tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return np.random.randn(VECTOR_DIM).tolist()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"🔢 STEP 6: Generating embeddings for {len(df_train)} records\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n⚙️ Using model: BAAI/bge-m3\")\n",
        "print(f\"   Vector dimension: {VECTOR_DIM}\")\n",
        "\n",
        "# Generate embeddings in batches (MUCH faster!)\n",
        "batch_size = 32\n",
        "all_embeddings = []\n",
        "\n",
        "for i in tqdm(range(0, len(df_train), batch_size), desc=\"Generating embeddings\"):\n",
        "    batch_end = min(i + batch_size, len(df_train))\n",
        "    batch_texts = df_train.iloc[i:batch_end]['transliteration_normalized'].tolist()\n",
        "\n",
        "    try:\n",
        "        # Process entire batch at once (FAST!)\n",
        "        batch_embeddings = embedding_model.encode(\n",
        "            batch_texts,\n",
        "            normalize_embeddings=True,\n",
        "            show_progress_bar=False\n",
        "        )\n",
        "        all_embeddings.extend(batch_embeddings.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Batch error at {i}: {e}\")\n",
        "        # Fallback: process individually\n",
        "        for text in batch_texts:\n",
        "            all_embeddings.append(get_embedding_fast(text))\n",
        "\n",
        "df_train['embedding'] = all_embeddings\n",
        "\n",
        "print(f\"\\n✅ Embedding generation complete!\")\n",
        "print(f\"   Total: {len(all_embeddings)} embeddings\")\n",
        "print(f\"   Dimension: {len(all_embeddings[0])}\")\n",
        "\n",
        "# Verify\n",
        "sample_embedding = all_embeddings[0]\n",
        "print(f\"\\n📊 Sample embedding (first 10 values):\")\n",
        "print(f\"   {sample_embedding[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "42ed64e5fa4947e7b897d296ce226bd7",
            "c6f41c76787e4027a1ea0c3780fdf725",
            "5bd13a48d41346fab763940a55a0dfd2",
            "bde1b709c5464784b5f00772455b0be4",
            "722a083dbc6d47568dd88736fb54595c",
            "c4cd6f15b34d433abebf1d50e0294aee",
            "b6805fbc08294099b830ab7d2b7d3609",
            "b7faa8b74b564e159a5828f6a2adce3c",
            "283ce8c3331249c09cbd18c50bc6c185",
            "2b40d1ddd71a4dd7a59ccaf3948f371d",
            "a6d7106fbf4243e38913d4c9e30da421"
          ]
        },
        "id": "GxC1-gvOCXVI",
        "outputId": "a5e26dd1-5f69-45f2-c850-84e4ecfc550e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📥 Loading embedding model...\n",
            "✅ Model loaded: BAAI/bge-m3\n",
            "\n",
            "======================================================================\n",
            "🔢 STEP 6: Generating embeddings for 8997 records\n",
            "======================================================================\n",
            "\n",
            "⚙️ Using model: BAAI/bge-m3\n",
            "   Vector dimension: 1024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42ed64e5fa4947e7b897d296ce226bd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Embedding generation complete!\n",
            "   Total: 8997 embeddings\n",
            "   Dimension: 1024\n",
            "\n",
            "📊 Sample embedding (first 10 values):\n",
            "   [0.009475680999457836, 0.012296928092837334, -0.03066054731607437, 0.0029091022443026304, -0.038571588695049286, -0.0011071120388805866, -0.002732239430770278, -0.013377217575907707, 0.02956884168088436, -0.00481629790738225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 8: Exract Lemmas from Lemmettizaton\n",
        "\n",
        "def extract_lemmas(lemmatization_text):\n",
        "    \"\"\"Extract lemma words from lemmatization field\"\"\"\n",
        "    if not isinstance(lemmatization_text, str):\n",
        "        return []\n",
        "\n",
        "    lemmas = []\n",
        "    parts = lemmatization_text.split()\n",
        "\n",
        "    for part in parts:\n",
        "        if '|' in part:\n",
        "            lemma_id, lemma_word = part.split('|', 1)\n",
        "            # Skip suffixes/particles\n",
        "            if not lemma_word.startswith('='):\n",
        "                lemmas.append(lemma_word)\n",
        "\n",
        "    return lemmas\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📝 STEP 7: Extracting lemmas\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_train['lemmas'] = df_train['lemmatization'].apply(extract_lemmas)\n",
        "\n",
        "print(f\"✅ Lemma extraction complete!\")\n",
        "print(f\"\\n📋 Sample lemmas:\")\n",
        "for i in range(min(3, len(df_train))):\n",
        "    lemmas = df_train.iloc[i]['lemmas']\n",
        "    print(f\"   {i+1}. {lemmas[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_10wqplYVZzG",
        "outputId": "fa78b628-a1ba-416f-8719-18e304fe3b40"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📝 STEP 7: Extracting lemmas\n",
            "======================================================================\n",
            "✅ Lemma extraction complete!\n",
            "\n",
            "📋 Sample lemmas:\n",
            "   1. ['ḥm-nṯr-Ḫwi̯=f-wꞽ', 'ḥr.ꞽ-sštꜣ']\n",
            "   2. ['zꜣ', 'sms.w', 'ꞽm.ꞽ-rʾ-zẖꜣ.ww-ꜥ-n-nswt', 'Sšm-nfr']\n",
            "   3. ['zbi̯', 'ṯw', 'm', 'ꜥḥꜥ.w', 'nfr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 9: Setup Qdrant Vector Database\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Setting up Qdrant database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize Qdrant (in-memory for development)\n",
        "# For production, use: QdrantClient(host=\"localhost\", port=6333)\n",
        "qdrant = QdrantClient(path=\"qdrant_db\")\n",
        "\n",
        "print(f\"✅ Qdrant client initialized (in-memory)\")\n",
        "\n",
        "# Create collection\n",
        "collection_name = \"egyptian_transliterations\"\n",
        "\n",
        "qdrant.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(\n",
        "        size=VECTOR_DIM,\n",
        "        distance=Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"✅ Collection created: {collection_name}\")\n",
        "print(f\"   Vector size: {VECTOR_DIM}\")\n",
        "print(f\"   Distance metric: COSINE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UG3AUbNCdQf",
        "outputId": "948f9e1c-dfc1-4180-e152-b236738355cd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Setting up Qdrant database\n",
            "======================================================================\n",
            "✅ Qdrant client initialized (in-memory)\n",
            "✅ Collection created: egyptian_transliterations\n",
            "   Vector size: 1024\n",
            "   Distance metric: COSINE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 10: upload data to qdrant\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\" Uploading {len(df_train)} records to Qdrant\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare points\n",
        "points = []\n",
        "\n",
        "for idx, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Preparing points\"):\n",
        "    point = PointStruct(\n",
        "        id=idx,\n",
        "        vector=row['embedding'],\n",
        "        payload={\n",
        "            \"transliteration_original\": row['transliteration'],\n",
        "            \"transliteration_normalized\": row['transliteration_normalized'],\n",
        "            \"lemmas\": row['lemmas'],\n",
        "            \"UPOS\": row.get('UPOS', ''),\n",
        "            \"glossing\": row.get('glossing', ''),\n",
        "            \"translation_de\": row['translation']\n",
        "        }\n",
        "    )\n",
        "    points.append(point)\n",
        "\n",
        "# Upload in batches\n",
        "batch_size = 100\n",
        "print(f\"\\n📦 Uploading in batches of {batch_size}...\")\n",
        "\n",
        "for i in tqdm(range(0, len(points), batch_size), desc=\"Uploading batches\"):\n",
        "    batch = points[i:i+batch_size]\n",
        "    qdrant.upsert(\n",
        "        collection_name=collection_name,\n",
        "        points=batch\n",
        "    )\n",
        "\n",
        "print(f\"\\n✅ Upload complete!\")\n",
        "print(f\"   Total records in database: {len(points)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "7216cd5fae6e4d768b8f071ec1c25b56",
            "c009d46d4dd14113ba46e2ab6df0f22a",
            "ce4f618a91f647ac99be8d437b797c4f",
            "a9a8f14b1744404c83ad325a23fb754f",
            "446b74318c4a4adc82198a377e905fa5",
            "fa92cdc49bd347149f893363e94a75c7",
            "73badaa2cf61418bbbc4bb5bdb0a9526",
            "5cd4a8a346f14e7fb8abde63715395c4",
            "c9c2f36cfb514423b4a159d13f8e9312",
            "f37bc16b4b364d358c068e24c1512e9c",
            "cc47f023ce44468c97a72769f081b0d4",
            "9be96d8795cd422db61efdd84fc2fdf5",
            "059994550c2a49d38af469798f208416",
            "d55a3d02c9c04c87b02593390e86f05e",
            "667b9372f0694cf780283b6c5bb9be50",
            "aaac75a5b1c24feda77205f0c49b6ccf",
            "5e178421dcae454396d03a7f7ba8f1a9",
            "78c2337aab0b4b0cb4c2573a32f29494",
            "6386f8a676d84c7b871dd38a75e40112",
            "6fcf926a6ced4320a8fd9cd2d30a616b",
            "6b6c760628344d6087c40e630e699cd0",
            "579099cc53f345c889b662c402846894"
          ]
        },
        "id": "KX1tF45TCoj4",
        "outputId": "7c54b4cb-98d9-4b6c-c085-e0f0d9affe63"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Uploading 8997 records to Qdrant\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preparing points:   0%|          | 0/8997 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7216cd5fae6e4d768b8f071ec1c25b56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Uploading in batches of 100...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading batches:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9be96d8795cd422db61efdd84fc2fdf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Upload complete!\n",
            "   Total records in database: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 11 : verify Database\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ STEP 10: Verifying database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "count_info = qdrant.count(\n",
        "    collection_name=collection_name,\n",
        "    exact=True\n",
        ")\n",
        "\n",
        "print(f\"📊 Collection statistics:\")\n",
        "print(f\"   Name: {collection_name}\")\n",
        "print(f\"   Points count: {count_info.count}\")\n",
        "\n",
        "# Test search\n",
        "print(f\"\\n🔍 Testing search functionality...\")\n",
        "\n",
        "test_query = df_train.iloc[0]['transliteration_normalized']\n",
        "test_embedding = df_train.iloc[0]['embedding']\n",
        "\n",
        "search_results = qdrant.query_points(\n",
        "    collection_name=collection_name,\n",
        "    query=test_embedding,\n",
        "    limit=3\n",
        ").points\n",
        "\n",
        "print(f\"\\n📝 Test query: {test_query}\")\n",
        "print(f\"\\n🎯 Top 3 search results:\")\n",
        "\n",
        "for i, result in enumerate(search_results, 1):\n",
        "    print(f\"\\n   {i}. Score: {result.score:.4f}\")\n",
        "    print(f\"      Transliteration: {result.payload['transliteration_normalized']}\")\n",
        "    print(f\"      Translation: {result.payload['translation_de'][:60]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMuTNW6qCulU",
        "outputId": "85946c14-d68e-4d57-bf55-6f7b630c7f62"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ STEP 10: Verifying database\n",
            "======================================================================\n",
            "📊 Collection statistics:\n",
            "   Name: egyptian_transliterations\n",
            "   Points count: 8997\n",
            "\n",
            "🔍 Testing search functionality...\n",
            "\n",
            "📝 Test query: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "\n",
            "🎯 Top 3 search results:\n",
            "\n",
            "   1. Score: 1.0000\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses....\n",
            "\n",
            "   2. Score: 0.9444\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta ka=i-n.i-nswt\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses Kai-ni-nisut....\n",
            "\n",
            "   3. Score: 0.8680\n",
            "      Transliteration: wꜥb-nswt hr.i-sshta im.i-s.t-ka=i\n",
            "      Translation: Der Wab-Priester des Königs und Hüter des Geheimnisses Imi-s...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🔮 PART 2: RAG Translation Pipeline\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 12: Install Additional Libraries"
      ],
      "metadata": {
        "id": "yvZqYFT0C9I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load Ollama API Key securely from Colab Secrets\n",
        "OLLAMA_API_KEY = userdata.get('OLLAMA_API_KEY')\n",
        "\n",
        "if OLLAMA_API_KEY is None:\n",
        "    raise ValueError(\"❌ OLLAMA_API_KEY not found in Colab Secrets\")\n",
        "\n",
        "# Set env var for libraries that expect it\n",
        "os.environ['OLLAMA_API_KEY'] = OLLAMA_API_KEY\n",
        "\n",
        "# Configuration\n",
        "LLM_MODEL = \"qwen3-vl:235b-instruct-cloud\" #\"gpt-oss:120b-cloud\" #\"qwen3-next:80b-cloud\" #\"qwen3-vl:235b-cloud\"\n",
        "TOP_K_RESULTS = 20\n",
        "\n",
        "print(\"🔧 RAG Pipeline Configuration:\")\n",
        "print(f\"   LLM Model: {LLM_MODEL}\")\n",
        "print(f\"   Top-K Results: {TOP_K_RESULTS}\")\n",
        "print(f\"   API Key: ✅ Loaded securely from Colab Secrets\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvesV_2PC5oN",
        "outputId": "6a7e2fc9-62f8-4991-b4d1-0bbfdb3bebd7"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 RAG Pipeline Configuration:\n",
            "   LLM Model: qwen3-vl:235b-instruct-cloud\n",
            "   Top-K Results: 20\n",
            "   API Key: ✅ Loaded securely from Colab Secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miYKvim1EuUN",
        "outputId": "6ecf7058-6511-455e-afc7-5c7a99f9e067"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank-bm25) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 14: prepare BM25 index for Sparce Search\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" Building BM25 index for sparse search\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Tokenize corpus for BM25\n",
        "corpus_texts = df_train['transliteration_normalized'].tolist()\n",
        "tokenized_corpus = [text.split() for text in corpus_texts]\n",
        "\n",
        "# Build BM25 index\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(f\"✅ BM25 index built!\")\n",
        "print(f\"   Documents indexed: {len(tokenized_corpus)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmx9860CDGEV",
        "outputId": "5b23b878-fdb1-41da-f2e8-22cb4c1cf33e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Building BM25 index for sparse search\n",
            "======================================================================\n",
            "✅ BM25 index built!\n",
            "   Documents indexed: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 15: Hybrid Search Function\n",
        "def hybrid_search(query_text, query_embedding, top_k=10, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Perform hybrid search: Dense (Vector) + Sparse (BM25)\n",
        "\n",
        "    Args:\n",
        "        query_text: Normalized transliteration query\n",
        "        query_embedding: Embedding vector of query\n",
        "        top_k: Number of results to return\n",
        "        alpha: Weight for dense search (1-alpha for sparse)\n",
        "\n",
        "    Returns:\n",
        "        List of search results with scores\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Dense Search (Vector Similarity)\n",
        "    dense_results = qdrant.query_points(\n",
        "        collection_name=collection_name,\n",
        "        query=query_embedding,\n",
        "        limit=top_k * 2\n",
        "    ).points\n",
        "\n",
        "\n",
        "    # 2. Sparse Search (BM25)\n",
        "    query_tokens = query_text.split()\n",
        "    bm25_scores = bm25.get_scores(query_tokens)\n",
        "\n",
        "    # Get top BM25 indices\n",
        "    top_bm25_indices = np.argsort(bm25_scores)[-top_k*2:][::-1]\n",
        "\n",
        "    # 3. Reciprocal Rank Fusion (RRF)\n",
        "    combined_scores = {}\n",
        "\n",
        "    # Add dense scores\n",
        "    for rank, result in enumerate(dense_results):\n",
        "        doc_id = result.id\n",
        "        rrf_score = 1 / (rank + 60)  # RRF formula\n",
        "        combined_scores[doc_id] = {\n",
        "            'rrf_score': rrf_score,\n",
        "            'dense_score': result.score,\n",
        "            'sparse_score': 0,\n",
        "            'payload': result.payload\n",
        "        }\n",
        "\n",
        "    # Add sparse scores\n",
        "    for rank, idx in enumerate(top_bm25_indices):\n",
        "        if idx in combined_scores:\n",
        "            combined_scores[idx]['rrf_score'] += 1 / (rank + 60)\n",
        "            combined_scores[idx]['sparse_score'] = bm25_scores[idx]\n",
        "        else:\n",
        "            # Retrieve payload from Qdrant\n",
        "            point = qdrant.retrieve(\n",
        "                collection_name=collection_name,\n",
        "                ids=[int(idx)]\n",
        "            )\n",
        "            if point:\n",
        "                combined_scores[idx] = {\n",
        "                    'rrf_score': 1 / (rank + 60),\n",
        "                    'dense_score': 0,\n",
        "                    'sparse_score': bm25_scores[idx],\n",
        "                    'payload': point[0].payload\n",
        "                }\n",
        "\n",
        "    # 4. Sort by combined RRF score\n",
        "    sorted_results = sorted(\n",
        "        combined_scores.items(),\n",
        "        key=lambda x: x[1]['rrf_score'],\n",
        "        reverse=True\n",
        "    )[:top_k]\n",
        "\n",
        "    # 5. Format results\n",
        "    final_results = []\n",
        "    for doc_id, scores in sorted_results:\n",
        "        final_results.append({\n",
        "            'id': doc_id,\n",
        "            'rrf_score': scores['rrf_score'],\n",
        "            'dense_score': scores['dense_score'],\n",
        "            'sparse_score': scores['sparse_score'],\n",
        "            'payload': scores['payload']\n",
        "        })\n",
        "\n",
        "    return final_results\n",
        "\n",
        "print(\"✅ Hybrid search function ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fcxk7HDOIe",
        "outputId": "e4a01ee1-b6d4-43c2-bcbb-dcb3c0fb5227"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid search function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 16: LLM Translation Function\n",
        "import requests\n",
        "OLLAMA_API_URL = \"https://ollama.com/api/chat\"\n",
        "\n",
        "def translate_with_llm(query_original, query_normalized, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Use LLM to translate Egyptian to German based on retrieved examples\n",
        "    \"\"\"\n",
        "\n",
        "    # Build examples context (same as before)\n",
        "    examples_text = \"\"\n",
        "    for i, example in enumerate(retrieved_examples, 1):\n",
        "        payload = example['payload']\n",
        "        examples_text += f\"\"\"\n",
        "Example {i}:\n",
        "- Original: {payload['transliteration_original']}\n",
        "- Normalized: {payload['transliteration_normalized']}\n",
        "- Lemmas: {', '.join(payload['lemmas'][:5]) if payload['lemmas'] else 'N/A'}\n",
        "- POS Tags: {payload['UPOS']}\n",
        "- Glossing: {payload['glossing']}\n",
        "- German: {payload['translation_de']}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    # Build prompt (same as before)\n",
        "    prompt = f\"\"\"You are a senior linguist specializing in Earlier Egyptian (Old Egyptian & Early Middle Egyptian),\n",
        "with strong expertise in morphology, syntax, and historical semantics.\n",
        "\n",
        "Your task is to translate an Earlier Egyptian transliteration into German\n",
        "using retrieved linguistic examples ONLY as structural and semantic guidance.\n",
        "\n",
        "=====================================\n",
        "QUERY TO TRANSLATE\n",
        "=====================================\n",
        "\n",
        "Normalized Transliteration:\n",
        "{query_normalized}\n",
        "\n",
        "=====================================\n",
        "RETRIEVED DATABASE EXAMPLES\n",
        "=====================================\n",
        "{examples_text}\n",
        "\n",
        "=====================================\n",
        "INSTRUCTIONS\n",
        "=====================================\n",
        "Follow these steps carefully:\n",
        "\n",
        "1. Linguistic Analysis\n",
        "   - Identify the grammatical category of each word (verb, noun, particle, suffix, etc.)\n",
        "   - Detect verb tense/aspect, suffix pronouns, and syntactic order (VSO, SVO, nominal clause).\n",
        "\n",
        "2. Morphological Alignment\n",
        "   - Compare suffixes, verb forms, and particles with the retrieved examples.\n",
        "   - Use lemma meanings as semantic hints, not literal translations.\n",
        "\n",
        "3. Translation Construction\n",
        "   - Produce a fluent and historically plausible German translation.\n",
        "   - Adapt word order to correct German syntax.\n",
        "   - Prefer linguistically conservative interpretations over speculative ones.\n",
        "\n",
        "4. Uncertainty Handling\n",
        "   - If multiple readings are possible, choose the most likely one.\n",
        "   - Briefly mention ambiguity only if it materially affects meaning.\n",
        "\n",
        "=====================================\n",
        "STRICT RULES\n",
        "=====================================\n",
        "- DO NOT copy any German translation from the examples.\n",
        "- DO NOT mention example numbers or quote them.\n",
        "- DO NOT add explanations unless uncertainty exists.\n",
        "- DO NOT hallucinate missing words.\n",
        "- Base your output strictly on Earlier Egyptian grammar.\n",
        "\n",
        "=====================================\n",
        "OUTPUT FORMAT (STRICT)\n",
        "=====================================\n",
        "German Translation: <one clear German sentence>\n",
        "Confidence: High | Medium | Low\n",
        "Notes: <only if confidence is Medium or Low>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Call Ollama Cloud API with CORRECT endpoint\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        # Use Ollama's native format (not OpenAI format)\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist specializing in translating Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            # Ollama format uses 'message' -> 'content'\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Extract German translation\n",
        "            import re\n",
        "            match = re.search(r'German Translation:\\s*(.+?)(?:\\n|$)', llm_output, re.IGNORECASE)\n",
        "            if match:\n",
        "                german_translation = match.group(1).strip()\n",
        "                return german_translation, llm_output\n",
        "            else:\n",
        "                return llm_output.split('\\n')[0].strip(), llm_output\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            print(f\"   Response: {response.text}\")\n",
        "            return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "B1hvYIFHE-0N"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## part 17: German to English Tranlslation\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading German→English translation model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load MarianMT model\n",
        "print(\"📥 Loading MarianMT model...\")\n",
        "de_en_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
        "de_en_tokenizer = MarianTokenizer.from_pretrained(de_en_model_name)\n",
        "de_en_model = MarianMTModel.from_pretrained(de_en_model_name)\n",
        "\n",
        "print(f\"✅ Model loaded: {de_en_model_name}\")\n",
        "\n",
        "def translate_german_to_english(german_text):\n",
        "    \"\"\"Translate German to English using MarianMT\"\"\"\n",
        "    try:\n",
        "        # Tokenize\n",
        "        inputs = de_en_tokenizer(\n",
        "            german_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Generate translation\n",
        "        outputs = de_en_model.generate(**inputs)\n",
        "\n",
        "        # Decode\n",
        "        english_text = de_en_tokenizer.decode(\n",
        "            outputs[0],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        return english_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ German→English translation ready!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMd-YxkhFE3l",
        "outputId": "f2a85271-525b-4c21-f2ca-9a4df934a631"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Loading German→English translation model\n",
            "======================================================================\n",
            "📥 Loading MarianMT model...\n",
            "✅ Model loaded: Helsinki-NLP/opus-mt-de-en\n",
            "✅ German→English translation ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 18: Complete Translation pipeline\n",
        "\n",
        "def translate_egyptian_to_english(query_original, show_details=True):\n",
        "    \"\"\"\n",
        "    Complete pipeline: Egyptian → German → English\n",
        "\n",
        "    Args:\n",
        "        query_original: Original Egyptian transliteration\n",
        "        show_details: Print intermediate steps\n",
        "\n",
        "    Returns:\n",
        "        dict with results\n",
        "    \"\"\"\n",
        "\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"📝 TRANSLATING: {query_original}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Normalize query\n",
        "    query_normalized = normalize_transliteration(query_original)\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n1️⃣ Normalization:\")\n",
        "        print(f\"   Original:   {query_original}\")\n",
        "        print(f\"   Normalized: {query_normalized}\")\n",
        "\n",
        "    # Step 2: Generate embedding\n",
        "    query_embedding = embedding_model.encode(\n",
        "        query_normalized,\n",
        "        normalize_embeddings=True\n",
        "    ).tolist()\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n2️⃣ Embedding generated (dim={len(query_embedding)})\")\n",
        "\n",
        "    # Step 3: Hybrid search\n",
        "    if show_details:\n",
        "        print(f\"\\n3️⃣ Hybrid search (Dense + BM25)...\")\n",
        "\n",
        "    search_results = hybrid_search(\n",
        "        query_text=query_normalized,\n",
        "        query_embedding=query_embedding,\n",
        "        top_k=TOP_K_RESULTS\n",
        "    )\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   ✅ Found {len(search_results)} results\")\n",
        "        print(f\"\\n   📊 Top 3 matches:\")\n",
        "        for i, result in enumerate(search_results[:3], 1):\n",
        "            print(f\"\\n   {i}. RRF Score: {result['rrf_score']:.4f}\")\n",
        "            print(f\"      Transliteration: {result['payload']['transliteration_normalized']}\")\n",
        "            print(f\"      German: {result['payload']['translation_de'][:50]}...\")\n",
        "\n",
        "    # Step 4: LLM Translation (German)\n",
        "    if show_details:\n",
        "        print(f\"\\n4️⃣ LLM Translation (Egyptian → German)...\")\n",
        "\n",
        "    german_translation, llm_full_output = translate_with_llm(\n",
        "        query_original=query_original,\n",
        "        query_normalized=query_normalized,\n",
        "        retrieved_examples=search_results\n",
        "    )\n",
        "\n",
        "    if not german_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'LLM translation failed'\n",
        "        }\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   🇩🇪 German: {german_translation}\")\n",
        "\n",
        "    # Step 5: German → English\n",
        "    if show_details:\n",
        "        print(f\"\\n5️⃣ Translation (German → English)...\")\n",
        "\n",
        "    english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "    if not english_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'German→English translation failed'\n",
        "        }\n",
        "\n",
        "    # Final result\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"✅ TRANSLATION COMPLETE\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"🏛️ Egyptian:  {query_original}\")\n",
        "        print(f\"🔤 Normalized: {query_normalized}\")\n",
        "        print(f\"🇩🇪 German:    {german_translation}\")\n",
        "        print(f\"🇬🇧 English:   {english_translation}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'query_original': query_original,\n",
        "        'query_normalized': query_normalized,\n",
        "        'german': german_translation,\n",
        "        'english': english_translation,\n",
        "        'llm_output': llm_full_output,\n",
        "        'top_matches': search_results[:3]\n",
        "    }\n",
        "\n",
        "print(\"✅ Complete translation pipeline ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlcLe4THFK2M",
        "outputId": "d030767e-b032-4e87-e093-64a00e819fcd"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Complete translation pipeline ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========No======================"
      ],
      "metadata": {
        "id": "FN2OlfR5E5zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## part 19: Batch Processing Test set\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 STEP 13: Processing test set\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load test set\n",
        "print(\"📥 Loading test set...\")\n",
        "df_test = pd.read_csv('tla_test_set.csv')\n",
        "print(f\"✅ Loaded {len(df_test)} test records\")\n",
        "\n",
        "# Process subset (first 10 for demo)\n",
        "print(f\"\\n🔄 Translating first 10 test queries...\")\n",
        "print(\"(Processing all {len(df_test)} would take ~{len(df_test)*2/60:.1f} minutes)\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx in tqdm(range(min(10, len(df_test))), desc=\"Translating\"):\n",
        "    query = df_test.iloc[idx]['transliteration']\n",
        "\n",
        "    result = translate_egyptian_to_english(\n",
        "        query_original=query,\n",
        "        show_details=False\n",
        "    )\n",
        "\n",
        "    if result['success']:\n",
        "        results.append({\n",
        "            'query_original': result['query_original'],\n",
        "            'query_normalized': result['query_normalized'],\n",
        "            'reference_german': df_test.iloc[idx]['translation'],\n",
        "            'predicted_german': result['german'],\n",
        "            'predicted_english': result['english']\n",
        "        })\n",
        "\n",
        "# Create results dataframe\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\n✅ Processed {len(results)} queries successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "4f2a80b2760942b285c45c11a53e7570",
            "5525fa234ecc41fea6be00d4356d332c",
            "a5a26da884ac40fabb6c494e76ce852b",
            "baeb4497d5114da3a450404f057ad6ce",
            "6888a4ebc9754312974e8b4e3a30319f",
            "eaee7f5d2d3d45d2a7705e6816f00b75",
            "9381aeb2923247f28bee4542e75e5037",
            "8a623991c5b74a239580be2ce050240b",
            "ee2f03e9e17948f598b38ce81b21f778",
            "a880618972b8418f90624c47297aaaab",
            "bef7b7b21c054670b5662ded63ffa53f"
          ]
        },
        "id": "cDcdKvGhFq3z",
        "outputId": "a7acfba8-b9d3-4197-9a3a-849fc81a5c26"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 STEP 13: Processing test set\n",
            "======================================================================\n",
            "📥 Loading test set...\n",
            "✅ Loaded 91 test records\n",
            "\n",
            "🔄 Translating first 10 test queries...\n",
            "(Processing all {len(df_test)} would take ~{len(df_test)*2/60:.1f} minutes)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Translating:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f2a80b2760942b285c45c11a53e7570"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Processed 10 queries successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 20: Display result"
      ],
      "metadata": {
        "id": "kNuEm7SsMWA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 SAMPLE RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i in range(min(5, len(df_results))):\n",
        "    row = df_results.iloc[i]\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"Query {i+1}:\")\n",
        "    print(f\"{'─'*70}\")\n",
        "    print(f\"🏛️ Egyptian:    {row['query_original']}\")\n",
        "    print(f\"🔤 Normalized:  {row['query_normalized']}\")\n",
        "    print(f\"📖 Reference:   {row['reference_german']}\")\n",
        "    print(f\"🤖 Predicted:   {row['predicted_german']}\")\n",
        "    print(f\"🇬🇧 English:    {row['predicted_english']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6N6F5iMZMd",
        "outputId": "4d0449ac-6c91-4e68-b306-dc50114a3118"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 SAMPLE RESULTS\n",
            "======================================================================\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 1:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "🔤 Normalized:  smr-wꜥ.ti khr.i-hab.t im.i-ra-iꜥw hr.w-khwi\n",
            "📖 Reference:   Der Einzige Freund, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\n",
            "🤖 Predicted:   Der einzige Freund des Königs, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\n",
            "🇬🇧 English:    The King's only friend, the presiding priest, the ruler of the foreign language troupe, Harchuf.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 2:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ šs\n",
            "🔤 Normalized:  kha apd kha apd kha mnkh.t kha ih kha ta hnq.t pa.t kha apd kha apd kha shs\n",
            "📖 Reference:   Tausend an Geflügel, tausend an Geflügel, tausend an Kleidung, tausend an Rind, tausend an Brot, Bier und Gebäck, tausend an Geflügel, tausend an Geflügel, tausend an Geflügel, tausend an Alabaster.\n",
            "🤖 Predicted:   Tausend an Geflügel, tausend an Geflügel, tausend an Kleidung, tausend an Rind, tausend an Brot, tausend an Bier, tausend an Gebäck, tausend an Geflügel, tausend an Geflügel, tausend an Alabaster.\n",
            "🇬🇧 English:    Thousands of poultry, thousands of poultry, thousands of clothing, thousands of cattle, thousands of bread, thousands of beer, thousands of pastries, thousands of poultry, thousands of poultry, thousands of alabasters.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 3:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr msi̯.n ꜣs.t nṯr.(ꞽ)t\n",
            "🔤 Normalized:  i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n as.t ntjr.it\n",
            "📖 Reference:   Sei gegrüßt, Min bei seinen Prozessionen, mit hoher Federkrone, Sohn des Osiris, den Isis, die Göttliche, geboren hat;\n",
            "🤖 Predicted:   Sei gegrüßt, Min, im Peret, mit Doppelfederkrone, Sohn des Osiris, unter den Göttern.\n",
            "🇬🇧 English:    Greetings, Min, in the Peret, with double feather crown, son of Osiris, among the gods.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 4:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    šdi̯.t kꜣ rḫ.yt\n",
            "🔤 Normalized:  shdi.t ka rkh.yt\n",
            "📖 Reference:   Darbringen der Speisen (für die) Untertanen\n",
            "🤖 Predicted:   Das Opfern der Kammer zur Versorgung der Untertanen.\n",
            "🇬🇧 English:    Sacrificing the chamber to supply the subjects.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 5:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    (w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ꞽr =s\n",
            "🔤 Normalized:  wsr.w ni.t m n ir.t-hr.w shmi.t ir\n",
            "📖 Reference:   Osiris Neith, nimm dir das Horusauge, zu dem er geht.\n",
            "🤖 Predicted:   Osiris Neith, nimm dir das Horusauge, zu dem er geht.\n",
            "🇬🇧 English:    Osiris Neith, take the horusuck he's going to.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============NO============================="
      ],
      "metadata": {
        "id": "pvWw1w60FAk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 📊 EVALUATION METRICS FOR EGYPTIAN TRANSLITERATION RAG SYSTEM\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 24: Install Evaluation Libraries"
      ],
      "metadata": {
        "id": "4N2_SXgKIFEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_test))\n",
        "print(df_test.columns.tolist())\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "hIxubIv2IAKx",
        "outputId": "84af551f-07f8-4242-9d4a-a171d1bca68a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'transliteration_normalized']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     transliteration  \\\n",
              "0  smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...   \n",
              "1  ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...   \n",
              "2  ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...   \n",
              "3                                    šdi̯.t kꜣ rḫ.yt   \n",
              "4  (w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...   \n",
              "\n",
              "                                       lemmatization  \\\n",
              "0  400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...   \n",
              "1  113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...   \n",
              "2  91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...   \n",
              "3                  158710|šdi̯ 162890|kꜣ 95820|rḫ.yt   \n",
              "4  49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...   \n",
              "\n",
              "                                                UPOS  \\\n",
              "0                               NOUN NOUN NOUN PROPN   \n",
              "1  NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...   \n",
              "2  VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...   \n",
              "3                                     VERB NOUN NOUN   \n",
              "4   NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON   \n",
              "\n",
              "                                            glossing  \\\n",
              "0                               TITL TITL TITL PERSN   \n",
              "1  N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....   \n",
              "2  V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...   \n",
              "3                                      V\\inf N.m N.f   \n",
              "4  TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...   \n",
              "\n",
              "                                         translation  \\\n",
              "0  Der Einzige Freund, der Vorlesepriester, der V...   \n",
              "1  Tausend an Geflügel, tausend an Geflügel, taus...   \n",
              "2  Sei gegrüßt, Min bei seinen Prozessionen, mit ...   \n",
              "3        Darbringen der Speisen (für die) Untertanen   \n",
              "4  Osiris Neith, nimm dir das Horusauge, zu dem e...   \n",
              "\n",
              "                          transliteration_normalized  \n",
              "0        smr-wꜥ.ti khr.i-hab.t im.i-ra-iꜥw hr.w-khwi  \n",
              "1  kha apd kha apd kha mnkh.t kha ih kha ta hnq.t...  \n",
              "2  i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...  \n",
              "3                                   shdi.t ka rkh.yt  \n",
              "4                 wsr.w ni.t m n ir.t-hr.w shmi.t ir  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf6a1f32-3d80-452d-b5c0-c92e8a184c1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transliteration</th>\n",
              "      <th>lemmatization</th>\n",
              "      <th>UPOS</th>\n",
              "      <th>glossing</th>\n",
              "      <th>translation</th>\n",
              "      <th>transliteration_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...</td>\n",
              "      <td>400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...</td>\n",
              "      <td>NOUN NOUN NOUN PROPN</td>\n",
              "      <td>TITL TITL TITL PERSN</td>\n",
              "      <td>Der Einzige Freund, der Vorlesepriester, der V...</td>\n",
              "      <td>smr-wꜥ.ti khr.i-hab.t im.i-ra-iꜥw hr.w-khwi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...</td>\n",
              "      <td>113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...</td>\n",
              "      <td>NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...</td>\n",
              "      <td>N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....</td>\n",
              "      <td>Tausend an Geflügel, tausend an Geflügel, taus...</td>\n",
              "      <td>kha apd kha apd kha mnkh.t kha ih kha ta hnq.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...</td>\n",
              "      <td>91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...</td>\n",
              "      <td>VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...</td>\n",
              "      <td>V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...</td>\n",
              "      <td>Sei gegrüßt, Min bei seinen Prozessionen, mit ...</td>\n",
              "      <td>i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>šdi̯.t kꜣ rḫ.yt</td>\n",
              "      <td>158710|šdi̯ 162890|kꜣ 95820|rḫ.yt</td>\n",
              "      <td>VERB NOUN NOUN</td>\n",
              "      <td>V\\inf N.m N.f</td>\n",
              "      <td>Darbringen der Speisen (für die) Untertanen</td>\n",
              "      <td>shdi.t ka rkh.yt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...</td>\n",
              "      <td>49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...</td>\n",
              "      <td>NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON</td>\n",
              "      <td>TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...</td>\n",
              "      <td>Osiris Neith, nimm dir das Horusauge, zu dem e...</td>\n",
              "      <td>wsr.w ni.t m n ir.t-hr.w shmi.t ir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6a1f32-3d80-452d-b5c0-c92e8a184c1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf6a1f32-3d80-452d-b5c0-c92e8a184c1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf6a1f32-3d80-452d-b5c0-c92e8a184c1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"transliteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"\\ua7bdw mdw =f \\u1e0fi\\u032f =f \\u1e6f\\ua723m n =f \\u1e25r\",\n          \"m \\u1e2bm wn\\ua7bds r\\ua725w\",\n          \"smr-w\\ua725.t\\ua7bd \\u1e96r(.\\ua7bd)-\\u1e25(\\ua723)b(.t) (\\ua7bd)m(.\\ua7bd)-r(\\u02be)-(\\ua7bd)\\ua725w \\u1e25r(.w)-\\u1e2bwi\\u032f=f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatization\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"851515|\\ua7bdw 78150|mdw 10050|=f 96700|r\\u1e0fi\\u032f 10050|=f 174590|\\u1e6f\\ua723m 78870|n 10050|=f 107510|\\u1e25r\",\n          \"64410|m 116910|\\u1e2bm 800001|Wn\\ua7bds 400015|R\\ua725w\",\n          \"400142|smr-w\\ua725.t\\ua7bd 124340|\\u1e96r.\\ua7bd-\\u1e25\\ua723b.t 400011|\\ua7bdm.\\ua7bd-r\\u02be-\\ua7bd\\ua725\\ua723.w 705022|\\u1e24r.w-\\u1e2bwi\\u032f=f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UPOS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"PART NOUN PRON VERB PRON VERB ADP PRON NOUN\",\n          \"VERB VERB PROPN PROPN\",\n          \"NOUN NOUN NOUN PROPN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glossing\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"PTCL N.m:stpr -3sg.m V\\\\tam.act:stpr -3sg.m V\\\\tam.act PREP:stpr -3sg.m N.m\",\n          \"V\\\\imp.sg V\\\\advz ROYLN DIVN\",\n          \"TITL TITL TITL PERSN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"(Und) seine Rede kann Milde erreichen (lit. l\\u00e4sst f\\u00fcr ihn das Gesicht sich verh\\u00fcllen).\",\n          \"Sei nicht in Unkenntnis des Unas, Re.\",\n          \"Der Einzige Freund, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transliteration_normalized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"iw mdw dji tjam n hr\",\n          \"m khm wnis r\\ua725w\",\n          \"smr-w\\ua725.ti khr.i-hab.t im.i-ra-i\\ua725w hr.w-khwi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 19: Install Evaluation Libraries\n",
        "import sys\n",
        "print(\"\\n📦 Installing all evaluation libraries...\")\n",
        "eval_packages = [\n",
        "    'nltk',\n",
        "    'rouge-score',\n",
        "    'sacrebleu',\n",
        "]\n",
        "\n",
        "for package in eval_packages:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--break-system-packages', '-q'])\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from sacrebleu.metrics import CHRF\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data\n",
        "print(\"📥 Downloading NLTK data...\")\n",
        "try:\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "    print(\"✅ NLTK data ready!\")\n",
        "except:\n",
        "    print(\"⚠️ NLTK download warning (may still work)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRKJZc-8IHLK",
        "outputId": "43938cb2-0940-42b7-8ec9-6a0137d708df"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Installing all evaluation libraries...\n",
            "📥 Downloading NLTK data...\n",
            "✅ NLTK data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 20: Define Evaluation Metrics\n",
        "\n",
        "# ============================================================================\n",
        "# TRANSLATION QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_bleu(reference, hypothesis):\n",
        "    \"\"\"Calculate BLEU score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        smoothing = SmoothingFunction()\n",
        "        bleu_score = sentence_bleu(\n",
        "            [reference_tokens],\n",
        "            hypothesis_tokens,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "        return bleu_score * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_rouge(reference, hypothesis):\n",
        "    \"\"\"Calculate ROUGE scores\"\"\"\n",
        "    try:\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        scores = scorer.score(reference, hypothesis)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure * 100,\n",
        "            'rouge2': scores['rouge2'].fmeasure * 100,\n",
        "            'rougeL': scores['rougeL'].fmeasure * 100\n",
        "        }\n",
        "    except:\n",
        "        return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "def calculate_meteor(reference, hypothesis):\n",
        "    \"\"\"Calculate METEOR score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        meteor = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "        return meteor * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_chrf(reference, hypothesis):\n",
        "    \"\"\"Calculate chrF score (0-100)\"\"\"\n",
        "    try:\n",
        "        chrf = CHRF()\n",
        "        score = chrf.sentence_score(hypothesis, [reference])\n",
        "        return score.score  # Already 0-100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_exact_match(reference, hypothesis):\n",
        "    \"\"\"Calculate exact match\"\"\"\n",
        "    return 100.0 if reference.strip().lower() == hypothesis.strip().lower() else 0.0\n",
        "\n",
        "def calculate_word_overlap(reference, hypothesis):\n",
        "    \"\"\"Calculate word-level overlap percentage\"\"\"\n",
        "    try:\n",
        "        ref_words = set(reference.lower().split())\n",
        "        hyp_words = set(hypothesis.lower().split())\n",
        "        if len(ref_words) == 0:\n",
        "            return 0.0\n",
        "        overlap = len(ref_words.intersection(hyp_words))\n",
        "        return (overlap / len(ref_words)) * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# ============================================================================\n",
        "# RETRIEVAL QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Calculate Recall@K - checks if reference appears in top K results\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "        k_values: List of K values to calculate recall for\n",
        "\n",
        "    Returns:\n",
        "        Dict with Recall@K for each K\n",
        "    \"\"\"\n",
        "    recalls = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        found = False\n",
        "        for i, example in enumerate(retrieved_examples[:k]):\n",
        "            if i >= len(retrieved_examples):\n",
        "                break\n",
        "            retrieved_german = example['payload']['translation_de']\n",
        "            # Check if the reference matches (exact or high similarity)\n",
        "            if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        recalls[f'recall@{k}'] = 100.0 if found else 0.0\n",
        "\n",
        "    return recalls\n",
        "\n",
        "def calculate_mrr(reference_german, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Calculate Mean Reciprocal Rank (MRR)\n",
        "\n",
        "    MRR = 1 / rank of first relevant result\n",
        "    If no relevant result found, MRR = 0\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "\n",
        "    Returns:\n",
        "        MRR score (0-100)\n",
        "    \"\"\"\n",
        "    for i, example in enumerate(retrieved_examples):\n",
        "        retrieved_german = example['payload']['translation_de']\n",
        "        # Check if this is a relevant result\n",
        "        if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "            # Rank starts at 1, not 0\n",
        "            mrr = 1.0 / (i + 1)\n",
        "            return mrr * 100  # Convert to percentage\n",
        "\n",
        "    # No relevant result found\n",
        "    return 0.0\n",
        "\n",
        "def calculate_average_retrieval_score(retrieved_examples, top_k=10):\n",
        "    \"\"\"\n",
        "    Calculate average retrieval score from top K results\n",
        "\n",
        "    Args:\n",
        "        retrieved_examples: List of retrieved examples with scores\n",
        "        top_k: Number of top results to consider\n",
        "\n",
        "    Returns:\n",
        "        Average RRF score (0-100)\n",
        "    \"\"\"\n",
        "    if not retrieved_examples:\n",
        "        return 0.0\n",
        "\n",
        "    scores = [example['rrf_score'] for example in retrieved_examples[:top_k]]\n",
        "    avg_score = np.mean(scores) if scores else 0.0\n",
        "    return avg_score * 100  # Convert to percentage\n",
        "\n",
        "print(\"✅ All evaluation metrics defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRXoXLezLdHa",
        "outputId": "6d115881-b18d-41ca-a6cf-f8cd243b7af9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All evaluation metrics defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🔄 Part 21: Process RAG Test Set with ALL Metrics\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING RAG TEST SET WITH ALL METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load test set\n",
        "print(\"\\n📥 Loading test set...\")\n",
        "df_test = pd.read_csv('tla_test_set.csv')[:25]  # Limit for demo\n",
        "print(f\"✅ Loaded {len(df_test)} test records\")\n",
        "\n",
        "# Initialize results storage\n",
        "test_results = []\n",
        "failed_translations = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} test samples...\")\n",
        "print(\"⏱️ Estimated time: ~{:.1f} minutes\\n\".format(len(df_test) * 3 / 60))\n",
        "\n",
        "# Process each test sample\n",
        "for idx in tqdm(range(len(df_test)), desc=\"RAG Translation\"):\n",
        "    try:\n",
        "        # Get query\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        # Translate Egyptian → German → English using RAG\n",
        "        result = translate_egyptian_to_english(\n",
        "            query_original=query_original,\n",
        "            show_details=False\n",
        "        )\n",
        "\n",
        "        if result['success']:\n",
        "            # Translate reference German → English\n",
        "            reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "            if reference_english:\n",
        "                # Store results (including retrieval info)\n",
        "                test_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'transliteration_normalized': result['query_normalized'],\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german': result['german'],\n",
        "                    'predicted_english': result['english'],\n",
        "                    'top_matches': result['top_matches']  # Store retrieval results\n",
        "                })\n",
        "            else:\n",
        "                failed_translations.append({\n",
        "                    'sample_id': idx,\n",
        "                    'reason': 'Reference translation to English failed'\n",
        "                })\n",
        "        else:\n",
        "            failed_translations.append({\n",
        "                'sample_id': idx,\n",
        "                'reason': result.get('error', 'RAG translation failed')\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_translations.append({\n",
        "            'sample_id': idx,\n",
        "            'reason': f'Exception: {str(e)}'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "# Create results DataFrame\n",
        "df_test_results = pd.DataFrame(test_results)\n",
        "\n",
        "print(f\"\\n✅ RAG Processing complete!\")\n",
        "print(f\"   Successful: {len(test_results)}\")\n",
        "print(f\"   Failed: {len(failed_translations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "8aaf464ca4a844c489eeb16164b917c4",
            "53df6c7e59ba474d812bedab4d8f5eaf",
            "95eab9f963d44e0dbf4e37368e0ef7f0",
            "fbffbd5b50144eea996afbb0e53c4cef",
            "b97ee139f3c1459690ba5059236193a5",
            "2bd514239b774cc6bcf6bd309c13dba1",
            "340e476832bb403d8fb2fc9c3f8cf59c",
            "013d3780cf11429fb82c8cc521133abc",
            "30f6081fcc654bac81dc29aaed0c2f3c",
            "baa5b22b1e7d4449b7580b530a533a1e",
            "978cefc8b3db43738981161bf3a212fd"
          ]
        },
        "id": "7lmnADTOLhfg",
        "outputId": "20bcaaf6-8578-474c-9bd0-e171c9ef5b24"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING RAG TEST SET WITH ALL METRICS\n",
            "======================================================================\n",
            "\n",
            "📥 Loading test set...\n",
            "✅ Loaded 25 test records\n",
            "\n",
            "🔄 Processing 25 test samples...\n",
            "⏱️ Estimated time: ~1.2 minutes\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG Translation:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aaf464ca4a844c489eeb16164b917c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ RAG Processing complete!\n",
            "   Successful: 25\n",
            "   Failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 22: Calculate ALL Metrics (Translation + Retrieval)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING ALL METRICS FOR RAG SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "metrics_list = []\n",
        "\n",
        "print(f\"\\n🔄 Computing all metrics for {len(df_test_results)} translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_test_results.iterrows(), total=len(df_test_results), desc=\"Computing all metrics\"):\n",
        "    reference_english = row['reference_english']\n",
        "    hypothesis_english = row['predicted_english']\n",
        "    reference_german = row['reference_german']\n",
        "    retrieved_examples = row['top_matches']\n",
        "\n",
        "    # Calculate translation quality metrics\n",
        "    rouge_scores = calculate_rouge(reference_english, hypothesis_english)\n",
        "\n",
        "    # Calculate retrieval quality metrics\n",
        "    recall_scores = calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10, 20])\n",
        "    mrr_score = calculate_mrr(reference_german, retrieved_examples)\n",
        "    avg_retrieval_score = calculate_average_retrieval_score(retrieved_examples, top_k=10)\n",
        "\n",
        "    # Combine all metrics\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference_english, hypothesis_english),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference_english, hypothesis_english),\n",
        "        'chrf': calculate_chrf(reference_english, hypothesis_english),\n",
        "        'exact_match': calculate_exact_match(reference_english, hypothesis_english),\n",
        "        'word_overlap': calculate_word_overlap(reference_english, hypothesis_english),\n",
        "        # Retrieval Quality Metrics\n",
        "        'recall@1': recall_scores['recall@1'],\n",
        "        'recall@3': recall_scores['recall@3'],\n",
        "        'recall@5': recall_scores['recall@5'],\n",
        "        'recall@10': recall_scores['recall@10'],\n",
        "        'recall@20': recall_scores['recall@20'],\n",
        "        'mrr': mrr_score,\n",
        "        'avg_retrieval_score': avg_retrieval_score\n",
        "    }\n",
        "\n",
        "    metrics_list.append(metrics)\n",
        "\n",
        "# Create metrics DataFrame\n",
        "df_metrics = pd.DataFrame(metrics_list)\n",
        "\n",
        "print(\"✅ All metrics calculation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "ff83f943d10b4b019409f34ff40373b3",
            "0d91e8dfa39f420cbc4223df32369d18",
            "80c9d6af823747059491dac9b0cdddc5",
            "84e41a3499664d3988df18a7344a3823",
            "31992ad1a9874314a5c363949dfa7740",
            "95be3833e232409988a1b057d39b9146",
            "c700919ea6ae42e3bde5b806cfe295e2",
            "e0e931f8984b4a269b271566d5559425",
            "1e4c5111ea784c04b210907f2d34759e",
            "51224411c1b14a2085f3f94d64f5c5e4",
            "d7beb56fe50248b19dbf7afc5ed0279d"
          ]
        },
        "id": "v0BrfMFlLoV4",
        "outputId": "5a5bdd82-a194-4c9b-cdc3-fd0bbf9268ee"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CALCULATING ALL METRICS FOR RAG SYSTEM\n",
            "======================================================================\n",
            "\n",
            "🔄 Computing all metrics for 25 translations...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing all metrics:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff83f943d10b4b019409f34ff40373b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All metrics calculation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 📈 Part 23: Display Complete RAG System Summary\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for all metrics\n",
        "avg_metrics = {\n",
        "    # Translation Quality\n",
        "    'BLEU': df_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_metrics['meteor'].mean(),\n",
        "    'chrF': df_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_metrics['word_overlap'].mean(),\n",
        "    # Retrieval Quality\n",
        "    'Recall@1': df_metrics['recall@1'].mean(),\n",
        "    'Recall@3': df_metrics['recall@3'].mean(),\n",
        "    'Recall@5': df_metrics['recall@5'].mean(),\n",
        "    'Recall@10': df_metrics['recall@10'].mean(),\n",
        "    'Recall@20': df_metrics['recall@20'].mean(),\n",
        "    'MRR': df_metrics['mrr'].mean(),\n",
        "    'Avg Retrieval Score': df_metrics['avg_retrieval_score'].mean()\n",
        "}\n",
        "\n",
        "# Quality emoji function\n",
        "def get_quality_emoji(metric_name, score):\n",
        "    \"\"\"Get quality emoji based on metric and score\"\"\"\n",
        "    if metric_name in ['Recall@1', 'Recall@3', 'Exact Match']:\n",
        "        return '🟢' if score > 20 else '🟡' if score > 5 else '🔴'\n",
        "    elif 'Recall' in metric_name:\n",
        "        return '🟢' if score > 40 else '🟡' if score > 20 else '🔴'\n",
        "    elif metric_name == 'MRR':\n",
        "        return '🟢' if score > 30 else '🟡' if score > 15 else '🔴'\n",
        "    else:\n",
        "        return '🟢' if score > 50 else '🟡' if score > 30 else '🔴'\n",
        "\n",
        "print(\"\\n📊 TRANSLATION QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "translation_metrics = ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'METEOR', 'chrF', 'Exact Match', 'Word Overlap']\n",
        "for metric in translation_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n📊 RETRIEVAL QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "retrieval_metrics = ['Recall@1', 'Recall@3', 'Recall@5', 'Recall@10', 'Recall@20', 'MRR', 'Avg Retrieval Score']\n",
        "for metric in retrieval_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "# Distribution statistics for key metrics\n",
        "print(\"\\n📈 KEY METRIC DISTRIBUTIONS:\")\n",
        "print(\"─\" * 70)\n",
        "\n",
        "for metric_name, metric_col in [('BLEU', 'bleu'), ('METEOR', 'meteor'), ('Recall@10', 'recall@10'), ('MRR', 'mrr')]:\n",
        "    scores = df_metrics[metric_col]\n",
        "    print(f\"\\n{metric_name}:\")\n",
        "    print(f\"   Min:    {scores.min():6.2f}%\")\n",
        "    print(f\"   25%:    {scores.quantile(0.25):6.2f}%\")\n",
        "    print(f\"   Median: {scores.median():6.2f}%\")\n",
        "    print(f\"   75%:    {scores.quantile(0.75):6.2f}%\")\n",
        "    print(f\"   Max:    {scores.max():6.2f}%\")\n",
        "    print(f\"   Std:    {scores.std():6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaXAJjvrLqAl",
        "outputId": "059d75ca-40dc-4fc8-b542-ebcbda1e9b4e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "📊 TRANSLATION QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 BLEU                :  25.47%\n",
            "   🟢 ROUGE-1             :  51.22%\n",
            "   🟡 ROUGE-2             :  35.23%\n",
            "   🟡 ROUGE-L             :  49.76%\n",
            "   🟡 METEOR              :  40.05%\n",
            "   🟡 chrF                :  45.58%\n",
            "   🔴 Exact Match         :   4.00%\n",
            "   🟡 Word Overlap        :  40.80%\n",
            "\n",
            "📊 RETRIEVAL QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 Recall@1            :   0.00%\n",
            "   🔴 Recall@3            :   0.00%\n",
            "   🔴 Recall@5            :   0.00%\n",
            "   🔴 Recall@10           :   0.00%\n",
            "   🔴 Recall@20           :   0.00%\n",
            "   🔴 MRR                 :   0.00%\n",
            "   🔴 Avg Retrieval Score :   3.06%\n",
            "\n",
            "📈 KEY METRIC DISTRIBUTIONS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "BLEU:\n",
            "   Min:      0.00%\n",
            "   25%:      1.89%\n",
            "   Median:   8.84%\n",
            "   75%:     50.65%\n",
            "   Max:    100.00%\n",
            "   Std:     30.80%\n",
            "\n",
            "METEOR:\n",
            "   Min:      0.00%\n",
            "   25%:     15.49%\n",
            "   Median:  34.31%\n",
            "   75%:     63.61%\n",
            "   Max:     99.77%\n",
            "   Std:     29.87%\n",
            "\n",
            "Recall@10:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:      0.00%\n",
            "   Std:      0.00%\n",
            "\n",
            "MRR:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:      0.00%\n",
            "   Std:      0.00%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 24: Visual Comparison Charts\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 VISUAL METRIC COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Translation metrics\n",
        "print(\"\\n🎯 Translation Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[:8]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "# Retrieval metrics\n",
        "print(\"\\n🔍 Retrieval Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[8:]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOlhOQqeLrt6",
        "outputId": "892087c6-f129-41fa-b67e-39203d440b81"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 VISUAL METRIC COMPARISON\n",
            "======================================================================\n",
            "\n",
            "🎯 Translation Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "BLEU                 ████████████  25.47%\n",
            "ROUGE-1              █████████████████████████  51.22%\n",
            "ROUGE-2              █████████████████  35.23%\n",
            "ROUGE-L              ████████████████████████  49.76%\n",
            "METEOR               ████████████████████  40.05%\n",
            "chrF                 ██████████████████████  45.58%\n",
            "Exact Match          ██   4.00%\n",
            "Word Overlap         ████████████████████  40.80%\n",
            "\n",
            "🔍 Retrieval Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Recall@1                0.00%\n",
            "Recall@3                0.00%\n",
            "Recall@5                0.00%\n",
            "Recall@10               0.00%\n",
            "Recall@20               0.00%\n",
            "MRR                     0.00%\n",
            "Avg Retrieval Score  █   3.06%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 25: Process LLM-Only Test Set\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING LLM-ONLY TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# LLM-only translation function (simplified)\n",
        "\n",
        "def translate_with_llm_only(query_original, query_normalized):\n",
        "    \"\"\"\n",
        "    Direct LLM translation WITHOUT RAG retrieval\n",
        "    Only uses the LLM's knowledge\n",
        "    \"\"\"\n",
        "\n",
        "    # Simple prompt without retrieved examples\n",
        "    prompt = f\"\"\"You are an expert linguist specialized in Earlier Egyptian grammar and historical translation.\n",
        "\n",
        "Translate the following Earlier Egyptian transliteration into German.\n",
        "Use a conservative, grammar-based interpretation.\n",
        "Do not modernize meanings or add implied words.\n",
        "\n",
        "Egyptian Transliteration:\n",
        "{query_original}\n",
        "\n",
        "Output ONLY the German translation.\n",
        "Do not add explanations, comments, or alternative readings.\n",
        "\n",
        "German Translation:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist. Translate Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Clean the response\n",
        "            german_translation = llm_output.strip()\n",
        "            # Remove \"German Translation:\" prefix if present\n",
        "            german_translation = re.sub(r'^German Translation:\\s*', '', german_translation, flags=re.IGNORECASE)\n",
        "\n",
        "            return german_translation.strip()\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ LLM-only translation function ready!\")\n",
        "\n",
        "# Process LLM-only\n",
        "llm_only_results = []\n",
        "llm_only_failed = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} samples with LLM-only...\")\n",
        "\n",
        "for idx in tqdm(range(len(df_test)), desc=\"LLM-only translation\"):\n",
        "    try:\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        query_normalized = normalize_transliteration(query_original)\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        german_translation = translate_with_llm_only(query_original, query_normalized)\n",
        "\n",
        "        if german_translation:\n",
        "            english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "            if english_translation:\n",
        "                # Get reference English from RAG results\n",
        "                if idx < len(df_test_results):\n",
        "                    reference_english = df_test_results.iloc[idx]['reference_english']\n",
        "                else:\n",
        "                    reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "                llm_only_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german_llm': german_translation,\n",
        "                    'predicted_english_llm': english_translation\n",
        "                })\n",
        "            else:\n",
        "                llm_only_failed.append({'sample_id': idx, 'reason': 'English translation failed'})\n",
        "        else:\n",
        "            llm_only_failed.append({'sample_id': idx, 'reason': 'LLM translation failed'})\n",
        "\n",
        "    except Exception as e:\n",
        "        llm_only_failed.append({'sample_id': idx, 'reason': f'Exception: {str(e)}'})\n",
        "        continue\n",
        "\n",
        "df_llm_only = pd.DataFrame(llm_only_results)\n",
        "\n",
        "print(f\"\\n✅ LLM-only processing complete!\")\n",
        "print(f\"   Successful: {len(llm_only_results)}\")\n",
        "print(f\"   Failed: {len(llm_only_failed)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "39aff42a1e1b4f21a37cba5381de92eb",
            "f92bb13c75fc473dbd41ff1b1f7f2bac",
            "5ca2533e339041a096a45f927f30527e",
            "2ae4fe4f0b7c4f298af39b92ebe4dd2a",
            "b880c832f55a461dbd8a7ecd33695f2f",
            "c594116772a84ab1b083a34374500352",
            "7ec9f0ee155e4347b9d962a679017ecc",
            "374710c89c4948989e8b423fbc776240",
            "1c64358084cb43d3b47114d39f1b7d3e",
            "785c3d5263774df591c46a2ea95c8334",
            "1bca6ba1c2594d2faf94995da066e63d"
          ]
        },
        "id": "QvcfuygKLuSm",
        "outputId": "715a420d-5fef-4036-d2dd-08229055b7d4"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING LLM-ONLY TEST SET\n",
            "======================================================================\n",
            "✅ LLM-only translation function ready!\n",
            "\n",
            "🔄 Processing 25 samples with LLM-only...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LLM-only translation:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39aff42a1e1b4f21a37cba5381de92eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ LLM-only processing complete!\n",
            "   Successful: 25\n",
            "   Failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🏆 Part 26: Calculate Metrics for LLM-Only\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING METRICS FOR LLM-ONLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "llm_only_metrics = []\n",
        "\n",
        "print(f\"\\n🔄 Computing metrics for {len(df_llm_only)} LLM-only translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_llm_only.iterrows(), total=len(df_llm_only), desc=\"Computing LLM-only metrics\"):\n",
        "    reference = row['reference_english']\n",
        "    hypothesis = row['predicted_english_llm']\n",
        "\n",
        "    rouge_scores = calculate_rouge(reference, hypothesis)\n",
        "\n",
        "    # LLM-only has NO retrieval metrics (all 0)\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference, hypothesis),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference, hypothesis),\n",
        "        'chrf': calculate_chrf(reference, hypothesis),\n",
        "        'exact_match': calculate_exact_match(reference, hypothesis),\n",
        "        'word_overlap': calculate_word_overlap(reference, hypothesis),\n",
        "        # Retrieval metrics = 0 (no retrieval)\n",
        "        'recall@1': 0.0,\n",
        "        'recall@3': 0.0,\n",
        "        'recall@5': 0.0,\n",
        "        'recall@10': 0.0,\n",
        "        'recall@20': 0.0,\n",
        "        'mrr': 0.0,\n",
        "        'avg_retrieval_score': 0.0\n",
        "    }\n",
        "\n",
        "    llm_only_metrics.append(metrics)\n",
        "\n",
        "df_llm_only_metrics = pd.DataFrame(llm_only_metrics)\n",
        "\n",
        "print(\"✅ LLM-only metrics calculation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "6fd8ef9932b54a1a9f16282facfc14c7",
            "ce50e51071a64943905f6dfceb3a82c6",
            "4fcd51d78d904125bf2ca1afa42249eb",
            "74483e11128b403fb172b3e70282a4f7",
            "7dab95e55cd647b6a6d35bfd06db097d",
            "cfdf71a8bd7a4dd6bda3c8699c9b009b",
            "17dc8c86cf494479b25a71f5dd8a0d77",
            "b417d5533f7846fda6d8a29c4382394a",
            "26bd0886a44e4e80a0900d9bebe7ca38",
            "7ffc220c5e0d43c28f92f9e6daa129c4",
            "a347de97d2e846139e30031fd908f51e"
          ]
        },
        "id": "i22O9ubtLu4N",
        "outputId": "69669b0b-e53a-47c4-f786-cdca62f90e0f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CALCULATING METRICS FOR LLM-ONLY\n",
            "======================================================================\n",
            "\n",
            "🔄 Computing metrics for 25 LLM-only translations...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing LLM-only metrics:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fd8ef9932b54a1a9f16282facfc14c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM-only metrics calculation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  Part 27: COMPREHENSIVE COMPARISON\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🆚 COMPREHENSIVE RAG vs LLM-ONLY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for LLM-only\n",
        "llm_only_averages = {\n",
        "    'BLEU': df_llm_only_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_llm_only_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_llm_only_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_llm_only_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_llm_only_metrics['meteor'].mean(),\n",
        "    'chrF': df_llm_only_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_llm_only_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_llm_only_metrics['word_overlap'].mean(),\n",
        "    'Recall@1': 0.0,\n",
        "    'Recall@3': 0.0,\n",
        "    'Recall@5': 0.0,\n",
        "    'Recall@10': 0.0,\n",
        "    'Recall@20': 0.0,\n",
        "    'MRR': 0.0,\n",
        "    'Avg Retrieval Score': 0.0\n",
        "}\n",
        "\n",
        "print(\"\\n📊 COMPLETE METRICS COMPARISON:\")\n",
        "print(\"─\" * 100)\n",
        "print(f\"{'Metric':<25} {'RAG System':<15} {'LLM-Only':<15} {'Difference':<15} {'Winner':<15}\")\n",
        "print(\"─\" * 100)\n",
        "\n",
        "for metric in avg_metrics.keys():\n",
        "    rag_score = avg_metrics[metric]\n",
        "    llm_score = llm_only_averages[metric]\n",
        "    diff = rag_score - llm_score\n",
        "\n",
        "    if 'Recall' in metric or metric == 'MRR' or metric == 'Avg Retrieval Score':\n",
        "        winner = \"🏆 RAG (only)\" if diff > 0 else \"N/A\"\n",
        "    else:\n",
        "        winner = \"🏆 RAG\" if diff > 0 else \"🏆 LLM\" if diff < 0 else \"🤝 Tie\"\n",
        "\n",
        "    print(f\"{metric:<25} {rag_score:>6.2f}%        {llm_score:>6.2f}%        {diff:>+6.2f}%       {winner:<15}\")\n",
        "\n",
        "print(\"─\" * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe84ktPsLw8n",
        "outputId": "823749f4-4d1c-46cc-abb4-f9d87c202950"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🆚 COMPREHENSIVE RAG vs LLM-ONLY COMPARISON\n",
            "======================================================================\n",
            "\n",
            "📊 COMPLETE METRICS COMPARISON:\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Metric                    RAG System      LLM-Only        Difference      Winner         \n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "BLEU                       25.47%          2.55%        +22.92%       🏆 RAG          \n",
            "ROUGE-1                    51.22%         19.00%        +32.22%       🏆 RAG          \n",
            "ROUGE-2                    35.23%          5.26%        +29.97%       🏆 RAG          \n",
            "ROUGE-L                    49.76%         17.25%        +32.51%       🏆 RAG          \n",
            "METEOR                     40.05%         10.32%        +29.74%       🏆 RAG          \n",
            "chrF                       45.58%         15.29%        +30.29%       🏆 RAG          \n",
            "Exact Match                 4.00%          0.00%         +4.00%       🏆 RAG          \n",
            "Word Overlap               40.80%         16.80%        +24.00%       🏆 RAG          \n",
            "Recall@1                    0.00%          0.00%         +0.00%       N/A            \n",
            "Recall@3                    0.00%          0.00%         +0.00%       N/A            \n",
            "Recall@5                    0.00%          0.00%         +0.00%       N/A            \n",
            "Recall@10                   0.00%          0.00%         +0.00%       N/A            \n",
            "Recall@20                   0.00%          0.00%         +0.00%       N/A            \n",
            "MRR                         0.00%          0.00%         +0.00%       N/A            \n",
            "Avg Retrieval Score         3.06%          0.00%         +3.06%       🏆 RAG (only)   \n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 29: Detailed Comparison Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 DETAILED COMPARISON ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Statistical comparison\n",
        "comparison_stats = []\n",
        "\n",
        "for metric_col in ['bleu', 'rouge1', 'meteor', 'chrf', 'recall@10', 'mrr']:\n",
        "    rag_scores = df_metrics[metric_col].values\n",
        "    llm_scores = df_llm_only_metrics[metric_col].values\n",
        "\n",
        "    stats = {\n",
        "        'Metric': metric_col.upper(),\n",
        "        'RAG_Mean': rag_scores.mean(),\n",
        "        'RAG_Median': np.median(rag_scores),\n",
        "        'RAG_Std': rag_scores.std(),\n",
        "        'LLM_Mean': llm_scores.mean(),\n",
        "        'LLM_Median': np.median(llm_scores),\n",
        "        'LLM_Std': llm_scores.std(),\n",
        "        'Mean_Diff': rag_scores.mean() - llm_scores.mean()\n",
        "    }\n",
        "\n",
        "    comparison_stats.append(stats)\n",
        "\n",
        "df_comparison_stats = pd.DataFrame(comparison_stats)\n",
        "\n",
        "print(\"\\n📊 Statistical Summary:\")\n",
        "print(\"─\" * 100)\n",
        "print(df_comparison_stats.to_string(index=False))\n",
        "print(\"─\" * 100)"
      ],
      "metadata": {
        "id": "kun4eiuSIfwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934c1473-a718-4d0c-87dc-12cc109c9cb2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 DETAILED COMPARISON ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "📊 Statistical Summary:\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "   Metric  RAG_Mean  RAG_Median   RAG_Std  LLM_Mean  LLM_Median   LLM_Std  Mean_Diff\n",
            "     BLEU 25.474183    8.839449 30.175759  2.552323    1.888980  2.665147  22.921861\n",
            "   ROUGE1 51.224286   50.000000 29.189863 19.004810   17.391304 12.678676  32.219476\n",
            "   METEOR 40.053982   34.307065 29.262594 10.317260    8.620690  8.129328  29.736722\n",
            "     CHRF 45.580489   37.711307 29.377861 15.285760   15.007055  6.607843  30.294729\n",
            "RECALL@10  0.000000    0.000000  0.000000  0.000000    0.000000  0.000000   0.000000\n",
            "      MRR  0.000000    0.000000  0.000000  0.000000    0.000000  0.000000   0.000000\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 30: Win/Loss Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🏆 SAMPLE-BY-SAMPLE WIN/LOSS ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "for metric in ['bleu', 'meteor', 'chrf']:\n",
        "    metric_wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "    for i in range(min(len(df_metrics), len(df_llm_only_metrics))):\n",
        "        rag_score = df_metrics.iloc[i][metric]\n",
        "        llm_score = df_llm_only_metrics.iloc[i][metric]\n",
        "\n",
        "        if rag_score > llm_score:\n",
        "            metric_wins['RAG'] += 1\n",
        "            wins['RAG'] += 1\n",
        "        elif llm_score > rag_score:\n",
        "            metric_wins['LLM'] += 1\n",
        "            wins['LLM'] += 1\n",
        "        else:\n",
        "            metric_wins['Tie'] += 1\n",
        "            wins['Tie'] += 1\n",
        "\n",
        "    total = sum(metric_wins.values())\n",
        "    print(f\"\\n{metric.upper()} Wins:\")\n",
        "    print(f\"  RAG:      {metric_wins['RAG']:3d} ({metric_wins['RAG']/total*100:5.1f}%)\")\n",
        "    print(f\"  LLM-Only: {metric_wins['LLM']:3d} ({metric_wins['LLM']/total*100:5.1f}%)\")\n",
        "    print(f\"  Tie:      {metric_wins['Tie']:3d} ({metric_wins['Tie']/total*100:5.1f}%)\")\n",
        "\n",
        "total_comparisons = sum(wins.values())\n",
        "print(f\"\\n{'─' * 70}\")\n",
        "print(f\"Overall Wins (across all metrics):\")\n",
        "print(f\"  🏆 RAG:      {wins['RAG']:3d} ({wins['RAG']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🏆 LLM-Only: {wins['LLM']:3d} ({wins['LLM']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🤝 Tie:      {wins['Tie']:3d} ({wins['Tie']/total_comparisons*100:5.1f}%)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "## 💾 Part 32: Save All Results\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"💾 SAVING ALL RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save RAG comprehensive results\n",
        "df_test_results_full = df_test_results.copy()\n",
        "for metric in df_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_test_results_full[metric] = df_metrics[metric].values\n",
        "\n",
        "df_test_results_full.to_csv('rag_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ RAG comprehensive results saved to: rag_comprehensive_results.csv\")\n",
        "\n",
        "# Save LLM-only comprehensive results\n",
        "df_llm_only_full = df_llm_only.copy()\n",
        "for metric in df_llm_only_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_llm_only_full[metric] = df_llm_only_metrics[metric].values\n",
        "\n",
        "df_llm_only_full.to_csv('llm_only_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ LLM-only comprehensive results saved to: llm_only_comprehensive_results.csv\")\n",
        "\n",
        "# Save comparison summary\n",
        "comparison_summary = pd.DataFrame([\n",
        "    {'System': 'RAG', **{f'{k}': v for k, v in avg_metrics.items()}},\n",
        "    {'System': 'LLM-Only', **{f'{k}': v for k, v in llm_only_averages.items()}},\n",
        "    {'System': 'Difference (RAG - LLM)', **{f'{k}': avg_metrics[k] - llm_only_averages[k] for k in avg_metrics.keys()}}\n",
        "])\n",
        "\n",
        "comparison_summary.to_csv('complete_comparison_summary.csv', index=False)\n",
        "print(f\"✅ Comparison summary saved to: complete_comparison_summary.csv\")\n",
        "\n",
        "# Save statistical comparison\n",
        "df_comparison_stats.to_csv('comparison_statistics.csv', index=False)\n",
        "print(f\"✅ Statistics saved to: comparison_statistics.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "## ✅ Part 33: FINAL COMPREHENSIVE REPORT\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FINAL COMPREHENSIVE EVALUATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Determine overall winner\n",
        "rag_total = sum(avg_metrics.values())\n",
        "llm_total = sum(llm_only_averages.values())\n",
        "overall_winner = \"RAG System 🏆\" if rag_total > llm_total else \"LLM-Only 🏆\" if llm_total > rag_total else \"Tie 🤝\"\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 System Performance Summary:\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "RAG SYSTEM (Hybrid Search + LLM):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {avg_metrics['BLEU']:.2f}%\n",
        "  • METEOR:       {avg_metrics['METEOR']:.2f}%\n",
        "  • chrF:         {avg_metrics['chrF']:.2f}%\n",
        "  • ROUGE-1:      {avg_metrics['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {avg_metrics['Exact Match']:.2f}%\n",
        "\n",
        "Retrieval Quality:\n",
        "  • Recall@1:     {avg_metrics['Recall@1']:.2f}%\n",
        "  • Recall@10:    {avg_metrics['Recall@10']:.2f}%\n",
        "  • MRR:          {avg_metrics['MRR']:.2f}%\n",
        "  • Avg Score:    {avg_metrics['Avg Retrieval Score']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "LLM-ONLY (No RAG):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_llm_only_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {llm_only_averages['BLEU']:.2f}%\n",
        "  • METEOR:       {llm_only_averages['METEOR']:.2f}%\n",
        "  • chrF:         {llm_only_averages['chrF']:.2f}%\n",
        "  • ROUGE-1:      {llm_only_averages['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {llm_only_averages['Exact Match']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "COMPARISON RESULTS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "🏆 Overall Winner: {overall_winner}\n",
        "\n",
        "Translation Improvement (RAG - LLM):\n",
        "  • BLEU:    {avg_metrics['BLEU'] - llm_only_averages['BLEU']:+.2f}%\n",
        "  • METEOR:  {avg_metrics['METEOR'] - llm_only_averages['METEOR']:+.2f}%\n",
        "  • chrF:    {avg_metrics['chrF'] - llm_only_averages['chrF']:+.2f}%\n",
        "\n",
        "Sample-wise Wins:\n",
        "  • RAG wins:      {wins['RAG']} ({wins['RAG']/total_comparisons*100:.1f}%)\n",
        "  • LLM-only wins: {wins['LLM']} ({wins['LLM']/total_comparisons*100:.1f}%)\n",
        "\n",
        "Retrieval Effectiveness:\n",
        "  • Recall@10:     {avg_metrics['Recall@10']:.1f}% (RAG finds relevant in top 10)\n",
        "  • MRR:           {avg_metrics['MRR']:.1f}% (Average rank quality)\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "CONCLUSIONS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "{\"✅ The RAG system significantly outperforms LLM-only approach.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] + 5 else\n",
        " \"🟡 The RAG system shows moderate improvement over LLM-only.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] else\n",
        " \"❌ The LLM-only approach performs comparably or better than RAG.\"}\n",
        "\n",
        "{\"✅ Retrieval quality is good (Recall@10 > 40%).\" if avg_metrics['Recall@10'] > 40 else\n",
        " \"🟡 Retrieval quality is moderate (Recall@10 20-40%).\" if avg_metrics['Recall@10'] > 20 else\n",
        " \"❌ Retrieval quality needs improvement (Recall@10 < 20%).\"}\n",
        "\n",
        "📁 Output Files:\n",
        "1. rag_comprehensive_results.csv - RAG results with all metrics\n",
        "2. llm_only_comprehensive_results.csv - LLM-only results with all metrics\n",
        "3. complete_comparison_summary.csv - Full comparison table\n",
        "4. comparison_statistics.csv - Detailed statistical analysis\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\\n🎉 Complete evaluation finished!\")\n",
        "print(\"=\"*70 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT1lqUw3bNjR",
        "outputId": "10d1ea6d-92ca-49b3-edda-882c7129a343"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🏆 SAMPLE-BY-SAMPLE WIN/LOSS ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "BLEU Wins:\n",
            "  RAG:       19 ( 76.0%)\n",
            "  LLM-Only:   4 ( 16.0%)\n",
            "  Tie:        2 (  8.0%)\n",
            "\n",
            "METEOR Wins:\n",
            "  RAG:       22 ( 88.0%)\n",
            "  LLM-Only:   1 (  4.0%)\n",
            "  Tie:        2 (  8.0%)\n",
            "\n",
            "CHRF Wins:\n",
            "  RAG:       21 ( 84.0%)\n",
            "  LLM-Only:   4 ( 16.0%)\n",
            "  Tie:        0 (  0.0%)\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Overall Wins (across all metrics):\n",
            "  🏆 RAG:       62 ( 82.7%)\n",
            "  🏆 LLM-Only:   9 ( 12.0%)\n",
            "  🤝 Tie:        4 (  5.3%)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "💾 SAVING ALL RESULTS\n",
            "======================================================================\n",
            "✅ RAG comprehensive results saved to: rag_comprehensive_results.csv\n",
            "✅ LLM-only comprehensive results saved to: llm_only_comprehensive_results.csv\n",
            "✅ Comparison summary saved to: complete_comparison_summary.csv\n",
            "✅ Statistics saved to: comparison_statistics.csv\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "✅ FINAL COMPREHENSIVE EVALUATION REPORT\n",
            "======================================================================\n",
            "\n",
            "📊 System Performance Summary:\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "RAG SYSTEM (Hybrid Search + LLM):\n",
            "════════════════════════════════════════════════════════════════\n",
            "Total samples: 25\n",
            "\n",
            "Translation Quality:\n",
            "  • BLEU:         25.47%\n",
            "  • METEOR:       40.05%\n",
            "  • chrF:         45.58%\n",
            "  • ROUGE-1:      51.22%\n",
            "  • Exact Match:  4.00%\n",
            "\n",
            "Retrieval Quality:\n",
            "  • Recall@1:     0.00%\n",
            "  • Recall@10:    0.00%\n",
            "  • MRR:          0.00%\n",
            "  • Avg Score:    3.06%\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "LLM-ONLY (No RAG):\n",
            "════════════════════════════════════════════════════════════════\n",
            "Total samples: 25\n",
            "\n",
            "Translation Quality:\n",
            "  • BLEU:         2.55%\n",
            "  • METEOR:       10.32%\n",
            "  • chrF:         15.29%\n",
            "  • ROUGE-1:      19.00%\n",
            "  • Exact Match:  0.00%\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "COMPARISON RESULTS:\n",
            "════════════════════════════════════════════════════════════════\n",
            "🏆 Overall Winner: RAG System 🏆\n",
            "\n",
            "Translation Improvement (RAG - LLM):\n",
            "  • BLEU:    +22.92%\n",
            "  • METEOR:  +29.74%\n",
            "  • chrF:    +30.29%\n",
            "\n",
            "Sample-wise Wins:\n",
            "  • RAG wins:      62 (82.7%)\n",
            "  • LLM-only wins: 9 (12.0%)\n",
            "\n",
            "Retrieval Effectiveness:\n",
            "  • Recall@10:     0.0% (RAG finds relevant in top 10)\n",
            "  • MRR:           0.0% (Average rank quality)\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "CONCLUSIONS:\n",
            "════════════════════════════════════════════════════════════════\n",
            "✅ The RAG system significantly outperforms LLM-only approach.\n",
            "\n",
            "❌ Retrieval quality needs improvement (Recall@10 < 20%).\n",
            "\n",
            "📁 Output Files:\n",
            "1. rag_comprehensive_results.csv - RAG results with all metrics\n",
            "2. llm_only_comprehensive_results.csv - LLM-only results with all metrics\n",
            "3. complete_comparison_summary.csv - Full comparison table\n",
            "4. comparison_statistics.csv - Detailed statistical analysis\n",
            "\n",
            "======================================================================\n",
            "\n",
            "🎉 Complete evaluation finished!\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B37-VkA6CfgZ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubLgDHADCfdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94A10PxvCfat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DU4XhRBlCfYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijuTBOBgCfVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-q64xv_OCfS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qe0OXSHCCfQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}