{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3b6989dca5e416b9955750662c702e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f01cc3e2c20d44ffb1c840b60886e3fe",
              "IPY_MODEL_eb1e5fda90564bc2b85beebfe2dbdbbc",
              "IPY_MODEL_3db20383962f4d6ab55d74213247db22"
            ],
            "layout": "IPY_MODEL_487c5f3ae5c248db874482b4d86a2432"
          }
        },
        "f01cc3e2c20d44ffb1c840b60886e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7a37d0efbe446d8d59aa609852de1b",
            "placeholder": "​",
            "style": "IPY_MODEL_021ecf3105f3496a85c1253c14af1af0",
            "value": "Generating embeddings: 100%"
          }
        },
        "eb1e5fda90564bc2b85beebfe2dbdbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a084561b52d44b04af019d93d5dc9488",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ffef40e25b1402a807bbb5b72951ba9",
            "value": 282
          }
        },
        "3db20383962f4d6ab55d74213247db22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466d54b2c7004bb689bd3fe2ee4152fd",
            "placeholder": "​",
            "style": "IPY_MODEL_af10eaa6c1824215ae2bcf4eae96ec16",
            "value": " 282/282 [01:56&lt;00:00,  2.61it/s]"
          }
        },
        "487c5f3ae5c248db874482b4d86a2432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7a37d0efbe446d8d59aa609852de1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "021ecf3105f3496a85c1253c14af1af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a084561b52d44b04af019d93d5dc9488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ffef40e25b1402a807bbb5b72951ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "466d54b2c7004bb689bd3fe2ee4152fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af10eaa6c1824215ae2bcf4eae96ec16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb5c08f82334a54b6c11971a7526412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d264d55554484b2e9768844784d3cd0f",
              "IPY_MODEL_444cd42ddebd4cdda4f0926c02b8670f",
              "IPY_MODEL_e5ec106e6fc74e53baf07b54c02aed0f"
            ],
            "layout": "IPY_MODEL_7932e3693ff04f6981757dfc889f1bf0"
          }
        },
        "d264d55554484b2e9768844784d3cd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3dfee5e4d5466fb1585a5fb389ddd9",
            "placeholder": "​",
            "style": "IPY_MODEL_a78bdce8eb494264bdc34ab3754ab855",
            "value": "Preparing points: 100%"
          }
        },
        "444cd42ddebd4cdda4f0926c02b8670f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c22741b96d64886ac3adc6205718c3a",
            "max": 8997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c99e5cd21d884f77913f4c98b3ba63db",
            "value": 8997
          }
        },
        "e5ec106e6fc74e53baf07b54c02aed0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f2fc3e7883452b85b453f9d967f995",
            "placeholder": "​",
            "style": "IPY_MODEL_1dff3f4a48454232b244650b8e574e0c",
            "value": " 8997/8997 [00:01&lt;00:00, 2493.95it/s]"
          }
        },
        "7932e3693ff04f6981757dfc889f1bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3dfee5e4d5466fb1585a5fb389ddd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78bdce8eb494264bdc34ab3754ab855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c22741b96d64886ac3adc6205718c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99e5cd21d884f77913f4c98b3ba63db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33f2fc3e7883452b85b453f9d967f995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dff3f4a48454232b244650b8e574e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9ad6cebd9624220a74fb75b2d3783eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed1fbce44d24fbda359cea095835647",
              "IPY_MODEL_81882a602b074b40a5dac06243f0b291",
              "IPY_MODEL_025bfd85c9904d12ab432313f00474bd"
            ],
            "layout": "IPY_MODEL_c6ed428c30c440dc9e32259dbf5c0381"
          }
        },
        "2ed1fbce44d24fbda359cea095835647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac022b3924f48468059c20db1503810",
            "placeholder": "​",
            "style": "IPY_MODEL_8fdb623193aa43a39b6062cfcca8ac40",
            "value": "Uploading batches: 100%"
          }
        },
        "81882a602b074b40a5dac06243f0b291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbff18ec9ce46a993628ab15e117192",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d378f558d16d47189aad5a6c13cd285e",
            "value": 90
          }
        },
        "025bfd85c9904d12ab432313f00474bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fc6ebb9a4d24153b7f92cdfc4747c5e",
            "placeholder": "​",
            "style": "IPY_MODEL_3ab5bb58399b49ce9d47d5f2eb128593",
            "value": " 90/90 [00:08&lt;00:00, 13.38it/s]"
          }
        },
        "c6ed428c30c440dc9e32259dbf5c0381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac022b3924f48468059c20db1503810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fdb623193aa43a39b6062cfcca8ac40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbff18ec9ce46a993628ab15e117192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d378f558d16d47189aad5a6c13cd285e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fc6ebb9a4d24153b7f92cdfc4747c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab5bb58399b49ce9d47d5f2eb128593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f2a80b2760942b285c45c11a53e7570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5525fa234ecc41fea6be00d4356d332c",
              "IPY_MODEL_a5a26da884ac40fabb6c494e76ce852b",
              "IPY_MODEL_baeb4497d5114da3a450404f057ad6ce"
            ],
            "layout": "IPY_MODEL_6888a4ebc9754312974e8b4e3a30319f"
          }
        },
        "5525fa234ecc41fea6be00d4356d332c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaee7f5d2d3d45d2a7705e6816f00b75",
            "placeholder": "​",
            "style": "IPY_MODEL_9381aeb2923247f28bee4542e75e5037",
            "value": "Translating: 100%"
          }
        },
        "a5a26da884ac40fabb6c494e76ce852b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a623991c5b74a239580be2ce050240b",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee2f03e9e17948f598b38ce81b21f778",
            "value": 10
          }
        },
        "baeb4497d5114da3a450404f057ad6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a880618972b8418f90624c47297aaaab",
            "placeholder": "​",
            "style": "IPY_MODEL_bef7b7b21c054670b5662ded63ffa53f",
            "value": " 10/10 [02:34&lt;00:00, 14.42s/it]"
          }
        },
        "6888a4ebc9754312974e8b4e3a30319f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaee7f5d2d3d45d2a7705e6816f00b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9381aeb2923247f28bee4542e75e5037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a623991c5b74a239580be2ce050240b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2f03e9e17948f598b38ce81b21f778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a880618972b8418f90624c47297aaaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef7b7b21c054670b5662ded63ffa53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8616b1b21c3a40e9b249df6d7396f6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b8095d0486040e5ad7f9dfd8ef37d7f",
              "IPY_MODEL_dfd1b50a9b674d849c171165c552d598",
              "IPY_MODEL_093791a24ae54f50bfc0820f34f814a5"
            ],
            "layout": "IPY_MODEL_c5110e587ee34cb5b3832d9d8041ceac"
          }
        },
        "7b8095d0486040e5ad7f9dfd8ef37d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02deebd78dd042299bdd5c88d7319aa6",
            "placeholder": "​",
            "style": "IPY_MODEL_0cbd59fbe393470b8bf743725c84e394",
            "value": "RAG Translation: 100%"
          }
        },
        "dfd1b50a9b674d849c171165c552d598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792be0f0d10643b892c7aae53e554fda",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_839db4c3c1e14e45a609684bb7469acb",
            "value": 25
          }
        },
        "093791a24ae54f50bfc0820f34f814a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71afe4d6858341c2b25aaf804a9e0ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_eddbe8b1ea2b42e4963df08942061b2b",
            "value": " 25/25 [02:12&lt;00:00,  3.89s/it]"
          }
        },
        "c5110e587ee34cb5b3832d9d8041ceac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02deebd78dd042299bdd5c88d7319aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbd59fbe393470b8bf743725c84e394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "792be0f0d10643b892c7aae53e554fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839db4c3c1e14e45a609684bb7469acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71afe4d6858341c2b25aaf804a9e0ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddbe8b1ea2b42e4963df08942061b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68f66511c4ec490c94a1d5bb04620037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd5e0988c67143538b9b0a5b6aea7430",
              "IPY_MODEL_4841b8489f2b48d4a576cb679b7498c4",
              "IPY_MODEL_8ec5b2aa08f34116a15be7fd5c316b8d"
            ],
            "layout": "IPY_MODEL_1eb13f6171054493b28182986df9c4cc"
          }
        },
        "cd5e0988c67143538b9b0a5b6aea7430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a5fc998d154c898541fb07fdbf4bb9",
            "placeholder": "​",
            "style": "IPY_MODEL_b41adf3a9232499e830c93cd9de4a62c",
            "value": "Computing all metrics: 100%"
          }
        },
        "4841b8489f2b48d4a576cb679b7498c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f2f8900f7444cc68ff0ce593eed3d01",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b69361af3ab44ea2b2ca843f2c54ab63",
            "value": 25
          }
        },
        "8ec5b2aa08f34116a15be7fd5c316b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d27bcb051af42f596a8a60539bf8951",
            "placeholder": "​",
            "style": "IPY_MODEL_68d0d855712e46dca14cc9a22e7b64be",
            "value": " 25/25 [00:00&lt;00:00, 501.09it/s]"
          }
        },
        "1eb13f6171054493b28182986df9c4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a5fc998d154c898541fb07fdbf4bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b41adf3a9232499e830c93cd9de4a62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2f8900f7444cc68ff0ce593eed3d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69361af3ab44ea2b2ca843f2c54ab63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d27bcb051af42f596a8a60539bf8951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d0d855712e46dca14cc9a22e7b64be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be022938b0294e34919ccebd8a379295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d3eef03dd7d4e79a5fa490a1f9f013c",
              "IPY_MODEL_21aad9a111b94a5cb443b2ffcd2ffb81",
              "IPY_MODEL_162ab04d99ee4278a8813943b98828fa"
            ],
            "layout": "IPY_MODEL_a58c2fce18614150b1a15f291aaa2a17"
          }
        },
        "9d3eef03dd7d4e79a5fa490a1f9f013c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f39b660b0c4a69bce096a58bfc244d",
            "placeholder": "​",
            "style": "IPY_MODEL_b068f3c100044f069cc0f780d28484ab",
            "value": "LLM-only translation:  24%"
          }
        },
        "21aad9a111b94a5cb443b2ffcd2ffb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847f359cbe214523806bc9d51565cff6",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2acab60bf9f147c38aafe4cb43a71bd7",
            "value": 6
          }
        },
        "162ab04d99ee4278a8813943b98828fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e854e517afea4003b92d9abf305435a3",
            "placeholder": "​",
            "style": "IPY_MODEL_27fe6efcdc7a41a8b68151a0fa17d89b",
            "value": " 6/25 [00:32&lt;01:53,  5.95s/it]"
          }
        },
        "a58c2fce18614150b1a15f291aaa2a17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f39b660b0c4a69bce096a58bfc244d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b068f3c100044f069cc0f780d28484ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847f359cbe214523806bc9d51565cff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acab60bf9f147c38aafe4cb43a71bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e854e517afea4003b92d9abf305435a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fe6efcdc7a41a8b68151a0fa17d89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🏛️ TLA Dataset Preparation for Egyptian Transliteration RAG System\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 1: Install & Import Libraries"
      ],
      "metadata": {
        "id": "G8IS7D22A4pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Upgrade pip first\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# 🔹 Core Dependencies\n",
        "!pip install datasets>=2.18.0 --quiet\n",
        "!pip install transformers>=4.38.0 --quiet\n",
        "!pip install torch>=2.2.0 --quiet\n",
        "!pip install pandas>=2.2.0 --quiet\n",
        "!pip install numpy>=1.26.0 --quiet\n",
        "\n",
        "# 🔹 Translation\n",
        "!pip install sentencepiece>=0.2.0 --quiet\n",
        "\n",
        "# 🔹 Vector Database\n",
        "!pip install qdrant-client>=1.7.0 --quiet\n",
        "\n",
        "# 🔹 Ollama Cloud API\n",
        "!pip install httpx>=0.25.2,<0.26.0 --quiet\n",
        "!pip install ollama>=0.1.7 --quiet\n",
        "\n",
        "# 🔹 BM25 for Hybrid Search\n",
        "!pip install rank-bm25>=0.2.2 --quiet\n",
        "\n",
        "# 🔹 Utilities\n",
        "!pip install tqdm>=4.66.0 --quiet\n",
        "!pip install python-dotenv>=1.0.0 --quiet\n",
        "!pip install jupyter>=1.0.0 --quiet\n",
        "!pip install ipywidgets>=8.1.0 --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install matplotlib --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install nltk==3.9.2 --quiet\n",
        "!pip install rouge-score==0.1.2 --quiet\n",
        "!pip install sacrebleu==2.6.0 --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQ2QDe-BFUS",
        "outputId": "518240b7-0e1f-4b28-d062-8640dd4287a9"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 0.26.0: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic6N9oFNBnES",
        "outputId": "f0c39c3c-7986-46a6-fb14-94bfc6eaf65e"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGQENGBIAMmK",
        "outputId": "26f5584d-bde8-4c4e-fbbf-a5bd5f08ae73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
        "import subprocess\n",
        "import json\n",
        "import ollama\n",
        "\n",
        "print(\"✅ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## configuration\n",
        "# Models\n",
        "EMBEDDING_MODEL = \"bge-m3:latest\"  # Ollama local\n",
        "\n",
        "# Settings\n",
        "VECTOR_DIM = 1024\n",
        "TRAIN_SPLIT = 0.99  # 95% for training, 5% for testing\n",
        "\n",
        "# Egyptian character mapping (uniliteral signs)\n",
        "EGYPTIAN_CHAR_MAP = {\n",
        "    # Traditional → Normalized\n",
        "    'ꜣ': 'a',      # vulture (aleph)\n",
        "    'ꞽ': 'i',      # reed (yodh)\n",
        "    'y': 'y',      # double yodh\n",
        "    'ꜥ': 'a',      # arm (ayin)\n",
        "    'w': 'w',      # quail\n",
        "    'b': 'b',      # leg\n",
        "    'p': 'p',      # stool\n",
        "    'f': 'f',      # viper\n",
        "    'm': 'm',      # owl\n",
        "    'n': 'n',      # water\n",
        "    'r': 'r',      # mouth\n",
        "    'h': 'h',      # shelter\n",
        "    'ḥ': 'h',      # wick\n",
        "    'ḫ': 'kh',     # placenta\n",
        "    'ẖ': 'kh',     # belly\n",
        "    's': 's',      # cloth\n",
        "    'š': 'sh',     # pool\n",
        "    'ḳ': 'q',      # hill\n",
        "    'q': 'q',      # hill\n",
        "    'k': 'k',      # basket\n",
        "    'g': 'g',      # stand\n",
        "    't': 't',      # bun\n",
        "    'ṯ': 'tj',     # rope\n",
        "    'd': 'd',      # hand\n",
        "    'ḏ': 'dj',     # cobra\n",
        "\n",
        "    # Additional special characters\n",
        "    'ṭ': 't',\n",
        "    'ḍ': 'd',\n",
        "    'ṣ': 's',\n",
        "    'ẓ': 'z',\n",
        "    'ḥ': 'h',\n",
        "}\n",
        "\n",
        "# Suffixes to remove (pronouns and particles)\n",
        "SUFFIXES_TO_REMOVE = [\n",
        "    '=f',   # his/him\n",
        "    '=k',   # your/you (masc)\n",
        "    '=ṯ',   # your/you (fem)\n",
        "    '=s',   # her/it\n",
        "    '=sn',  # their/them\n",
        "    '=ꞽ',   # my/me\n",
        "    '=n',   # our/us\n",
        "    '=tn',  # your/you (pl)\n",
        "    '=fꞽ',  # variant\n",
        "]\n",
        "\n",
        "print(f\"🔧 Configuration loaded\")\n",
        "print(f\"   Training split: {TRAIN_SPLIT*100}%\")\n",
        "print(f\"   Embedding model: {EMBEDDING_MODEL}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4dDTE0dAyUy",
        "outputId": "3ac1788b-12d0-453d-880d-6737357eb86f"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Configuration loaded\n",
            "   Training split: 99.0%\n",
            "   Embedding model: bge-m3:latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 3: Load dataset\n",
        "print(\"📥 Loading TLA dataset from HuggingFace...\")\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(f\"✅ Loaded {len(df)} records\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nSample record:\")\n",
        "print(df.iloc[0][['transliteration', 'translation', 'UPOS']].to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGgDrQdBuND",
        "outputId": "9bcfbb52-9e57-4a54-ab29-bd71f647e90c"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading TLA dataset from HuggingFace...\n",
            "✅ Loaded 12773 records\n",
            "\n",
            "Columns: ['hieroglyphs', 'transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'dateNotBefore', 'dateNotAfter']\n",
            "\n",
            "Sample record:\n",
            "{'transliteration': 'nḏ (w)di̯ r =s', 'translation': '(es) werde zerrieben, (es) werde darauf gelegt.', 'UPOS': 'VERB VERB ADP PRON'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 4 : Data Cleaning\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🧹 STEP 1: Removing unwanted columns\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Remove unwanted columns\n",
        "columns_to_drop = ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
        "df_clean = df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(f\"✅ Removed columns: {columns_to_drop}\")\n",
        "print(f\"   Remaining columns: {list(df_clean.columns)}\")\n",
        "\n",
        "# Remove rows with missing critical data\n",
        "print(\"\\n🧹 STEP 2: Removing rows with missing data\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.dropna(subset=['transliteration', 'translation'])\n",
        "df_clean = df_clean[df_clean['transliteration'].str.strip() != '']\n",
        "df_clean = df_clean[df_clean['translation'].str.strip() != '']\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} rows with missing data\")\n",
        "print(f\"   Records remaining: {len(df_clean)}\")\n",
        "\n",
        "# Remove duplicates\n",
        "print(\"\\n🧹 STEP 3: Removing duplicates\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.drop_duplicates(subset=['transliteration'], keep='first')\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} duplicate records\")\n",
        "print(f\"   Unique records: {len(df_clean)}\")\n",
        "\n",
        "df_clean = df_clean.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkwYUNi4BwPK",
        "outputId": "0c26d29f-d212-44e5-a6d9-5a37c57de938"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🧹 STEP 1: Removing unwanted columns\n",
            "======================================================================\n",
            "✅ Removed columns: ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
            "   Remaining columns: ['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation']\n",
            "\n",
            "🧹 STEP 2: Removing rows with missing data\n",
            "✅ Removed 0 rows with missing data\n",
            "   Records remaining: 12773\n",
            "\n",
            "🧹 STEP 3: Removing duplicates\n",
            "✅ Removed 3685 duplicate records\n",
            "   Unique records: 9088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 5: Transliteration Normalization\n",
        "def normalize_transliteration(text):\n",
        "    \"\"\"\n",
        "    Normalize Egyptian transliteration:\n",
        "    1. Remove brackets\n",
        "    2. Lowercase\n",
        "    3. Map special characters\n",
        "    4. Remove suffixes\n",
        "    5. Clean spaces\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == '':\n",
        "        return \"\"\n",
        "\n",
        "    # Step 1: Remove brackets (but keep content)\n",
        "    text = re.sub(r'[()]', '', text)\n",
        "\n",
        "    # Step 2: Normalize Unicode (NFC form)\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "    # REMOVE combining marks (important for di̯, etc.)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "\n",
        "    # Step 3: Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Step 4: Map Egyptian characters\n",
        "    for egy_char, normalized in EGYPTIAN_CHAR_MAP.items():\n",
        "        text = text.replace(egy_char.lower(), normalized)\n",
        "\n",
        "    # Step 5: Remove suffixes (pronouns/particles)\n",
        "    for suffix in SUFFIXES_TO_REMOVE:\n",
        "        # Match suffix at word boundaries or before spaces/dots\n",
        "        pattern = re.escape(suffix) + r'(?=[\\s\\.]|$)'\n",
        "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Step 6: Clean up extra spaces and dots\n",
        "    text = re.sub(r'\\.+', '.', text)  # Multiple dots to single\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces to single\n",
        "    text = text.strip('. ')  # Remove leading/trailing dots and spaces\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔤 STEP 4: Normalizing transliterations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test normalization on sample\n",
        "sample_text = df_clean.iloc[0]['transliteration']\n",
        "normalized_sample = normalize_transliteration(sample_text)\n",
        "\n",
        "print(f\"\\n📝 Sample normalization:\")\n",
        "print(f\"   Original:   {sample_text}\")\n",
        "print(f\"   Normalized: {normalized_sample}\")\n",
        "\n",
        "# Apply normalization to entire dataset\n",
        "print(f\"\\n🔄 Normalizing {len(df_clean)} transliterations...\")\n",
        "\n",
        "df_clean['transliteration_normalized'] = df_clean['transliteration'].apply(\n",
        "    normalize_transliteration\n",
        ")\n",
        "\n",
        "\n",
        "# Remove empty normalizations\n",
        "df_clean = df_clean[df_clean['transliteration_normalized'].str.len() > 0]\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Normalization complete!\")\n",
        "print(f\"   Valid records: {len(df_clean)}\")\n",
        "\n",
        "# Show more examples\n",
        "print(f\"\\n📋 Sample normalizations:\")\n",
        "for i in range(min(5, len(df_clean))):\n",
        "    orig = df_clean.iloc[i]['transliteration']\n",
        "    norm = df_clean.iloc[i]['transliteration_normalized']\n",
        "    print(f\"   {i+1}. {orig[:40]:40} → {norm[:40]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXrqavRoCKQ7",
        "outputId": "7801bd01-86f8-4224-e1f8-19c12f0d1c8e"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🔤 STEP 4: Normalizing transliterations\n",
            "======================================================================\n",
            "\n",
            "📝 Sample normalization:\n",
            "   Original:   nḏ (w)di̯ r =s\n",
            "   Normalized: ndj wdi r\n",
            "\n",
            "🔄 Normalizing 9088 transliterations...\n",
            "✅ Normalization complete!\n",
            "   Valid records: 9088\n",
            "\n",
            "📋 Sample normalizations:\n",
            "   1. nḏ (w)di̯ r =s                           → ndj wdi r\n",
            "   2. n ṯw ꞽm =sn                              → n tjw im\n",
            "   3. ḫꜣ m tʾ ḥnq.t kꜣ(.PL) ꜣpd(.PL) n ꞽmꜣḫ ꞽm → kha m tʾ hnq.t ka.pl apd.pl n imakh im.i\n",
            "   4. ꜥḥꜥ                                      → aha\n",
            "   5. (w)sꞽr wnꞽs m n =k ꞽr.t-ḥr.w ꞽꜥb n =k s( → wsir wnis m n ir.t-hr.w iab n si ir rʾ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 6: Train/ test split\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"📊 STEP 5: Creating train/test split ({TRAIN_SPLIT*100}%/{(1-TRAIN_SPLIT)*100}%)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Shuffle dataset\n",
        "df_clean = df_clean.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split\n",
        "split_idx = int(len(df_clean) * TRAIN_SPLIT)\n",
        "df_train = df_clean.iloc[:split_idx].copy()\n",
        "df_test = df_clean.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"✅ Split complete!\")\n",
        "print(f\"   Training set: {len(df_train)} records ({len(df_train)/len(df_clean)*100:.1f}%)\")\n",
        "print(f\"   Test set:     {len(df_test)} records ({len(df_test)/len(df_clean)*100:.1f}%)\")\n",
        "\n",
        "# Save test set for later evaluation\n",
        "df_test.to_csv('tla_test_set.csv', index=False)\n",
        "print(f\"\\n💾 Test set saved to: tla_test_set.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axmvNF_5CQqq",
        "outputId": "35203ff1-41d8-432e-b82c-72be4fe4c761"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 STEP 5: Creating train/test split (99.0%/1.0000000000000009%)\n",
            "======================================================================\n",
            "✅ Split complete!\n",
            "   Training set: 8997 records (99.0%)\n",
            "   Test set:     91 records (1.0%)\n",
            "\n",
            "💾 Test set saved to: tla_test_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 7: Generate Embedding\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"\\n📥 Loading embedding model...\")\n",
        "# Load model (do this ONCE before the loop)\n",
        "embedding_model = SentenceTransformer('BAAI/bge-m3')\n",
        "print(f\"✅ Model loaded: BAAI/bge-m3\")\n",
        "\n",
        "def get_embedding_fast(text):\n",
        "    \"\"\"Generate embedding using sentence-transformers\"\"\"\n",
        "    try:\n",
        "        # Generate embedding\n",
        "        embedding = embedding_model.encode(text, normalize_embeddings=True)\n",
        "        return embedding.tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return np.random.randn(VECTOR_DIM).tolist()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"🔢 STEP 6: Generating embeddings for {len(df_train)} records\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n⚙️ Using model: BAAI/bge-m3\")\n",
        "print(f\"   Vector dimension: {VECTOR_DIM}\")\n",
        "\n",
        "# Generate embeddings in batches (MUCH faster!)\n",
        "batch_size = 32\n",
        "all_embeddings = []\n",
        "\n",
        "for i in tqdm(range(0, len(df_train), batch_size), desc=\"Generating embeddings\"):\n",
        "    batch_end = min(i + batch_size, len(df_train))\n",
        "    batch_texts = df_train.iloc[i:batch_end]['transliteration_normalized'].tolist()\n",
        "\n",
        "    try:\n",
        "        # Process entire batch at once (FAST!)\n",
        "        batch_embeddings = embedding_model.encode(\n",
        "            batch_texts,\n",
        "            normalize_embeddings=True,\n",
        "            show_progress_bar=False\n",
        "        )\n",
        "        all_embeddings.extend(batch_embeddings.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Batch error at {i}: {e}\")\n",
        "        # Fallback: process individually\n",
        "        for text in batch_texts:\n",
        "            all_embeddings.append(get_embedding_fast(text))\n",
        "\n",
        "df_train['embedding'] = all_embeddings\n",
        "\n",
        "print(f\"\\n✅ Embedding generation complete!\")\n",
        "print(f\"   Total: {len(all_embeddings)} embeddings\")\n",
        "print(f\"   Dimension: {len(all_embeddings[0])}\")\n",
        "\n",
        "# Verify\n",
        "sample_embedding = all_embeddings[0]\n",
        "print(f\"\\n📊 Sample embedding (first 10 values):\")\n",
        "print(f\"   {sample_embedding[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "e3b6989dca5e416b9955750662c702e4",
            "f01cc3e2c20d44ffb1c840b60886e3fe",
            "eb1e5fda90564bc2b85beebfe2dbdbbc",
            "3db20383962f4d6ab55d74213247db22",
            "487c5f3ae5c248db874482b4d86a2432",
            "1a7a37d0efbe446d8d59aa609852de1b",
            "021ecf3105f3496a85c1253c14af1af0",
            "a084561b52d44b04af019d93d5dc9488",
            "0ffef40e25b1402a807bbb5b72951ba9",
            "466d54b2c7004bb689bd3fe2ee4152fd",
            "af10eaa6c1824215ae2bcf4eae96ec16"
          ]
        },
        "id": "GxC1-gvOCXVI",
        "outputId": "4637d167-1010-4f11-f15a-d17445cdcf56"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📥 Loading embedding model...\n",
            "✅ Model loaded: BAAI/bge-m3\n",
            "\n",
            "======================================================================\n",
            "🔢 STEP 6: Generating embeddings for 8997 records\n",
            "======================================================================\n",
            "\n",
            "⚙️ Using model: BAAI/bge-m3\n",
            "   Vector dimension: 1024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b6989dca5e416b9955750662c702e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Embedding generation complete!\n",
            "   Total: 8997 embeddings\n",
            "   Dimension: 1024\n",
            "\n",
            "📊 Sample embedding (first 10 values):\n",
            "   [0.009475680999457836, 0.012296928092837334, -0.03066054731607437, 0.0029091022443026304, -0.038571588695049286, -0.0011071120388805866, -0.002732239430770278, -0.013377217575907707, 0.02956884168088436, -0.00481629790738225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 8: Exract Lemmas from Lemmettizaton\n",
        "\n",
        "def extract_lemmas(lemmatization_text):\n",
        "    \"\"\"Extract lemma words from lemmatization field\"\"\"\n",
        "    if not isinstance(lemmatization_text, str):\n",
        "        return []\n",
        "\n",
        "    lemmas = []\n",
        "    parts = lemmatization_text.split()\n",
        "\n",
        "    for part in parts:\n",
        "        if '|' in part:\n",
        "            lemma_id, lemma_word = part.split('|', 1)\n",
        "            # Skip suffixes/particles\n",
        "            if not lemma_word.startswith('='):\n",
        "                lemmas.append(lemma_word)\n",
        "\n",
        "    return lemmas\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📝 STEP 7: Extracting lemmas\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_train['lemmas'] = df_train['lemmatization'].apply(extract_lemmas)\n",
        "\n",
        "print(f\"✅ Lemma extraction complete!\")\n",
        "print(f\"\\n📋 Sample lemmas:\")\n",
        "for i in range(min(3, len(df_train))):\n",
        "    lemmas = df_train.iloc[i]['lemmas']\n",
        "    print(f\"   {i+1}. {lemmas[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_10wqplYVZzG",
        "outputId": "feffc4de-b1d5-466e-c26c-08307d5a7c4b"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📝 STEP 7: Extracting lemmas\n",
            "======================================================================\n",
            "✅ Lemma extraction complete!\n",
            "\n",
            "📋 Sample lemmas:\n",
            "   1. ['ḥm-nṯr-Ḫwi̯=f-wꞽ', 'ḥr.ꞽ-sštꜣ']\n",
            "   2. ['zꜣ', 'sms.w', 'ꞽm.ꞽ-rʾ-zẖꜣ.ww-ꜥ-n-nswt', 'Sšm-nfr']\n",
            "   3. ['zbi̯', 'ṯw', 'm', 'ꜥḥꜥ.w', 'nfr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 9: Setup Qdrant Vector Database\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Setting up Qdrant database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize Qdrant (in-memory for development)\n",
        "# For production, use: QdrantClient(host=\"localhost\", port=6333)\n",
        "\n",
        "# Initialize persistent Qdrant (local)\n",
        "#qdrant = QdrantClient(path=\"qdrant_db\")\n",
        "\n",
        "# Initialize Qdrant (in-memory for development)\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"✅ Qdrant client initialized (in-memory)\")\n",
        "\n",
        "# Create collection\n",
        "collection_name = \"egyptian_transliterations\"\n",
        "\n",
        "qdrant.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(\n",
        "        size=VECTOR_DIM,\n",
        "        distance=Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"✅ Collection created: {collection_name}\")\n",
        "print(f\"   Vector size: {VECTOR_DIM}\")\n",
        "print(f\"   Distance metric: COSINE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UG3AUbNCdQf",
        "outputId": "a5b11744-b5d3-45f6-f9a2-a867107f03ba"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Setting up Qdrant database\n",
            "======================================================================\n",
            "✅ Qdrant client initialized (in-memory)\n",
            "✅ Collection created: egyptian_transliterations\n",
            "   Vector size: 1024\n",
            "   Distance metric: COSINE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 10: upload data to qdrant\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\" Uploading {len(df_train)} records to Qdrant\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare points\n",
        "points = []\n",
        "\n",
        "for idx, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Preparing points\"):\n",
        "    point = PointStruct(\n",
        "        id=idx,\n",
        "        vector=row['embedding'],\n",
        "        payload={\n",
        "            \"transliteration_original\": row['transliteration'],\n",
        "            \"transliteration_normalized\": row['transliteration_normalized'],\n",
        "            \"lemmas\": row['lemmas'],\n",
        "            \"UPOS\": row.get('UPOS', ''),\n",
        "            \"glossing\": row.get('glossing', ''),\n",
        "            \"translation_de\": row['translation']\n",
        "        }\n",
        "    )\n",
        "    points.append(point)\n",
        "\n",
        "# Upload in batches\n",
        "batch_size = 100\n",
        "print(f\"\\n📦 Uploading in batches of {batch_size}...\")\n",
        "\n",
        "for i in tqdm(range(0, len(points), batch_size), desc=\"Uploading batches\"):\n",
        "    batch = points[i:i+batch_size]\n",
        "    qdrant.upsert(\n",
        "        collection_name=collection_name,\n",
        "        points=batch\n",
        "    )\n",
        "\n",
        "print(f\"\\n✅ Upload complete!\")\n",
        "print(f\"   Total records in database: {len(points)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "efb5c08f82334a54b6c11971a7526412",
            "d264d55554484b2e9768844784d3cd0f",
            "444cd42ddebd4cdda4f0926c02b8670f",
            "e5ec106e6fc74e53baf07b54c02aed0f",
            "7932e3693ff04f6981757dfc889f1bf0",
            "0d3dfee5e4d5466fb1585a5fb389ddd9",
            "a78bdce8eb494264bdc34ab3754ab855",
            "1c22741b96d64886ac3adc6205718c3a",
            "c99e5cd21d884f77913f4c98b3ba63db",
            "33f2fc3e7883452b85b453f9d967f995",
            "1dff3f4a48454232b244650b8e574e0c",
            "f9ad6cebd9624220a74fb75b2d3783eb",
            "2ed1fbce44d24fbda359cea095835647",
            "81882a602b074b40a5dac06243f0b291",
            "025bfd85c9904d12ab432313f00474bd",
            "c6ed428c30c440dc9e32259dbf5c0381",
            "cac022b3924f48468059c20db1503810",
            "8fdb623193aa43a39b6062cfcca8ac40",
            "bcbff18ec9ce46a993628ab15e117192",
            "d378f558d16d47189aad5a6c13cd285e",
            "5fc6ebb9a4d24153b7f92cdfc4747c5e",
            "3ab5bb58399b49ce9d47d5f2eb128593"
          ]
        },
        "id": "KX1tF45TCoj4",
        "outputId": "3d060643-6e26-4477-feee-7a5656ac821f"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Uploading 8997 records to Qdrant\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preparing points:   0%|          | 0/8997 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efb5c08f82334a54b6c11971a7526412"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Uploading in batches of 100...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading batches:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9ad6cebd9624220a74fb75b2d3783eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Upload complete!\n",
            "   Total records in database: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 11 : verify Database\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ STEP 10: Verifying database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "count_info = qdrant.count(\n",
        "    collection_name=collection_name,\n",
        "    exact=True\n",
        ")\n",
        "\n",
        "print(f\"📊 Collection statistics:\")\n",
        "print(f\"   Name: {collection_name}\")\n",
        "print(f\"   Points count: {count_info.count}\")\n",
        "\n",
        "# Test search\n",
        "print(f\"\\n🔍 Testing search functionality...\")\n",
        "\n",
        "test_query = df_train.iloc[0]['transliteration_normalized']\n",
        "test_embedding = df_train.iloc[0]['embedding']\n",
        "\n",
        "search_results = qdrant.query_points(\n",
        "    collection_name=collection_name,\n",
        "    query=test_embedding,\n",
        "    limit=3\n",
        ").points\n",
        "\n",
        "print(f\"\\n📝 Test query: {test_query}\")\n",
        "print(f\"\\n🎯 Top 3 search results:\")\n",
        "\n",
        "for i, result in enumerate(search_results, 1):\n",
        "    print(f\"\\n   {i}. Score: {result.score:.4f}\")\n",
        "    print(f\"      Transliteration: {result.payload['transliteration_normalized']}\")\n",
        "    print(f\"      Translation: {result.payload['translation_de'][:60]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMuTNW6qCulU",
        "outputId": "7a192aeb-2c6e-4ea7-e62c-3ba961d60ed8"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ STEP 10: Verifying database\n",
            "======================================================================\n",
            "📊 Collection statistics:\n",
            "   Name: egyptian_transliterations\n",
            "   Points count: 8997\n",
            "\n",
            "🔍 Testing search functionality...\n",
            "\n",
            "📝 Test query: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "\n",
            "🎯 Top 3 search results:\n",
            "\n",
            "   1. Score: 1.0000\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses....\n",
            "\n",
            "   2. Score: 0.9444\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta ka=i-n.i-nswt\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses Kai-ni-nisut....\n",
            "\n",
            "   3. Score: 0.8495\n",
            "      Transliteration: wt.i hr.i-sshta\n",
            "      Translation: Balsamierer, Hüter des Geheimnisses...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🔮 PART 2: RAG Translation Pipeline\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 12: Install Additional Libraries"
      ],
      "metadata": {
        "id": "yvZqYFT0C9I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load Ollama API Key securely from Colab Secrets\n",
        "OLLAMA_API_KEY = userdata.get('OLLAMA_API_KEY')\n",
        "\n",
        "if OLLAMA_API_KEY is None:\n",
        "    raise ValueError(\"❌ OLLAMA_API_KEY not found in Colab Secrets\")\n",
        "\n",
        "# Set env var for libraries that expect it\n",
        "os.environ['OLLAMA_API_KEY'] = OLLAMA_API_KEY\n",
        "\n",
        "# Configuration\n",
        "LLM_MODEL = \"qwen3-vl:235b-instruct-cloud\" #\"gpt-oss:120b-cloud\" #\"qwen3-next:80b-cloud\" #\"qwen3-vl:235b-cloud\"\n",
        "TOP_K_RESULTS = 30\n",
        "\n",
        "print(\"🔧 RAG Pipeline Configuration:\")\n",
        "print(f\"   LLM Model: {LLM_MODEL}\")\n",
        "print(f\"   Top-K Results: {TOP_K_RESULTS}\")\n",
        "print(f\"   API Key: ✅ Loaded securely from Colab Secrets\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvesV_2PC5oN",
        "outputId": "544729d5-e88e-4818-d98b-e55cb4ce42c7"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 RAG Pipeline Configuration:\n",
            "   LLM Model: qwen3-vl:235b-instruct-cloud\n",
            "   Top-K Results: 30\n",
            "   API Key: ✅ Loaded securely from Colab Secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miYKvim1EuUN",
        "outputId": "c15e9992-f602-45ee-a599-46285458fb92"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank-bm25) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 14: prepare BM25 index for Sparce Search\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" Building BM25 index for sparse search\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Tokenize corpus for BM25\n",
        "corpus_texts = df_train['transliteration_normalized'].tolist()\n",
        "tokenized_corpus = [text.split() for text in corpus_texts]\n",
        "\n",
        "# Build BM25 index\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(f\"✅ BM25 index built!\")\n",
        "print(f\"   Documents indexed: {len(tokenized_corpus)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmx9860CDGEV",
        "outputId": "730b95a6-3eb2-4b61-94ed-add7610632f4"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Building BM25 index for sparse search\n",
            "======================================================================\n",
            "✅ BM25 index built!\n",
            "   Documents indexed: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 15: Hybrid Search Function\n",
        "def hybrid_search(query_text, query_embedding, top_k=10, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Perform hybrid search: Dense (Vector) + Sparse (BM25)\n",
        "\n",
        "    Args:\n",
        "        query_text: Normalized transliteration query\n",
        "        query_embedding: Embedding vector of query\n",
        "        top_k: Number of results to return\n",
        "        alpha: Weight for dense search (1-alpha for sparse)\n",
        "\n",
        "    Returns:\n",
        "        List of search results with scores\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Dense Search (Vector Similarity)\n",
        "    dense_results = qdrant.query_points(\n",
        "        collection_name=collection_name,\n",
        "        query=query_embedding,\n",
        "        limit=top_k * 2\n",
        "    ).points\n",
        "\n",
        "\n",
        "    # 2. Sparse Search (BM25)\n",
        "    query_tokens = query_text.split()\n",
        "    bm25_scores = bm25.get_scores(query_tokens)\n",
        "\n",
        "    # Get top BM25 indices\n",
        "    top_bm25_indices = np.argsort(bm25_scores)[-top_k*2:][::-1]\n",
        "\n",
        "    # 3. Reciprocal Rank Fusion (RRF)\n",
        "    combined_scores = {}\n",
        "\n",
        "    # Add dense scores\n",
        "    for rank, result in enumerate(dense_results):\n",
        "        doc_id = result.id\n",
        "        rrf_score = 1 / (rank + 60)  # RRF formula\n",
        "        combined_scores[doc_id] = {\n",
        "            'rrf_score': rrf_score,\n",
        "            'dense_score': result.score,\n",
        "            'sparse_score': 0,\n",
        "            'payload': result.payload\n",
        "        }\n",
        "\n",
        "    # Add sparse scores\n",
        "    for rank, idx in enumerate(top_bm25_indices):\n",
        "        if idx in combined_scores:\n",
        "            combined_scores[idx]['rrf_score'] += 1 / (rank + 60)\n",
        "            combined_scores[idx]['sparse_score'] = bm25_scores[idx]\n",
        "        else:\n",
        "            # Retrieve payload from Qdrant\n",
        "            point = qdrant.retrieve(\n",
        "                collection_name=collection_name,\n",
        "                ids=[int(idx)]\n",
        "            )\n",
        "            if point:\n",
        "                combined_scores[idx] = {\n",
        "                    'rrf_score': 1 / (rank + 60),\n",
        "                    'dense_score': 0,\n",
        "                    'sparse_score': bm25_scores[idx],\n",
        "                    'payload': point[0].payload\n",
        "                }\n",
        "\n",
        "    # 4. Sort by combined RRF score\n",
        "    sorted_results = sorted(\n",
        "        combined_scores.items(),\n",
        "        key=lambda x: x[1]['rrf_score'],\n",
        "        reverse=True\n",
        "    )[:top_k]\n",
        "\n",
        "    # 5. Format results\n",
        "    final_results = []\n",
        "    for doc_id, scores in sorted_results:\n",
        "        final_results.append({\n",
        "            'id': doc_id,\n",
        "            'rrf_score': scores['rrf_score'],\n",
        "            'dense_score': scores['dense_score'],\n",
        "            'sparse_score': scores['sparse_score'],\n",
        "            'payload': scores['payload']\n",
        "        })\n",
        "\n",
        "    return final_results\n",
        "\n",
        "print(\"✅ Hybrid search function ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fcxk7HDOIe",
        "outputId": "bb10f0bc-467d-48b2-c82f-ff6eca5629fb"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid search function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 16: LLM Translation Function\n",
        "import requests\n",
        "OLLAMA_API_URL = \"https://ollama.com/api/chat\"\n",
        "\n",
        "def translate_with_llm(query_original, query_normalized, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Use LLM to translate Egyptian to German based on retrieved examples\n",
        "    \"\"\"\n",
        "\n",
        "    # Build examples context (same as before)\n",
        "    examples_text = \"\"\n",
        "    for i, example in enumerate(retrieved_examples, 1):\n",
        "        payload = example['payload']\n",
        "        examples_text += f\"\"\"\n",
        "Example {i}:\n",
        "- Original: {payload['transliteration_original']}\n",
        "- Normalized: {payload['transliteration_normalized']}\n",
        "- Lemmas: {', '.join(payload['lemmas'][:5]) if payload['lemmas'] else 'N/A'}\n",
        "- POS Tags: {payload['UPOS']}\n",
        "- Glossing: {payload['glossing']}\n",
        "- German: {payload['translation_de']}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    # Build prompt (same as before)\n",
        "    prompt = f\"\"\"You are a senior linguist specializing in Earlier Egyptian (Old Egyptian & Early Middle Egyptian),\n",
        "with strong expertise in morphology, syntax, and historical semantics.\n",
        "\n",
        "Your task is to translate an Earlier Egyptian transliteration into German\n",
        "using retrieved linguistic examples ONLY as structural and semantic guidance.\n",
        "\n",
        "=====================================\n",
        "QUERY TO TRANSLATE\n",
        "=====================================\n",
        "\n",
        "Normalized Transliteration:\n",
        "{query_normalized}\n",
        "\n",
        "=====================================\n",
        "RETRIEVED DATABASE EXAMPLES\n",
        "=====================================\n",
        "{examples_text}\n",
        "\n",
        "=====================================\n",
        "INSTRUCTIONS\n",
        "=====================================\n",
        "Follow these steps carefully:\n",
        "\n",
        "1. Linguistic Analysis\n",
        "   - Identify the grammatical category of each word (verb, noun, particle, suffix, etc.)\n",
        "   - Detect verb tense/aspect, suffix pronouns, and syntactic order (VSO, SVO, nominal clause).\n",
        "\n",
        "2. Morphological Alignment\n",
        "   - Compare suffixes, verb forms, and particles with the retrieved examples.\n",
        "   - Use lemma meanings as semantic hints, not literal translations.\n",
        "\n",
        "3. Translation Construction\n",
        "   - Produce a fluent and historically plausible German translation.\n",
        "   - Adapt word order to correct German syntax.\n",
        "   - Prefer linguistically conservative interpretations over speculative ones.\n",
        "\n",
        "4. Uncertainty Handling\n",
        "   - If multiple readings are possible, choose the most likely one.\n",
        "   - Briefly mention ambiguity only if it materially affects meaning.\n",
        "\n",
        "=====================================\n",
        "STRICT RULES\n",
        "=====================================\n",
        "- DO NOT copy any German translation from the examples.\n",
        "- DO NOT mention example numbers or quote them.\n",
        "- DO NOT add explanations unless uncertainty exists.\n",
        "- DO NOT hallucinate missing words.\n",
        "- Base your output strictly on Earlier Egyptian grammar.\n",
        "\n",
        "=====================================\n",
        "OUTPUT FORMAT (STRICT)\n",
        "=====================================\n",
        "German Translation: <one clear German sentence>\n",
        "Confidence: High | Medium | Low\n",
        "Notes: <only if confidence is Medium or Low>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Call Ollama Cloud API with CORRECT endpoint\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        # Use Ollama's native format (not OpenAI format)\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist specializing in translating Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            # Ollama format uses 'message' -> 'content'\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Extract German translation\n",
        "            import re\n",
        "            match = re.search(r'German Translation:\\s*(.+?)(?:\\n|$)', llm_output, re.IGNORECASE)\n",
        "            if match:\n",
        "                german_translation = match.group(1).strip()\n",
        "                return german_translation, llm_output\n",
        "            else:\n",
        "                return llm_output.split('\\n')[0].strip(), llm_output\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            print(f\"   Response: {response.text}\")\n",
        "            return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "B1hvYIFHE-0N"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## part 17: German to English Tranlslation\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading German→English translation model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load MarianMT model\n",
        "print(\"📥 Loading MarianMT model...\")\n",
        "de_en_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
        "de_en_tokenizer = MarianTokenizer.from_pretrained(de_en_model_name)\n",
        "de_en_model = MarianMTModel.from_pretrained(de_en_model_name)\n",
        "\n",
        "print(f\"✅ Model loaded: {de_en_model_name}\")\n",
        "\n",
        "def translate_german_to_english(german_text):\n",
        "    \"\"\"Translate German to English using MarianMT\"\"\"\n",
        "    try:\n",
        "        # Tokenize\n",
        "        inputs = de_en_tokenizer(\n",
        "            german_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Generate translation\n",
        "        outputs = de_en_model.generate(**inputs)\n",
        "\n",
        "        # Decode\n",
        "        english_text = de_en_tokenizer.decode(\n",
        "            outputs[0],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        return english_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ German→English translation ready!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMd-YxkhFE3l",
        "outputId": "0ec82cce-7c7c-43e5-a855-4d90270c3d25"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Loading German→English translation model\n",
            "======================================================================\n",
            "📥 Loading MarianMT model...\n",
            "✅ Model loaded: Helsinki-NLP/opus-mt-de-en\n",
            "✅ German→English translation ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 18: Complete Translation pipeline\n",
        "\n",
        "def translate_egyptian_to_english(query_original, show_details=True):\n",
        "    \"\"\"\n",
        "    Complete pipeline: Egyptian → German → English\n",
        "\n",
        "    Args:\n",
        "        query_original: Original Egyptian transliteration\n",
        "        show_details: Print intermediate steps\n",
        "\n",
        "    Returns:\n",
        "        dict with results\n",
        "    \"\"\"\n",
        "\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"📝 TRANSLATING: {query_original}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Normalize query\n",
        "    query_normalized = normalize_transliteration(query_original)\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n1️⃣ Normalization:\")\n",
        "        print(f\"   Original:   {query_original}\")\n",
        "        print(f\"   Normalized: {query_normalized}\")\n",
        "\n",
        "    # Step 2: Generate embedding\n",
        "    query_embedding = embedding_model.encode(\n",
        "        query_normalized,\n",
        "        normalize_embeddings=True\n",
        "    ).tolist()\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n2️⃣ Embedding generated (dim={len(query_embedding)})\")\n",
        "\n",
        "    # Step 3: Hybrid search\n",
        "    if show_details:\n",
        "        print(f\"\\n3️⃣ Hybrid search (Dense + BM25)...\")\n",
        "\n",
        "    search_results = hybrid_search(\n",
        "        query_text=query_normalized,\n",
        "        query_embedding=query_embedding,\n",
        "        top_k=TOP_K_RESULTS\n",
        "    )\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   ✅ Found {len(search_results)} results\")\n",
        "        print(f\"\\n   📊 Top 3 matches:\")\n",
        "        for i, result in enumerate(search_results[:3], 1):\n",
        "            print(f\"\\n   {i}. RRF Score: {result['rrf_score']:.4f}\")\n",
        "            print(f\"      Transliteration: {result['payload']['transliteration_normalized']}\")\n",
        "            print(f\"      German: {result['payload']['translation_de'][:50]}...\")\n",
        "\n",
        "    # Step 4: LLM Translation (German)\n",
        "    if show_details:\n",
        "        print(f\"\\n4️⃣ LLM Translation (Egyptian → German)...\")\n",
        "\n",
        "    german_translation, llm_full_output = translate_with_llm(\n",
        "        query_original=query_original,\n",
        "        query_normalized=query_normalized,\n",
        "        retrieved_examples=search_results\n",
        "    )\n",
        "\n",
        "    if not german_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'LLM translation failed'\n",
        "        }\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   🇩🇪 German: {german_translation}\")\n",
        "\n",
        "    # Step 5: German → English\n",
        "    if show_details:\n",
        "        print(f\"\\n5️⃣ Translation (German → English)...\")\n",
        "\n",
        "    english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "    if not english_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'German→English translation failed'\n",
        "        }\n",
        "\n",
        "    # Final result\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"✅ TRANSLATION COMPLETE\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"🏛️ Egyptian:  {query_original}\")\n",
        "        print(f\"🔤 Normalized: {query_normalized}\")\n",
        "        print(f\"🇩🇪 German:    {german_translation}\")\n",
        "        print(f\"🇬🇧 English:   {english_translation}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'query_original': query_original,\n",
        "        'query_normalized': query_normalized,\n",
        "        'german': german_translation,\n",
        "        'english': english_translation,\n",
        "        'llm_output': llm_full_output,\n",
        "        'top_matches': search_results[:3]\n",
        "    }\n",
        "\n",
        "print(\"✅ Complete translation pipeline ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlcLe4THFK2M",
        "outputId": "40387d6a-7de8-4495-dbfe-6afcfa198687"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Complete translation pipeline ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========No======================"
      ],
      "metadata": {
        "id": "FN2OlfR5E5zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## part 19: Batch Processing Test set\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 STEP 13: Processing test set\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load test set\n",
        "print(\"📥 Loading test set...\")\n",
        "df_test = pd.read_csv('tla_test_set.csv')\n",
        "print(f\"✅ Loaded {len(df_test)} test records\")\n",
        "\n",
        "# Process subset (first 10 for demo)\n",
        "print(f\"\\n🔄 Translating first 10 test queries...\")\n",
        "print(\"(Processing all {len(df_test)} would take ~{len(df_test)*2/60:.1f} minutes)\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx in tqdm(range(min(10, len(df_test))), desc=\"Translating\"):\n",
        "    query = df_test.iloc[idx]['transliteration']\n",
        "\n",
        "    result = translate_egyptian_to_english(\n",
        "        query_original=query,\n",
        "        show_details=False\n",
        "    )\n",
        "\n",
        "    if result['success']:\n",
        "        results.append({\n",
        "            'query_original': result['query_original'],\n",
        "            'query_normalized': result['query_normalized'],\n",
        "            'reference_german': df_test.iloc[idx]['translation'],\n",
        "            'predicted_german': result['german'],\n",
        "            'predicted_english': result['english']\n",
        "        })\n",
        "\n",
        "# Create results dataframe\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\n✅ Processed {len(results)} queries successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "4f2a80b2760942b285c45c11a53e7570",
            "5525fa234ecc41fea6be00d4356d332c",
            "a5a26da884ac40fabb6c494e76ce852b",
            "baeb4497d5114da3a450404f057ad6ce",
            "6888a4ebc9754312974e8b4e3a30319f",
            "eaee7f5d2d3d45d2a7705e6816f00b75",
            "9381aeb2923247f28bee4542e75e5037",
            "8a623991c5b74a239580be2ce050240b",
            "ee2f03e9e17948f598b38ce81b21f778",
            "a880618972b8418f90624c47297aaaab",
            "bef7b7b21c054670b5662ded63ffa53f"
          ]
        },
        "id": "cDcdKvGhFq3z",
        "outputId": "a7acfba8-b9d3-4197-9a3a-849fc81a5c26"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 STEP 13: Processing test set\n",
            "======================================================================\n",
            "📥 Loading test set...\n",
            "✅ Loaded 91 test records\n",
            "\n",
            "🔄 Translating first 10 test queries...\n",
            "(Processing all {len(df_test)} would take ~{len(df_test)*2/60:.1f} minutes)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Translating:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f2a80b2760942b285c45c11a53e7570"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Processed 10 queries successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 20: Display result"
      ],
      "metadata": {
        "id": "kNuEm7SsMWA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 SAMPLE RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i in range(min(5, len(df_results))):\n",
        "    row = df_results.iloc[i]\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"Query {i+1}:\")\n",
        "    print(f\"{'─'*70}\")\n",
        "    print(f\"🏛️ Egyptian:    {row['query_original']}\")\n",
        "    print(f\"🔤 Normalized:  {row['query_normalized']}\")\n",
        "    print(f\"📖 Reference:   {row['reference_german']}\")\n",
        "    print(f\"🤖 Predicted:   {row['predicted_german']}\")\n",
        "    print(f\"🇬🇧 English:    {row['predicted_english']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6N6F5iMZMd",
        "outputId": "4d0449ac-6c91-4e68-b306-dc50114a3118"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 SAMPLE RESULTS\n",
            "======================================================================\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 1:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "🔤 Normalized:  smr-wꜥ.ti khr.i-hab.t im.i-ra-iꜥw hr.w-khwi\n",
            "📖 Reference:   Der Einzige Freund, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\n",
            "🤖 Predicted:   Der einzige Freund des Königs, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\n",
            "🇬🇧 English:    The King's only friend, the presiding priest, the ruler of the foreign language troupe, Harchuf.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 2:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ šs\n",
            "🔤 Normalized:  kha apd kha apd kha mnkh.t kha ih kha ta hnq.t pa.t kha apd kha apd kha shs\n",
            "📖 Reference:   Tausend an Geflügel, tausend an Geflügel, tausend an Kleidung, tausend an Rind, tausend an Brot, Bier und Gebäck, tausend an Geflügel, tausend an Geflügel, tausend an Geflügel, tausend an Alabaster.\n",
            "🤖 Predicted:   Tausend an Geflügel, tausend an Geflügel, tausend an Kleidung, tausend an Rind, tausend an Brot, tausend an Bier, tausend an Gebäck, tausend an Geflügel, tausend an Geflügel, tausend an Alabaster.\n",
            "🇬🇧 English:    Thousands of poultry, thousands of poultry, thousands of clothing, thousands of cattle, thousands of bread, thousands of beer, thousands of pastries, thousands of poultry, thousands of poultry, thousands of alabasters.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 3:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr msi̯.n ꜣs.t nṯr.(ꞽ)t\n",
            "🔤 Normalized:  i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n as.t ntjr.it\n",
            "📖 Reference:   Sei gegrüßt, Min bei seinen Prozessionen, mit hoher Federkrone, Sohn des Osiris, den Isis, die Göttliche, geboren hat;\n",
            "🤖 Predicted:   Sei gegrüßt, Min, im Peret, mit Doppelfederkrone, Sohn des Osiris, unter den Göttern.\n",
            "🇬🇧 English:    Greetings, Min, in the Peret, with double feather crown, son of Osiris, among the gods.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 4:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    šdi̯.t kꜣ rḫ.yt\n",
            "🔤 Normalized:  shdi.t ka rkh.yt\n",
            "📖 Reference:   Darbringen der Speisen (für die) Untertanen\n",
            "🤖 Predicted:   Das Opfern der Kammer zur Versorgung der Untertanen.\n",
            "🇬🇧 English:    Sacrificing the chamber to supply the subjects.\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Query 5:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "🏛️ Egyptian:    (w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ꞽr =s\n",
            "🔤 Normalized:  wsr.w ni.t m n ir.t-hr.w shmi.t ir\n",
            "📖 Reference:   Osiris Neith, nimm dir das Horusauge, zu dem er geht.\n",
            "🤖 Predicted:   Osiris Neith, nimm dir das Horusauge, zu dem er geht.\n",
            "🇬🇧 English:    Osiris Neith, take the horusuck he's going to.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============NO============================="
      ],
      "metadata": {
        "id": "pvWw1w60FAk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 📊 EVALUATION METRICS FOR EGYPTIAN TRANSLITERATION RAG SYSTEM\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 24: Install Evaluation Libraries"
      ],
      "metadata": {
        "id": "4N2_SXgKIFEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_test))\n",
        "print(df_test.columns.tolist())\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "hIxubIv2IAKx",
        "outputId": "b1c62961-e300-43f0-91d0-32ad4421c7a3"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91\n",
            "['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'transliteration_normalized']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        transliteration  \\\n",
              "8997  smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...   \n",
              "8998  ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...   \n",
              "8999  ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...   \n",
              "9000                                    šdi̯.t kꜣ rḫ.yt   \n",
              "9001  (w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...   \n",
              "\n",
              "                                          lemmatization  \\\n",
              "8997  400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...   \n",
              "8998  113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...   \n",
              "8999  91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...   \n",
              "9000                  158710|šdi̯ 162890|kꜣ 95820|rḫ.yt   \n",
              "9001  49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...   \n",
              "\n",
              "                                                   UPOS  \\\n",
              "8997                               NOUN NOUN NOUN PROPN   \n",
              "8998  NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...   \n",
              "8999  VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...   \n",
              "9000                                     VERB NOUN NOUN   \n",
              "9001   NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON   \n",
              "\n",
              "                                               glossing  \\\n",
              "8997                               TITL TITL TITL PERSN   \n",
              "8998  N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....   \n",
              "8999  V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...   \n",
              "9000                                      V\\inf N.m N.f   \n",
              "9001  TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...   \n",
              "\n",
              "                                            translation  \\\n",
              "8997  Der Einzige Freund, der Vorlesepriester, der V...   \n",
              "8998  Tausend an Geflügel, tausend an Geflügel, taus...   \n",
              "8999  Sei gegrüßt, Min bei seinen Prozessionen, mit ...   \n",
              "9000        Darbringen der Speisen (für die) Untertanen   \n",
              "9001  Osiris Neith, nimm dir das Horusauge, zu dem e...   \n",
              "\n",
              "                             transliteration_normalized  \n",
              "8997        smr-wa.ti khr.i-hab.t im.i-rʾ-iaw hr.w-khwi  \n",
              "8998  kha apd kha apd kha mnkh.t kha ih kha tʾ hnq.t...  \n",
              "8999  i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...  \n",
              "9000                                   shdi.t ka rkh.yt  \n",
              "9001                 wsr.w ni.t m n ir.t-hr.w shmi.t ir  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49af48ce-2871-4633-9ce2-399de25c88d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transliteration</th>\n",
              "      <th>lemmatization</th>\n",
              "      <th>UPOS</th>\n",
              "      <th>glossing</th>\n",
              "      <th>translation</th>\n",
              "      <th>transliteration_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...</td>\n",
              "      <td>400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...</td>\n",
              "      <td>NOUN NOUN NOUN PROPN</td>\n",
              "      <td>TITL TITL TITL PERSN</td>\n",
              "      <td>Der Einzige Freund, der Vorlesepriester, der V...</td>\n",
              "      <td>smr-wa.ti khr.i-hab.t im.i-rʾ-iaw hr.w-khwi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...</td>\n",
              "      <td>113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...</td>\n",
              "      <td>NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...</td>\n",
              "      <td>N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....</td>\n",
              "      <td>Tausend an Geflügel, tausend an Geflügel, taus...</td>\n",
              "      <td>kha apd kha apd kha mnkh.t kha ih kha tʾ hnq.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...</td>\n",
              "      <td>91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...</td>\n",
              "      <td>VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...</td>\n",
              "      <td>V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...</td>\n",
              "      <td>Sei gegrüßt, Min bei seinen Prozessionen, mit ...</td>\n",
              "      <td>i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9000</th>\n",
              "      <td>šdi̯.t kꜣ rḫ.yt</td>\n",
              "      <td>158710|šdi̯ 162890|kꜣ 95820|rḫ.yt</td>\n",
              "      <td>VERB NOUN NOUN</td>\n",
              "      <td>V\\inf N.m N.f</td>\n",
              "      <td>Darbringen der Speisen (für die) Untertanen</td>\n",
              "      <td>shdi.t ka rkh.yt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9001</th>\n",
              "      <td>(w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...</td>\n",
              "      <td>49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...</td>\n",
              "      <td>NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON</td>\n",
              "      <td>TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...</td>\n",
              "      <td>Osiris Neith, nimm dir das Horusauge, zu dem e...</td>\n",
              "      <td>wsr.w ni.t m n ir.t-hr.w shmi.t ir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49af48ce-2871-4633-9ce2-399de25c88d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49af48ce-2871-4633-9ce2-399de25c88d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49af48ce-2871-4633-9ce2-399de25c88d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 91,\n  \"fields\": [\n    {\n      \"column\": \"transliteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"m \\u1e25nb\\ua723b\\ua723.w \\u1e25r b\\ua723\\u1e96.t\",\n          \"\\u1e0f\\u1e0f.tw =s n p\\ua723y =\\ua7bd sn z\\ua723-nswt \\u1e25\\ua723.t\\ua7bd-\\ua725 sbk-n\\u1e2bt\",\n          \"(\\ua7bd)r(.\\ua7bdt-\\ua7bd)\\u1e2b(.t)-nswt n.\\ua7bd-s\\ua7bd-r\\u1e0fi\\u032f(.w)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatization\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"64410|m 882920|\\u1e25nb\\ua723b\\ua723 400090|\\u1e25r 53580|b\\ua723\\u1e96.t\",\n          \"96700|r\\u1e0fi\\u032f 10090|=s 400055|n 550021|p\\ua723y= 10030|=\\ua7bd 136230|sn 450223|z\\ua723-nswt 100520|\\u1e25\\ua723.t\\ua7bd-\\ua725 550004|Sbk-n\\u1e2bt.w\",\n          \"95750|\\ua7bdr.\\ua7bdt-\\ua7bd\\u1e2b.t-nswt 713172|N.\\ua7bd-s\\ua7bd-r\\u1e0f.w\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UPOS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83,\n        \"samples\": [\n          \"ADJ NOUN ADJ NOUN ADP PRON\",\n          \"NOUN NOUN NOUN PROPN\",\n          \"VERB ADP PRON PART PRON PROPN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glossing\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"N.m PREP-adjz:m.pl N.m PREP ROYLN dem.m.sg\",\n          \"TITL TITL TITL PERSN\",\n          \"V\\\\tam.act:stpr -2sg.m N.m:stpr -2sg.m V\\\\tam-pass:stpr -3sg.m PREP:stpr -2sg.m PREP V\\\\rel.f.sg:stpr -2sg.m ADJ:f.sg PREP N.m TITL V\\\\ptcp.pass.m.sg N.m:stpr -3sg.m ADV V\\\\ptcp.pass.m.sg:stpr -3sg.m PREP-adjz:m.sg N.f:stpr -3sg.m TITL PERSN N.m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"Schl\\u00e4ngel dich nicht auf das Gl\\u00e4nzende!\",\n          \"Es (=dieses Amt) ist meinem Bruder, dem K\\u00f6nigssohn und Grafen Sobeknacht zu geben.\",\n          \"Die Verwalterin des K\\u00f6nigsverm\\u00f6gens Ni-si-redju.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transliteration_normalized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"m hnbaba.w hr bakh.t\",\n          \"djdj.tw n pay =i sn za-nswt ha.ti-a sbk-nkht\",\n          \"ir.it-ikh.t-nswt n.i-si-rdji.w\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 19: Install Evaluation Libraries\n",
        "import sys\n",
        "print(\"\\n📦 Installing all evaluation libraries...\")\n",
        "eval_packages = [\n",
        "    'nltk',\n",
        "    'rouge-score',\n",
        "    'sacrebleu',\n",
        "]\n",
        "\n",
        "for package in eval_packages:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--break-system-packages', '-q'])\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from sacrebleu.metrics import CHRF\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data\n",
        "print(\"📥 Downloading NLTK data...\")\n",
        "try:\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "    print(\"✅ NLTK data ready!\")\n",
        "except:\n",
        "    print(\"⚠️ NLTK download warning (may still work)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRKJZc-8IHLK",
        "outputId": "2266bd43-562e-4956-c434-8262bb9cd726"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Installing all evaluation libraries...\n",
            "📥 Downloading NLTK data...\n",
            "✅ NLTK data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 20: Define Evaluation Metrics\n",
        "\n",
        "# ============================================================================\n",
        "# TRANSLATION QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_bleu(reference, hypothesis):\n",
        "    \"\"\"Calculate BLEU score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        smoothing = SmoothingFunction()\n",
        "        bleu_score = sentence_bleu(\n",
        "            [reference_tokens],\n",
        "            hypothesis_tokens,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "        return bleu_score * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_rouge(reference, hypothesis):\n",
        "    \"\"\"Calculate ROUGE scores\"\"\"\n",
        "    try:\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        scores = scorer.score(reference, hypothesis)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure * 100,\n",
        "            'rouge2': scores['rouge2'].fmeasure * 100,\n",
        "            'rougeL': scores['rougeL'].fmeasure * 100\n",
        "        }\n",
        "    except:\n",
        "        return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "def calculate_meteor(reference, hypothesis):\n",
        "    \"\"\"Calculate METEOR score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        meteor = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "        return meteor * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_chrf(reference, hypothesis):\n",
        "    \"\"\"Calculate chrF score (0-100)\"\"\"\n",
        "    try:\n",
        "        chrf = CHRF()\n",
        "        score = chrf.sentence_score(hypothesis, [reference])\n",
        "        return score.score  # Already 0-100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_exact_match(reference, hypothesis):\n",
        "    \"\"\"Calculate exact match\"\"\"\n",
        "    return 100.0 if reference.strip().lower() == hypothesis.strip().lower() else 0.0\n",
        "\n",
        "def calculate_word_overlap(reference, hypothesis):\n",
        "    \"\"\"Calculate word-level overlap percentage\"\"\"\n",
        "    try:\n",
        "        ref_words = set(reference.lower().split())\n",
        "        hyp_words = set(hypothesis.lower().split())\n",
        "        if len(ref_words) == 0:\n",
        "            return 0.0\n",
        "        overlap = len(ref_words.intersection(hyp_words))\n",
        "        return (overlap / len(ref_words)) * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# ============================================================================\n",
        "# RETRIEVAL QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Calculate Recall@K - checks if reference appears in top K results\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "        k_values: List of K values to calculate recall for\n",
        "\n",
        "    Returns:\n",
        "        Dict with Recall@K for each K\n",
        "    \"\"\"\n",
        "    recalls = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        found = False\n",
        "        for i, example in enumerate(retrieved_examples[:k]):\n",
        "            if i >= len(retrieved_examples):\n",
        "                break\n",
        "            retrieved_german = example['payload']['translation_de']\n",
        "            # Check if the reference matches (exact or high similarity)\n",
        "            if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        recalls[f'recall@{k}'] = 100.0 if found else 0.0\n",
        "\n",
        "    return recalls\n",
        "\n",
        "def calculate_mrr(reference_german, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Calculate Mean Reciprocal Rank (MRR)\n",
        "\n",
        "    MRR = 1 / rank of first relevant result\n",
        "    If no relevant result found, MRR = 0\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "\n",
        "    Returns:\n",
        "        MRR score (0-100)\n",
        "    \"\"\"\n",
        "    for i, example in enumerate(retrieved_examples):\n",
        "        retrieved_german = example['payload']['translation_de']\n",
        "        # Check if this is a relevant result\n",
        "        if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "            # Rank starts at 1, not 0\n",
        "            mrr = 1.0 / (i + 1)\n",
        "            return mrr * 100  # Convert to percentage\n",
        "\n",
        "    # No relevant result found\n",
        "    return 0.0\n",
        "\n",
        "def calculate_average_retrieval_score(retrieved_examples, top_k=10):\n",
        "    \"\"\"\n",
        "    Calculate average retrieval score from top K results\n",
        "\n",
        "    Args:\n",
        "        retrieved_examples: List of retrieved examples with scores\n",
        "        top_k: Number of top results to consider\n",
        "\n",
        "    Returns:\n",
        "        Average RRF score (0-100)\n",
        "    \"\"\"\n",
        "    if not retrieved_examples:\n",
        "        return 0.0\n",
        "\n",
        "    scores = [example['rrf_score'] for example in retrieved_examples[:top_k]]\n",
        "    avg_score = np.mean(scores) if scores else 0.0\n",
        "    return avg_score * 100  # Convert to percentage\n",
        "\n",
        "print(\"✅ All evaluation metrics defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRXoXLezLdHa",
        "outputId": "cb2c91c3-a3e0-4afd-b7bb-e6600a611eb3"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All evaluation metrics defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🔄 Part 21: Process RAG Test Set with ALL Metrics\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING RAG TEST SET WITH ALL METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load test set\n",
        "print(\"\\n📥 Loading test set...\")\n",
        "df_test = pd.read_csv('tla_test_set.csv')[:25]  # Limit for demo\n",
        "print(f\"✅ Loaded {len(df_test)} test records\")\n",
        "\n",
        "# Initialize results storage\n",
        "test_results = []\n",
        "failed_translations = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} test samples...\")\n",
        "print(\"⏱️ Estimated time: ~{:.1f} minutes\\n\".format(len(df_test) * 3 / 60))\n",
        "\n",
        "# Process each test sample\n",
        "for idx in tqdm(range(len(df_test)), desc=\"RAG Translation\"):\n",
        "    try:\n",
        "        # Get query\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        # Translate Egyptian → German → English using RAG\n",
        "        result = translate_egyptian_to_english(\n",
        "            query_original=query_original,\n",
        "            show_details=False\n",
        "        )\n",
        "\n",
        "        if result['success']:\n",
        "            # Translate reference German → English\n",
        "            reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "            if reference_english:\n",
        "                # Store results (including retrieval info)\n",
        "                test_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'transliteration_normalized': result['query_normalized'],\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german': result['german'],\n",
        "                    'predicted_english': result['english'],\n",
        "                    'top_matches': result['top_matches']  # Store retrieval results\n",
        "                })\n",
        "            else:\n",
        "                failed_translations.append({\n",
        "                    'sample_id': idx,\n",
        "                    'reason': 'Reference translation to English failed'\n",
        "                })\n",
        "        else:\n",
        "            failed_translations.append({\n",
        "                'sample_id': idx,\n",
        "                'reason': result.get('error', 'RAG translation failed')\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_translations.append({\n",
        "            'sample_id': idx,\n",
        "            'reason': f'Exception: {str(e)}'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "# Create results DataFrame\n",
        "df_test_results = pd.DataFrame(test_results)\n",
        "\n",
        "print(f\"\\n✅ RAG Processing complete!\")\n",
        "print(f\"   Successful: {len(test_results)}\")\n",
        "print(f\"   Failed: {len(failed_translations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "8616b1b21c3a40e9b249df6d7396f6ab",
            "7b8095d0486040e5ad7f9dfd8ef37d7f",
            "dfd1b50a9b674d849c171165c552d598",
            "093791a24ae54f50bfc0820f34f814a5",
            "c5110e587ee34cb5b3832d9d8041ceac",
            "02deebd78dd042299bdd5c88d7319aa6",
            "0cbd59fbe393470b8bf743725c84e394",
            "792be0f0d10643b892c7aae53e554fda",
            "839db4c3c1e14e45a609684bb7469acb",
            "71afe4d6858341c2b25aaf804a9e0ef2",
            "eddbe8b1ea2b42e4963df08942061b2b"
          ]
        },
        "id": "7lmnADTOLhfg",
        "outputId": "8fd05612-5b9d-4b0b-bbbc-bac133ffff2d"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING RAG TEST SET WITH ALL METRICS\n",
            "======================================================================\n",
            "\n",
            "📥 Loading test set...\n",
            "✅ Loaded 25 test records\n",
            "\n",
            "🔄 Processing 25 test samples...\n",
            "⏱️ Estimated time: ~1.2 minutes\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG Translation:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8616b1b21c3a40e9b249df6d7396f6ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ RAG Processing complete!\n",
            "   Successful: 25\n",
            "   Failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 22: Calculate ALL Metrics (Translation + Retrieval)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING ALL METRICS FOR RAG SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "metrics_list = []\n",
        "\n",
        "print(f\"\\n🔄 Computing all metrics for {len(df_test_results)} translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_test_results.iterrows(), total=len(df_test_results), desc=\"Computing all metrics\"):\n",
        "    reference_english = row['reference_english']\n",
        "    hypothesis_english = row['predicted_english']\n",
        "    reference_german = row['reference_german']\n",
        "    retrieved_examples = row['top_matches']\n",
        "\n",
        "    # Calculate translation quality metrics\n",
        "    rouge_scores = calculate_rouge(reference_english, hypothesis_english)\n",
        "\n",
        "    # Calculate retrieval quality metrics\n",
        "    recall_scores = calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10, 20])\n",
        "    mrr_score = calculate_mrr(reference_german, retrieved_examples)\n",
        "    avg_retrieval_score = calculate_average_retrieval_score(retrieved_examples, top_k=10)\n",
        "\n",
        "    # Combine all metrics\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference_english, hypothesis_english),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference_english, hypothesis_english),\n",
        "        'chrf': calculate_chrf(reference_english, hypothesis_english),\n",
        "        'exact_match': calculate_exact_match(reference_english, hypothesis_english),\n",
        "        'word_overlap': calculate_word_overlap(reference_english, hypothesis_english),\n",
        "        # Retrieval Quality Metrics\n",
        "        'recall@1': recall_scores['recall@1'],\n",
        "        'recall@3': recall_scores['recall@3'],\n",
        "        'recall@5': recall_scores['recall@5'],\n",
        "        'recall@10': recall_scores['recall@10'],\n",
        "        'recall@20': recall_scores['recall@20'],\n",
        "        'mrr': mrr_score,\n",
        "        'avg_retrieval_score': avg_retrieval_score\n",
        "    }\n",
        "\n",
        "    metrics_list.append(metrics)\n",
        "\n",
        "# Create metrics DataFrame\n",
        "df_metrics = pd.DataFrame(metrics_list)\n",
        "\n",
        "print(\"✅ All metrics calculation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "68f66511c4ec490c94a1d5bb04620037",
            "cd5e0988c67143538b9b0a5b6aea7430",
            "4841b8489f2b48d4a576cb679b7498c4",
            "8ec5b2aa08f34116a15be7fd5c316b8d",
            "1eb13f6171054493b28182986df9c4cc",
            "15a5fc998d154c898541fb07fdbf4bb9",
            "b41adf3a9232499e830c93cd9de4a62c",
            "1f2f8900f7444cc68ff0ce593eed3d01",
            "b69361af3ab44ea2b2ca843f2c54ab63",
            "7d27bcb051af42f596a8a60539bf8951",
            "68d0d855712e46dca14cc9a22e7b64be"
          ]
        },
        "id": "v0BrfMFlLoV4",
        "outputId": "6563b6a2-a448-41b9-d4f0-90ecc628dce8"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CALCULATING ALL METRICS FOR RAG SYSTEM\n",
            "======================================================================\n",
            "\n",
            "🔄 Computing all metrics for 25 translations...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing all metrics:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68f66511c4ec490c94a1d5bb04620037"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All metrics calculation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 📈 Part 23: Display Complete RAG System Summary\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for all metrics\n",
        "avg_metrics = {\n",
        "    # Translation Quality\n",
        "    'BLEU': df_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_metrics['meteor'].mean(),\n",
        "    'chrF': df_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_metrics['word_overlap'].mean(),\n",
        "    # Retrieval Quality\n",
        "    'Recall@1': df_metrics['recall@1'].mean(),\n",
        "    'Recall@3': df_metrics['recall@3'].mean(),\n",
        "    'Recall@5': df_metrics['recall@5'].mean(),\n",
        "    'Recall@10': df_metrics['recall@10'].mean(),\n",
        "    'Recall@20': df_metrics['recall@20'].mean(),\n",
        "    'MRR': df_metrics['mrr'].mean(),\n",
        "    'Avg Retrieval Score': df_metrics['avg_retrieval_score'].mean()\n",
        "}\n",
        "\n",
        "# Quality emoji function\n",
        "def get_quality_emoji(metric_name, score):\n",
        "    \"\"\"Get quality emoji based on metric and score\"\"\"\n",
        "    if metric_name in ['Recall@1', 'Recall@3', 'Exact Match']:\n",
        "        return '🟢' if score > 20 else '🟡' if score > 5 else '🔴'\n",
        "    elif 'Recall' in metric_name:\n",
        "        return '🟢' if score > 40 else '🟡' if score > 20 else '🔴'\n",
        "    elif metric_name == 'MRR':\n",
        "        return '🟢' if score > 30 else '🟡' if score > 15 else '🔴'\n",
        "    else:\n",
        "        return '🟢' if score > 50 else '🟡' if score > 30 else '🔴'\n",
        "\n",
        "print(\"\\n📊 TRANSLATION QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "translation_metrics = ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'METEOR', 'chrF', 'Exact Match', 'Word Overlap']\n",
        "for metric in translation_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n📊 RETRIEVAL QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "retrieval_metrics = ['Recall@1', 'Recall@3', 'Recall@5', 'Recall@10', 'Recall@20', 'MRR', 'Avg Retrieval Score']\n",
        "for metric in retrieval_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "# Distribution statistics for key metrics\n",
        "print(\"\\n📈 KEY METRIC DISTRIBUTIONS:\")\n",
        "print(\"─\" * 70)\n",
        "\n",
        "for metric_name, metric_col in [('BLEU', 'bleu'), ('METEOR', 'meteor'), ('Recall@10', 'recall@10'), ('MRR', 'mrr')]:\n",
        "    scores = df_metrics[metric_col]\n",
        "    print(f\"\\n{metric_name}:\")\n",
        "    print(f\"   Min:    {scores.min():6.2f}%\")\n",
        "    print(f\"   25%:    {scores.quantile(0.25):6.2f}%\")\n",
        "    print(f\"   Median: {scores.median():6.2f}%\")\n",
        "    print(f\"   75%:    {scores.quantile(0.75):6.2f}%\")\n",
        "    print(f\"   Max:    {scores.max():6.2f}%\")\n",
        "    print(f\"   Std:    {scores.std():6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaXAJjvrLqAl",
        "outputId": "f3f12a00-ba42-4a79-f280-9eec4d551f58"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "📊 TRANSLATION QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 BLEU                :  23.49%\n",
            "   🟢 ROUGE-1             :  54.51%\n",
            "   🟡 ROUGE-2             :  38.78%\n",
            "   🟢 ROUGE-L             :  53.01%\n",
            "   🟡 METEOR              :  41.68%\n",
            "   🟡 chrF                :  48.54%\n",
            "   🔴 Exact Match         :   4.00%\n",
            "   🟡 Word Overlap        :  44.15%\n",
            "\n",
            "📊 RETRIEVAL QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 Recall@1            :   0.00%\n",
            "   🔴 Recall@3            :   0.00%\n",
            "   🔴 Recall@5            :   0.00%\n",
            "   🔴 Recall@10           :   0.00%\n",
            "   🔴 Recall@20           :   0.00%\n",
            "   🔴 MRR                 :   0.00%\n",
            "   🔴 Avg Retrieval Score :   3.06%\n",
            "\n",
            "📈 KEY METRIC DISTRIBUTIONS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "BLEU:\n",
            "   Min:      0.00%\n",
            "   25%:      4.18%\n",
            "   Median:   8.84%\n",
            "   75%:     41.11%\n",
            "   Max:     73.68%\n",
            "   Std:     26.21%\n",
            "\n",
            "METEOR:\n",
            "   Min:      0.00%\n",
            "   25%:     15.49%\n",
            "   Median:  36.67%\n",
            "   75%:     65.06%\n",
            "   Max:     93.75%\n",
            "   Std:     29.27%\n",
            "\n",
            "Recall@10:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:      0.00%\n",
            "   Std:      0.00%\n",
            "\n",
            "MRR:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:      0.00%\n",
            "   Std:      0.00%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 24: Visual Comparison Charts\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 VISUAL METRIC COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Translation metrics\n",
        "print(\"\\n🎯 Translation Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[:8]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "# Retrieval metrics\n",
        "print(\"\\n🔍 Retrieval Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[8:]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOlhOQqeLrt6",
        "outputId": "847e3979-b78f-4296-f144-8cfee9206374"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 VISUAL METRIC COMPARISON\n",
            "======================================================================\n",
            "\n",
            "🎯 Translation Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "BLEU                 ███████████  23.49%\n",
            "ROUGE-1              ███████████████████████████  54.51%\n",
            "ROUGE-2              ███████████████████  38.78%\n",
            "ROUGE-L              ██████████████████████████  53.01%\n",
            "METEOR               ████████████████████  41.68%\n",
            "chrF                 ████████████████████████  48.54%\n",
            "Exact Match          ██   4.00%\n",
            "Word Overlap         ██████████████████████  44.15%\n",
            "\n",
            "🔍 Retrieval Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Recall@1                0.00%\n",
            "Recall@3                0.00%\n",
            "Recall@5                0.00%\n",
            "Recall@10               0.00%\n",
            "Recall@20               0.00%\n",
            "MRR                     0.00%\n",
            "Avg Retrieval Score  █   3.06%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 25: Process LLM-Only Test Set\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING LLM-ONLY TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# LLM-only translation function (simplified)\n",
        "\n",
        "def translate_with_llm_only(query_original, query_normalized):\n",
        "    \"\"\"\n",
        "    Direct LLM translation WITHOUT RAG retrieval\n",
        "    Only uses the LLM's knowledge\n",
        "    \"\"\"\n",
        "\n",
        "    # Simple prompt without retrieved examples\n",
        "    prompt = f\"\"\"You are an expert linguist specialized in Earlier Egyptian grammar and historical translation.\n",
        "\n",
        "Translate the following Earlier Egyptian transliteration into German.\n",
        "Use a conservative, grammar-based interpretation.\n",
        "Do not modernize meanings or add implied words.\n",
        "\n",
        "Egyptian Transliteration:\n",
        "{query_original}\n",
        "\n",
        "Output ONLY the German translation.\n",
        "Do not add explanations, comments, or alternative readings.\n",
        "\n",
        "German Translation:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist. Translate Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Clean the response\n",
        "            german_translation = llm_output.strip()\n",
        "            # Remove \"German Translation:\" prefix if present\n",
        "            german_translation = re.sub(r'^German Translation:\\s*', '', german_translation, flags=re.IGNORECASE)\n",
        "\n",
        "            return german_translation.strip()\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ LLM-only translation function ready!\")\n",
        "\n",
        "# Process LLM-only\n",
        "llm_only_results = []\n",
        "llm_only_failed = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} samples with LLM-only...\")\n",
        "\n",
        "for idx in tqdm(range(len(df_test)), desc=\"LLM-only translation\"):\n",
        "    try:\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        query_normalized = normalize_transliteration(query_original)\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        german_translation = translate_with_llm_only(query_original, query_normalized)\n",
        "\n",
        "        if german_translation:\n",
        "            english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "            if english_translation:\n",
        "                # Get reference English from RAG results\n",
        "                if idx < len(df_test_results):\n",
        "                    reference_english = df_test_results.iloc[idx]['reference_english']\n",
        "                else:\n",
        "                    reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "                llm_only_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german_llm': german_translation,\n",
        "                    'predicted_english_llm': english_translation\n",
        "                })\n",
        "            else:\n",
        "                llm_only_failed.append({'sample_id': idx, 'reason': 'English translation failed'})\n",
        "        else:\n",
        "            llm_only_failed.append({'sample_id': idx, 'reason': 'LLM translation failed'})\n",
        "\n",
        "    except Exception as e:\n",
        "        llm_only_failed.append({'sample_id': idx, 'reason': f'Exception: {str(e)}'})\n",
        "        continue\n",
        "\n",
        "df_llm_only = pd.DataFrame(llm_only_results)\n",
        "\n",
        "print(f\"\\n✅ LLM-only processing complete!\")\n",
        "print(f\"   Successful: {len(llm_only_results)}\")\n",
        "print(f\"   Failed: {len(llm_only_failed)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "be022938b0294e34919ccebd8a379295",
            "9d3eef03dd7d4e79a5fa490a1f9f013c",
            "21aad9a111b94a5cb443b2ffcd2ffb81",
            "162ab04d99ee4278a8813943b98828fa",
            "a58c2fce18614150b1a15f291aaa2a17",
            "13f39b660b0c4a69bce096a58bfc244d",
            "b068f3c100044f069cc0f780d28484ab",
            "847f359cbe214523806bc9d51565cff6",
            "2acab60bf9f147c38aafe4cb43a71bd7",
            "e854e517afea4003b92d9abf305435a3",
            "27fe6efcdc7a41a8b68151a0fa17d89b"
          ]
        },
        "id": "QvcfuygKLuSm",
        "outputId": "31776f01-0a5f-4c6b-b0cf-bdeaea708b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING LLM-ONLY TEST SET\n",
            "======================================================================\n",
            "✅ LLM-only translation function ready!\n",
            "\n",
            "🔄 Processing 25 samples with LLM-only...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LLM-only translation:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be022938b0294e34919ccebd8a379295"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🏆 Part 26: Calculate Metrics for LLM-Only\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING METRICS FOR LLM-ONLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "llm_only_metrics = []\n",
        "\n",
        "print(f\"\\n🔄 Computing metrics for {len(df_llm_only)} LLM-only translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_llm_only.iterrows(), total=len(df_llm_only), desc=\"Computing LLM-only metrics\"):\n",
        "    reference = row['reference_english']\n",
        "    hypothesis = row['predicted_english_llm']\n",
        "\n",
        "    rouge_scores = calculate_rouge(reference, hypothesis)\n",
        "\n",
        "    # LLM-only has NO retrieval metrics (all 0)\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference, hypothesis),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference, hypothesis),\n",
        "        'chrf': calculate_chrf(reference, hypothesis),\n",
        "        'exact_match': calculate_exact_match(reference, hypothesis),\n",
        "        'word_overlap': calculate_word_overlap(reference, hypothesis),\n",
        "        # Retrieval metrics = 0 (no retrieval)\n",
        "        'recall@1': 0.0,\n",
        "        'recall@3': 0.0,\n",
        "        'recall@5': 0.0,\n",
        "        'recall@10': 0.0,\n",
        "        'recall@20': 0.0,\n",
        "        'mrr': 0.0,\n",
        "        'avg_retrieval_score': 0.0\n",
        "    }\n",
        "\n",
        "    llm_only_metrics.append(metrics)\n",
        "\n",
        "df_llm_only_metrics = pd.DataFrame(llm_only_metrics)\n",
        "\n",
        "print(\"✅ LLM-only metrics calculation complete!\")"
      ],
      "metadata": {
        "id": "i22O9ubtLu4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  Part 27: COMPREHENSIVE COMPARISON\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🆚 COMPREHENSIVE RAG vs LLM-ONLY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for LLM-only\n",
        "llm_only_averages = {\n",
        "    'BLEU': df_llm_only_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_llm_only_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_llm_only_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_llm_only_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_llm_only_metrics['meteor'].mean(),\n",
        "    'chrF': df_llm_only_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_llm_only_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_llm_only_metrics['word_overlap'].mean(),\n",
        "    'Recall@1': 0.0,\n",
        "    'Recall@3': 0.0,\n",
        "    'Recall@5': 0.0,\n",
        "    'Recall@10': 0.0,\n",
        "    'Recall@20': 0.0,\n",
        "    'MRR': 0.0,\n",
        "    'Avg Retrieval Score': 0.0\n",
        "}\n",
        "\n",
        "print(\"\\n📊 COMPLETE METRICS COMPARISON:\")\n",
        "print(\"─\" * 100)\n",
        "print(f\"{'Metric':<25} {'RAG System':<15} {'LLM-Only':<15} {'Difference':<15} {'Winner':<15}\")\n",
        "print(\"─\" * 100)\n",
        "\n",
        "for metric in avg_metrics.keys():\n",
        "    rag_score = avg_metrics[metric]\n",
        "    llm_score = llm_only_averages[metric]\n",
        "    diff = rag_score - llm_score\n",
        "\n",
        "    if 'Recall' in metric or metric == 'MRR' or metric == 'Avg Retrieval Score':\n",
        "        winner = \"🏆 RAG (only)\" if diff > 0 else \"N/A\"\n",
        "    else:\n",
        "        winner = \"🏆 RAG\" if diff > 0 else \"🏆 LLM\" if diff < 0 else \"🤝 Tie\"\n",
        "\n",
        "    print(f\"{metric:<25} {rag_score:>6.2f}%        {llm_score:>6.2f}%        {diff:>+6.2f}%       {winner:<15}\")\n",
        "\n",
        "print(\"─\" * 100)\n"
      ],
      "metadata": {
        "id": "pe84ktPsLw8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 29: Detailed Comparison Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 DETAILED COMPARISON ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Statistical comparison\n",
        "comparison_stats = []\n",
        "\n",
        "for metric_col in ['bleu', 'rouge1', 'meteor', 'chrf', 'recall@10', 'mrr']:\n",
        "    rag_scores = df_metrics[metric_col].values\n",
        "    llm_scores = df_llm_only_metrics[metric_col].values\n",
        "\n",
        "    stats = {\n",
        "        'Metric': metric_col.upper(),\n",
        "        'RAG_Mean': rag_scores.mean(),\n",
        "        'RAG_Median': np.median(rag_scores),\n",
        "        'RAG_Std': rag_scores.std(),\n",
        "        'LLM_Mean': llm_scores.mean(),\n",
        "        'LLM_Median': np.median(llm_scores),\n",
        "        'LLM_Std': llm_scores.std(),\n",
        "        'Mean_Diff': rag_scores.mean() - llm_scores.mean()\n",
        "    }\n",
        "\n",
        "    comparison_stats.append(stats)\n",
        "\n",
        "df_comparison_stats = pd.DataFrame(comparison_stats)\n",
        "\n",
        "print(\"\\n📊 Statistical Summary:\")\n",
        "print(\"─\" * 100)\n",
        "print(df_comparison_stats.to_string(index=False))\n",
        "print(\"─\" * 100)"
      ],
      "metadata": {
        "id": "kun4eiuSIfwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 30: Win/Loss Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🏆 SAMPLE-BY-SAMPLE WIN/LOSS ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "for metric in ['bleu', 'meteor', 'chrf']:\n",
        "    metric_wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "    for i in range(min(len(df_metrics), len(df_llm_only_metrics))):\n",
        "        rag_score = df_metrics.iloc[i][metric]\n",
        "        llm_score = df_llm_only_metrics.iloc[i][metric]\n",
        "\n",
        "        if rag_score > llm_score:\n",
        "            metric_wins['RAG'] += 1\n",
        "            wins['RAG'] += 1\n",
        "        elif llm_score > rag_score:\n",
        "            metric_wins['LLM'] += 1\n",
        "            wins['LLM'] += 1\n",
        "        else:\n",
        "            metric_wins['Tie'] += 1\n",
        "            wins['Tie'] += 1\n",
        "\n",
        "    total = sum(metric_wins.values())\n",
        "    print(f\"\\n{metric.upper()} Wins:\")\n",
        "    print(f\"  RAG:      {metric_wins['RAG']:3d} ({metric_wins['RAG']/total*100:5.1f}%)\")\n",
        "    print(f\"  LLM-Only: {metric_wins['LLM']:3d} ({metric_wins['LLM']/total*100:5.1f}%)\")\n",
        "    print(f\"  Tie:      {metric_wins['Tie']:3d} ({metric_wins['Tie']/total*100:5.1f}%)\")\n",
        "\n",
        "total_comparisons = sum(wins.values())\n",
        "print(f\"\\n{'─' * 70}\")\n",
        "print(f\"Overall Wins (across all metrics):\")\n",
        "print(f\"  🏆 RAG:      {wins['RAG']:3d} ({wins['RAG']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🏆 LLM-Only: {wins['LLM']:3d} ({wins['LLM']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🤝 Tie:      {wins['Tie']:3d} ({wins['Tie']/total_comparisons*100:5.1f}%)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "## 💾 Part 32: Save All Results\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"💾 SAVING ALL RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save RAG comprehensive results\n",
        "df_test_results_full = df_test_results.copy()\n",
        "for metric in df_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_test_results_full[metric] = df_metrics[metric].values\n",
        "\n",
        "df_test_results_full.to_csv('rag_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ RAG comprehensive results saved to: rag_comprehensive_results.csv\")\n",
        "\n",
        "# Save LLM-only comprehensive results\n",
        "df_llm_only_full = df_llm_only.copy()\n",
        "for metric in df_llm_only_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_llm_only_full[metric] = df_llm_only_metrics[metric].values\n",
        "\n",
        "df_llm_only_full.to_csv('llm_only_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ LLM-only comprehensive results saved to: llm_only_comprehensive_results.csv\")\n",
        "\n",
        "# Save comparison summary\n",
        "comparison_summary = pd.DataFrame([\n",
        "    {'System': 'RAG', **{f'{k}': v for k, v in avg_metrics.items()}},\n",
        "    {'System': 'LLM-Only', **{f'{k}': v for k, v in llm_only_averages.items()}},\n",
        "    {'System': 'Difference (RAG - LLM)', **{f'{k}': avg_metrics[k] - llm_only_averages[k] for k in avg_metrics.keys()}}\n",
        "])\n",
        "\n",
        "comparison_summary.to_csv('complete_comparison_summary.csv', index=False)\n",
        "print(f\"✅ Comparison summary saved to: complete_comparison_summary.csv\")\n",
        "\n",
        "# Save statistical comparison\n",
        "df_comparison_stats.to_csv('comparison_statistics.csv', index=False)\n",
        "print(f\"✅ Statistics saved to: comparison_statistics.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "## ✅ Part 33: FINAL COMPREHENSIVE REPORT\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FINAL COMPREHENSIVE EVALUATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Determine overall winner\n",
        "rag_total = sum(avg_metrics.values())\n",
        "llm_total = sum(llm_only_averages.values())\n",
        "overall_winner = \"RAG System 🏆\" if rag_total > llm_total else \"LLM-Only 🏆\" if llm_total > rag_total else \"Tie 🤝\"\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 System Performance Summary:\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "RAG SYSTEM (Hybrid Search + LLM):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {avg_metrics['BLEU']:.2f}%\n",
        "  • METEOR:       {avg_metrics['METEOR']:.2f}%\n",
        "  • chrF:         {avg_metrics['chrF']:.2f}%\n",
        "  • ROUGE-1:      {avg_metrics['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {avg_metrics['Exact Match']:.2f}%\n",
        "\n",
        "Retrieval Quality:\n",
        "  • Recall@1:     {avg_metrics['Recall@1']:.2f}%\n",
        "  • Recall@10:    {avg_metrics['Recall@10']:.2f}%\n",
        "  • MRR:          {avg_metrics['MRR']:.2f}%\n",
        "  • Avg Score:    {avg_metrics['Avg Retrieval Score']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "LLM-ONLY (No RAG):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_llm_only_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {llm_only_averages['BLEU']:.2f}%\n",
        "  • METEOR:       {llm_only_averages['METEOR']:.2f}%\n",
        "  • chrF:         {llm_only_averages['chrF']:.2f}%\n",
        "  • ROUGE-1:      {llm_only_averages['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {llm_only_averages['Exact Match']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "COMPARISON RESULTS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "🏆 Overall Winner: {overall_winner}\n",
        "\n",
        "Translation Improvement (RAG - LLM):\n",
        "  • BLEU:    {avg_metrics['BLEU'] - llm_only_averages['BLEU']:+.2f}%\n",
        "  • METEOR:  {avg_metrics['METEOR'] - llm_only_averages['METEOR']:+.2f}%\n",
        "  • chrF:    {avg_metrics['chrF'] - llm_only_averages['chrF']:+.2f}%\n",
        "\n",
        "Sample-wise Wins:\n",
        "  • RAG wins:      {wins['RAG']} ({wins['RAG']/total_comparisons*100:.1f}%)\n",
        "  • LLM-only wins: {wins['LLM']} ({wins['LLM']/total_comparisons*100:.1f}%)\n",
        "\n",
        "Retrieval Effectiveness:\n",
        "  • Recall@10:     {avg_metrics['Recall@10']:.1f}% (RAG finds relevant in top 10)\n",
        "  • MRR:           {avg_metrics['MRR']:.1f}% (Average rank quality)\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "CONCLUSIONS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "{\"✅ The RAG system significantly outperforms LLM-only approach.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] + 5 else\n",
        " \"🟡 The RAG system shows moderate improvement over LLM-only.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] else\n",
        " \"❌ The LLM-only approach performs comparably or better than RAG.\"}\n",
        "\n",
        "{\"✅ Retrieval quality is good (Recall@10 > 40%).\" if avg_metrics['Recall@10'] > 40 else\n",
        " \"🟡 Retrieval quality is moderate (Recall@10 20-40%).\" if avg_metrics['Recall@10'] > 20 else\n",
        " \"❌ Retrieval quality needs improvement (Recall@10 < 20%).\"}\n",
        "\n",
        "📁 Output Files:\n",
        "1. rag_comprehensive_results.csv - RAG results with all metrics\n",
        "2. llm_only_comprehensive_results.csv - LLM-only results with all metrics\n",
        "3. complete_comparison_summary.csv - Full comparison table\n",
        "4. comparison_statistics.csv - Detailed statistical analysis\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\\n🎉 Complete evaluation finished!\")\n",
        "print(\"=\"*70 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "GT1lqUw3bNjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B37-VkA6CfgZ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubLgDHADCfdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94A10PxvCfat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DU4XhRBlCfYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijuTBOBgCfVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-q64xv_OCfS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qe0OXSHCCfQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}