{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73a5d0fd93964964803c5361405f1156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_765d653f084a4da9a47302e3c12f3ed7",
              "IPY_MODEL_9d5e53c22de54c38be31268d5446f04e",
              "IPY_MODEL_72eee6619b72496aae5f221bad35016f"
            ],
            "layout": "IPY_MODEL_cd7c2c076c98468e875a2292ee26ae5e"
          }
        },
        "765d653f084a4da9a47302e3c12f3ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec10cdf710ca43bc90a9f638e3fa4341",
            "placeholder": "​",
            "style": "IPY_MODEL_98b8ce37c778440cae681ff674d6d063",
            "value": "Loading weights: 100%"
          }
        },
        "9d5e53c22de54c38be31268d5446f04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92fc8d423f6848f39798c15b3d8d1a67",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_517856039dbb495cb8a2f9639539726b",
            "value": 391
          }
        },
        "72eee6619b72496aae5f221bad35016f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5f29ca6cd7426d9f0f8b5fdcebf232",
            "placeholder": "​",
            "style": "IPY_MODEL_b7a0f5278cb94f409e44c47c5c1c54e8",
            "value": " 391/391 [00:01&lt;00:00, 201.24it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "cd7c2c076c98468e875a2292ee26ae5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec10cdf710ca43bc90a9f638e3fa4341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b8ce37c778440cae681ff674d6d063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92fc8d423f6848f39798c15b3d8d1a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517856039dbb495cb8a2f9639539726b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e5f29ca6cd7426d9f0f8b5fdcebf232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a0f5278cb94f409e44c47c5c1c54e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24c84e3482d44777a180feb7aa31aac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05019e6c708049b29ce841aedb872ac4",
              "IPY_MODEL_3ce821c90f0f49d8ad686af56e1f4646",
              "IPY_MODEL_1d6e5a0dec2548e787dbec43dbd23c81"
            ],
            "layout": "IPY_MODEL_0bb8cfff416c4ec1a8828982d627ff46"
          }
        },
        "05019e6c708049b29ce841aedb872ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f844eae8b1ab47c4b57153e1142c1001",
            "placeholder": "​",
            "style": "IPY_MODEL_ea9edbf032be4a11a3bfb770ce1dbc69",
            "value": "Generating embeddings: 100%"
          }
        },
        "3ce821c90f0f49d8ad686af56e1f4646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8957204a1c845cc8865eff5bae97661",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9afd3aa2840b4f26bf372eb5ceb8fab2",
            "value": 282
          }
        },
        "1d6e5a0dec2548e787dbec43dbd23c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598e4ad124a74568bd2498cfc4bab24e",
            "placeholder": "​",
            "style": "IPY_MODEL_94b70bad084b444c8354a68877ef9b3c",
            "value": " 282/282 [01:53&lt;00:00,  2.69it/s]"
          }
        },
        "0bb8cfff416c4ec1a8828982d627ff46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f844eae8b1ab47c4b57153e1142c1001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9edbf032be4a11a3bfb770ce1dbc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8957204a1c845cc8865eff5bae97661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afd3aa2840b4f26bf372eb5ceb8fab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "598e4ad124a74568bd2498cfc4bab24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b70bad084b444c8354a68877ef9b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8686f0e758484ff284f5f24d194dbd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91de986f271b4f28b67567f047f57072",
              "IPY_MODEL_b473f14c71b44e288def6f8f7a7eadb0",
              "IPY_MODEL_15ac88e6e2c14a0ba4bfcccd4e1ad489"
            ],
            "layout": "IPY_MODEL_7fbc7d608ed544f3a9bbadd557dd15da"
          }
        },
        "91de986f271b4f28b67567f047f57072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc651bff5a58412d992e90e107f7f7ed",
            "placeholder": "​",
            "style": "IPY_MODEL_650a7c79009949ebbb73486b1a1b2d85",
            "value": "Preparing points: 100%"
          }
        },
        "b473f14c71b44e288def6f8f7a7eadb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0003ad52318a400fa454868557591e79",
            "max": 8997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c562e0f0be4d7b887f92085c7e603d",
            "value": 8997
          }
        },
        "15ac88e6e2c14a0ba4bfcccd4e1ad489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d478ec1b0e3c4eb2b0d0847a67f20d47",
            "placeholder": "​",
            "style": "IPY_MODEL_bffbab39736d42fb9ec40a0c5a5d520d",
            "value": " 8997/8997 [00:00&lt;00:00, 9653.17it/s]"
          }
        },
        "7fbc7d608ed544f3a9bbadd557dd15da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc651bff5a58412d992e90e107f7f7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650a7c79009949ebbb73486b1a1b2d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0003ad52318a400fa454868557591e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c562e0f0be4d7b887f92085c7e603d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d478ec1b0e3c4eb2b0d0847a67f20d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bffbab39736d42fb9ec40a0c5a5d520d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e641200f42f64692a28352deebea03b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35a8b99381634533b6728d8487443451",
              "IPY_MODEL_ba2fae734c944372a197662e25b65be9",
              "IPY_MODEL_4497928f12764d98b58fbb8c99c95bc9"
            ],
            "layout": "IPY_MODEL_67fd43595d6d4ddbac3c7d29bfc18ba2"
          }
        },
        "35a8b99381634533b6728d8487443451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64daade5f673479890a227184e06adf9",
            "placeholder": "​",
            "style": "IPY_MODEL_de799d547dfa454cbfacdf9f839d008d",
            "value": "Uploading batches: 100%"
          }
        },
        "ba2fae734c944372a197662e25b65be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa859bad43b41148478d7831c5d4cdb",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0543ba0c4d544a8ea7dc04810f098cee",
            "value": 90
          }
        },
        "4497928f12764d98b58fbb8c99c95bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17bf939b97b44af586d7657cf3449f0b",
            "placeholder": "​",
            "style": "IPY_MODEL_d8bec7f18e54427d9867feb9f24e730e",
            "value": " 90/90 [00:10&lt;00:00, 11.98it/s]"
          }
        },
        "67fd43595d6d4ddbac3c7d29bfc18ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64daade5f673479890a227184e06adf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de799d547dfa454cbfacdf9f839d008d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa859bad43b41148478d7831c5d4cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0543ba0c4d544a8ea7dc04810f098cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17bf939b97b44af586d7657cf3449f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8bec7f18e54427d9867feb9f24e730e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b587cf4e20f94b54be81fe1773069c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_839bd1a67dd344b4b435682aa23634ef",
              "IPY_MODEL_fbc3705001a74630950185e0b331d000",
              "IPY_MODEL_dc4a643beae24d01a6cb85395e16018e"
            ],
            "layout": "IPY_MODEL_294161a48f03402484f59d55650ef83a"
          }
        },
        "839bd1a67dd344b4b435682aa23634ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5924cf34e9764ee6aeb728f97f60c1ac",
            "placeholder": "​",
            "style": "IPY_MODEL_e06aa3af7b984bfb82196b64d00e6f2b",
            "value": "Loading weights: 100%"
          }
        },
        "fbc3705001a74630950185e0b331d000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccba5a667e4d4377a6eac811745bb5f8",
            "max": 258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22a9c521d7fa45d4bf4d3de158b92565",
            "value": 258
          }
        },
        "dc4a643beae24d01a6cb85395e16018e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb858ac9ff4149d79330c9575e6fa385",
            "placeholder": "​",
            "style": "IPY_MODEL_24caf66c0729402dad288892a171d739",
            "value": " 258/258 [00:00&lt;00:00, 391.29it/s, Materializing param=model.shared.weight]"
          }
        },
        "294161a48f03402484f59d55650ef83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5924cf34e9764ee6aeb728f97f60c1ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06aa3af7b984bfb82196b64d00e6f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccba5a667e4d4377a6eac811745bb5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a9c521d7fa45d4bf4d3de158b92565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb858ac9ff4149d79330c9575e6fa385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24caf66c0729402dad288892a171d739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3bc6b79f4594974b69d3e011c2047bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6121002b0b7347bca164fbe8c1050f5b",
              "IPY_MODEL_46f80f009cae473db9117e76850250bd",
              "IPY_MODEL_c1356cc4b09247b4af0e4f91f1b035e2"
            ],
            "layout": "IPY_MODEL_23a8cedf659d45ecb41c238a00ffe287"
          }
        },
        "6121002b0b7347bca164fbe8c1050f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc12ff6a8a5e4d47bf24f302ac5fa1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f892e57e9a4db6826f53eca12783cf",
            "value": "RAG Translation: 100%"
          }
        },
        "46f80f009cae473db9117e76850250bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff99de2505f34a83a6db33491d3e6df5",
            "max": 91,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7691d8cda054877a0a24e0ed446805a",
            "value": 91
          }
        },
        "c1356cc4b09247b4af0e4f91f1b035e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f53b53a7ae435aae317195bbc4e996",
            "placeholder": "​",
            "style": "IPY_MODEL_09f2c3fef2ca40f5899d9bc346ea9228",
            "value": " 91/91 [07:37&lt;00:00,  3.73s/it]"
          }
        },
        "23a8cedf659d45ecb41c238a00ffe287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc12ff6a8a5e4d47bf24f302ac5fa1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f892e57e9a4db6826f53eca12783cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff99de2505f34a83a6db33491d3e6df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7691d8cda054877a0a24e0ed446805a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0f53b53a7ae435aae317195bbc4e996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f2c3fef2ca40f5899d9bc346ea9228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae8d8622c02349b0b673c5930e02a9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e818b1ad59a346bbab5c1f591a0c6840",
              "IPY_MODEL_1d854b93c9384efaa780df9f1ee873ed",
              "IPY_MODEL_02a7be90c5d2401f8c841be781c5d5f0"
            ],
            "layout": "IPY_MODEL_f5eceb0b196249c3b48028ddb6003cd4"
          }
        },
        "e818b1ad59a346bbab5c1f591a0c6840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46701253d9cb450ab3abcf7c75bef865",
            "placeholder": "​",
            "style": "IPY_MODEL_eb81e8a7b7fc477fa0edfa2250ded902",
            "value": "Computing all metrics: 100%"
          }
        },
        "1d854b93c9384efaa780df9f1ee873ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef540f368b2b4cb1817dd72a7194b8a7",
            "max": 91,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d71e9bed46a94f2fb64e03a41dbc5c85",
            "value": 91
          }
        },
        "02a7be90c5d2401f8c841be781c5d5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddae0e35f8af41f18afd273d62f5b1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ede2a0037a3f46c6bad07bf1276446f9",
            "value": " 91/91 [00:00&lt;00:00, 661.69it/s]"
          }
        },
        "f5eceb0b196249c3b48028ddb6003cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46701253d9cb450ab3abcf7c75bef865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb81e8a7b7fc477fa0edfa2250ded902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef540f368b2b4cb1817dd72a7194b8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71e9bed46a94f2fb64e03a41dbc5c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddae0e35f8af41f18afd273d62f5b1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede2a0037a3f46c6bad07bf1276446f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b507fc0f5db47d090fba9a590968379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a4968878482476b9ac17b10791767f0",
              "IPY_MODEL_e7770ae1cd5e4e31a2b0af27394b2099",
              "IPY_MODEL_90f58378642b4896b2a1ccc997346c65"
            ],
            "layout": "IPY_MODEL_53e146cca61e408eb4b388bf72a79bdf"
          }
        },
        "0a4968878482476b9ac17b10791767f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6e2ad2b64b468692cd53e5a7cfebbb",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1998fd290d4ee3aa48c693420b9ba6",
            "value": "LLM-only translation: 100%"
          }
        },
        "e7770ae1cd5e4e31a2b0af27394b2099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8c4d36172b49d1b020a13293399c40",
            "max": 91,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebc98733d13b46108a73024ade0de9f7",
            "value": 91
          }
        },
        "90f58378642b4896b2a1ccc997346c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89613000ddfe406e9a99526e331f5a05",
            "placeholder": "​",
            "style": "IPY_MODEL_183c4c8e0e134ca7918c91f201e068a2",
            "value": " 91/91 [08:29&lt;00:00, 19.02s/it]"
          }
        },
        "53e146cca61e408eb4b388bf72a79bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6e2ad2b64b468692cd53e5a7cfebbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1998fd290d4ee3aa48c693420b9ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a8c4d36172b49d1b020a13293399c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc98733d13b46108a73024ade0de9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89613000ddfe406e9a99526e331f5a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183c4c8e0e134ca7918c91f201e068a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d408464a20476faa89d553823f91e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc64164e82084a72ba1a35678b0bd503",
              "IPY_MODEL_7373147373144a4ab4e7f7743cdcdc83",
              "IPY_MODEL_c730295bfd1b4affa3c4fa216752d0d1"
            ],
            "layout": "IPY_MODEL_820cf64ae61e4005b4bf90c49ffe711a"
          }
        },
        "dc64164e82084a72ba1a35678b0bd503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c32168f42844d1d9215e5c6243a8887",
            "placeholder": "​",
            "style": "IPY_MODEL_216e493d1d884d57a4a2d0239092ebf8",
            "value": "Computing LLM-only metrics: 100%"
          }
        },
        "7373147373144a4ab4e7f7743cdcdc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a9f423f9db4759b4e4928f658942c3",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0945a5439a6f44508c874d1dc34f8785",
            "value": 90
          }
        },
        "c730295bfd1b4affa3c4fa216752d0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cae6de18ade4f7abccc24ea5ab1407b",
            "placeholder": "​",
            "style": "IPY_MODEL_40bf43cd3693497aab182df95f63769a",
            "value": " 90/90 [00:00&lt;00:00, 608.23it/s]"
          }
        },
        "820cf64ae61e4005b4bf90c49ffe711a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c32168f42844d1d9215e5c6243a8887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e493d1d884d57a4a2d0239092ebf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61a9f423f9db4759b4e4928f658942c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0945a5439a6f44508c874d1dc34f8785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cae6de18ade4f7abccc24ea5ab1407b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40bf43cd3693497aab182df95f63769a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09ecd3a261f549fc876c00ec8b5a9dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d08cf5a0a82842f095313d2b5c842a34",
              "IPY_MODEL_4cabe24b5cac4c608d30fd7740533392",
              "IPY_MODEL_66772bf866a34d01a70a191cb3f73a26"
            ],
            "layout": "IPY_MODEL_25dfd17faaeb4e7285aad9e4a68548d3"
          }
        },
        "d08cf5a0a82842f095313d2b5c842a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1caa466edad4dd494d1f3490fc2b482",
            "placeholder": "​",
            "style": "IPY_MODEL_10d9491b93384fc89e4291ac33d34000",
            "value": "Testing K values: 100%"
          }
        },
        "4cabe24b5cac4c608d30fd7740533392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b6d7dc0f68489bbfa14b52aeaa9fdc",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a11fd13c09914a1689eb808a40ad8354",
            "value": 40
          }
        },
        "66772bf866a34d01a70a191cb3f73a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381c0bd04ac241198bf426da6e9be04e",
            "placeholder": "​",
            "style": "IPY_MODEL_3d8f1cab77e64955b5a79579163c4abf",
            "value": " 40/40 [02:42&lt;00:00,  5.13s/it]"
          }
        },
        "25dfd17faaeb4e7285aad9e4a68548d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1caa466edad4dd494d1f3490fc2b482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d9491b93384fc89e4291ac33d34000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4b6d7dc0f68489bbfa14b52aeaa9fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11fd13c09914a1689eb808a40ad8354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381c0bd04ac241198bf426da6e9be04e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8f1cab77e64955b5a79579163c4abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🏛️ TLA Dataset Preparation for Egyptian Transliteration RAG System\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 1: Install & Import Libraries"
      ],
      "metadata": {
        "id": "G8IS7D22A4pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Upgrade pip first\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# 🔹 Core Dependencies\n",
        "!pip install datasets>=2.18.0 --quiet\n",
        "!pip install transformers>=4.38.0 --quiet\n",
        "!pip install torch>=2.2.0 --quiet\n",
        "!pip install pandas>=2.2.0 --quiet\n",
        "!pip install numpy>=1.26.0 --quiet\n",
        "\n",
        "# 🔹 Translation\n",
        "!pip install sentencepiece>=0.2.0 --quiet\n",
        "\n",
        "# 🔹 Vector Database\n",
        "!pip install qdrant-client>=1.7.0 --quiet\n",
        "\n",
        "# 🔹 Ollama Cloud API\n",
        "!pip install httpx>=0.25.2,<0.26.0 --quiet\n",
        "!pip install ollama>=0.1.7 --quiet\n",
        "\n",
        "# 🔹 BM25 for Hybrid Search\n",
        "!pip install rank-bm25>=0.2.2 --quiet\n",
        "\n",
        "# 🔹 Utilities\n",
        "!pip install tqdm>=4.66.0 --quiet\n",
        "!pip install python-dotenv>=1.0.0 --quiet\n",
        "!pip install jupyter>=1.0.0 --quiet\n",
        "!pip install ipywidgets>=8.1.0 --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install matplotlib --quiet\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install nltk==3.9.2 --quiet\n",
        "!pip install rouge-score==0.1.2 --quiet\n",
        "!pip install sacrebleu==2.6.0 --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQ2QDe-BFUS",
        "outputId": "ac08b833-1d85-4933-b31d-a05969385cb3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 0.26.0: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic6N9oFNBnES",
        "outputId": "53b24a65-d069-4805-b211-eb18b383db4a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGQENGBIAMmK",
        "outputId": "b984b9a7-54bf-41fa-ffef-aeaa278f6f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
        "import subprocess\n",
        "import json\n",
        "import ollama\n",
        "\n",
        "print(\"✅ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## configuration\n",
        "# Models\n",
        "EMBEDDING_MODEL = \"BAAI/bge-m3\"  # Ollama local\n",
        "\n",
        "# Settings\n",
        "VECTOR_DIM = 1024\n",
        "TRAIN_SPLIT = 0.99  # 99% for training, 1% for testing\n",
        "\n",
        "# Egyptian character mapping (uniliteral signs)\n",
        "EGYPTIAN_CHAR_MAP = {\n",
        "    # Traditional → Normalized\n",
        "    'ꜣ': 'a',      # vulture (aleph)\n",
        "    'ꞽ': 'i',      # reed (yodh)\n",
        "    'y': 'y',      # double yodh\n",
        "    'ꜥ': 'a',      # arm (ayin)\n",
        "    'w': 'w',      # quail\n",
        "    'b': 'b',      # leg\n",
        "    'p': 'p',      # stool\n",
        "    'f': 'f',      # viper\n",
        "    'm': 'm',      # owl\n",
        "    'n': 'n',      # water\n",
        "    'r': 'r',      # mouth\n",
        "    'h': 'h',      # shelter\n",
        "    'ḥ': 'h',      # wick\n",
        "    'ḫ': 'kh',     # placenta\n",
        "    'ẖ': 'kh',     # belly\n",
        "    's': 's',      # cloth\n",
        "    'š': 'sh',     # pool\n",
        "    'ḳ': 'q',      # hill\n",
        "    'q': 'q',      # hill\n",
        "    'k': 'k',      # basket\n",
        "    'g': 'g',      # stand\n",
        "    't': 't',      # bun\n",
        "    'ṯ': 'tj',     # rope\n",
        "    'd': 'd',      # hand\n",
        "    'ḏ': 'dj',     # cobra\n",
        "\n",
        "    # Additional special characters\n",
        "    'ṭ': 't',\n",
        "    'ḍ': 'd',\n",
        "    'ṣ': 's',\n",
        "    'ẓ': 'z',\n",
        "    'ḥ': 'h',\n",
        "}\n",
        "\n",
        "# Suffixes to remove (pronouns and particles)\n",
        "SUFFIXES_TO_REMOVE = [\n",
        "    '=f',   # his/him\n",
        "    '=k',   # your/you (masc)\n",
        "    '=ṯ',   # your/you (fem)\n",
        "    '=s',   # her/it\n",
        "    '=sn',  # their/them\n",
        "    '=ꞽ',   # my/me\n",
        "    '=n',   # our/us\n",
        "    '=tn',  # your/you (pl)\n",
        "    '=fꞽ',  # variant\n",
        "]\n",
        "\n",
        "print(f\"🔧 Configuration loaded\")\n",
        "print(f\"   Training split: {TRAIN_SPLIT*100}%\")\n",
        "print(f\"   Embedding model: {EMBEDDING_MODEL}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4dDTE0dAyUy",
        "outputId": "98c7839f-8944-4d30-8755-f11184f301f2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Configuration loaded\n",
            "   Training split: 99.0%\n",
            "   Embedding model: BAAI/bge-m3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 3: Load dataset\n",
        "print(\"📥 Loading TLA dataset from HuggingFace...\")\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(f\"✅ Loaded {len(df)} records\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nSample record:\")\n",
        "print(df.iloc[0][['transliteration', 'translation', 'UPOS']].to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGgDrQdBuND",
        "outputId": "5178f8a1-4275-4b3d-8a9a-b5b64f865af6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading TLA dataset from HuggingFace...\n",
            "✅ Loaded 12773 records\n",
            "\n",
            "Columns: ['hieroglyphs', 'transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'dateNotBefore', 'dateNotAfter']\n",
            "\n",
            "Sample record:\n",
            "{'transliteration': 'nḏ (w)di̯ r =s', 'translation': '(es) werde zerrieben, (es) werde darauf gelegt.', 'UPOS': 'VERB VERB ADP PRON'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 4 : Data Cleaning\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🧹 STEP 1: Removing unwanted columns\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Remove unwanted columns\n",
        "columns_to_drop = ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
        "df_clean = df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(f\"✅ Removed columns: {columns_to_drop}\")\n",
        "print(f\"   Remaining columns: {list(df_clean.columns)}\")\n",
        "\n",
        "# Remove rows with missing critical data\n",
        "print(\"\\n🧹 STEP 2: Removing rows with missing data\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.dropna(subset=['transliteration', 'translation'])\n",
        "df_clean = df_clean[df_clean['transliteration'].str.strip() != '']\n",
        "df_clean = df_clean[df_clean['translation'].str.strip() != '']\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} rows with missing data\")\n",
        "print(f\"   Records remaining: {len(df_clean)}\")\n",
        "\n",
        "# Remove duplicates\n",
        "print(\"\\n🧹 STEP 3: Removing duplicates\")\n",
        "initial_count = len(df_clean)\n",
        "\n",
        "df_clean = df_clean.drop_duplicates(subset=['transliteration'], keep='first')\n",
        "\n",
        "print(f\"✅ Removed {initial_count - len(df_clean)} duplicate records\")\n",
        "print(f\"   Unique records: {len(df_clean)}\")\n",
        "\n",
        "df_clean = df_clean.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkwYUNi4BwPK",
        "outputId": "56a5947e-548d-421a-e081-acca823113e4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🧹 STEP 1: Removing unwanted columns\n",
            "======================================================================\n",
            "✅ Removed columns: ['hieroglyphs', 'dateNotBefore', 'dateNotAfter']\n",
            "   Remaining columns: ['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation']\n",
            "\n",
            "🧹 STEP 2: Removing rows with missing data\n",
            "✅ Removed 0 rows with missing data\n",
            "   Records remaining: 12773\n",
            "\n",
            "🧹 STEP 3: Removing duplicates\n",
            "✅ Removed 3685 duplicate records\n",
            "   Unique records: 9088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 5: Transliteration Normalization\n",
        "def normalize_transliteration(text):\n",
        "    \"\"\"\n",
        "    Normalize Egyptian transliteration:\n",
        "    1. Remove brackets\n",
        "    2. Lowercase\n",
        "    3. Map special characters\n",
        "    4. Remove suffixes\n",
        "    5. Clean spaces\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == '':\n",
        "        return \"\"\n",
        "\n",
        "    # Step 1: Remove brackets (but keep content)\n",
        "    text = re.sub(r'[()]', '', text)\n",
        "\n",
        "    # Step 2: Normalize Unicode (NFC form)\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "    # REMOVE combining marks (important for di̯, etc.)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "\n",
        "    # Step 3: Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Step 4: Map Egyptian characters\n",
        "    for egy_char, normalized in EGYPTIAN_CHAR_MAP.items():\n",
        "        text = text.replace(egy_char.lower(), normalized)\n",
        "\n",
        "    # Step 5: Remove suffixes (pronouns/particles)\n",
        "    for suffix in SUFFIXES_TO_REMOVE:\n",
        "        # Match suffix at word boundaries or before spaces/dots\n",
        "        pattern = re.escape(suffix) + r'(?=[\\s\\.]|$)'\n",
        "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Step 6: Clean up extra spaces and dots\n",
        "    text = re.sub(r'\\.+', '.', text)  # Multiple dots to single\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces to single\n",
        "    text = text.strip('. ')  # Remove leading/trailing dots and spaces\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔤 STEP 4: Normalizing transliterations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test normalization on sample\n",
        "sample_text = df_clean.iloc[0]['transliteration']\n",
        "normalized_sample = normalize_transliteration(sample_text)\n",
        "\n",
        "print(f\"\\n📝 Sample normalization:\")\n",
        "print(f\"   Original:   {sample_text}\")\n",
        "print(f\"   Normalized: {normalized_sample}\")\n",
        "\n",
        "# Apply normalization to entire dataset\n",
        "print(f\"\\n🔄 Normalizing {len(df_clean)} transliterations...\")\n",
        "\n",
        "df_clean['transliteration_normalized'] = df_clean['transliteration'].apply(\n",
        "    normalize_transliteration\n",
        ")\n",
        "\n",
        "\n",
        "# Remove empty normalizations\n",
        "df_clean = df_clean[df_clean['transliteration_normalized'].str.len() > 0]\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Normalization complete!\")\n",
        "print(f\"   Valid records: {len(df_clean)}\")\n",
        "\n",
        "# Show more examples\n",
        "print(f\"\\n📋 Sample normalizations:\")\n",
        "for i in range(min(5, len(df_clean))):\n",
        "    orig = df_clean.iloc[i]['transliteration']\n",
        "    norm = df_clean.iloc[i]['transliteration_normalized']\n",
        "    print(f\"   {i+1}. {orig[:40]:40} → {norm[:40]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXrqavRoCKQ7",
        "outputId": "3112d43d-1262-4136-da63-f2d1f44f9a0c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🔤 STEP 4: Normalizing transliterations\n",
            "======================================================================\n",
            "\n",
            "📝 Sample normalization:\n",
            "   Original:   nḏ (w)di̯ r =s\n",
            "   Normalized: ndj wdi r\n",
            "\n",
            "🔄 Normalizing 9088 transliterations...\n",
            "✅ Normalization complete!\n",
            "   Valid records: 9088\n",
            "\n",
            "📋 Sample normalizations:\n",
            "   1. nḏ (w)di̯ r =s                           → ndj wdi r\n",
            "   2. n ṯw ꞽm =sn                              → n tjw im\n",
            "   3. ḫꜣ m tʾ ḥnq.t kꜣ(.PL) ꜣpd(.PL) n ꞽmꜣḫ ꞽm → kha m tʾ hnq.t ka.pl apd.pl n imakh im.i\n",
            "   4. ꜥḥꜥ                                      → aha\n",
            "   5. (w)sꞽr wnꞽs m n =k ꞽr.t-ḥr.w ꞽꜥb n =k s( → wsir wnis m n ir.t-hr.w iab n si ir rʾ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 6: Train/ test split\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"📊 STEP 5: Creating train/test split ({TRAIN_SPLIT*100}%/{(1-TRAIN_SPLIT)*100}%)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Shuffle dataset\n",
        "df_clean = df_clean.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split\n",
        "split_idx = int(len(df_clean) * TRAIN_SPLIT)\n",
        "df_train = df_clean.iloc[:split_idx].copy()\n",
        "df_test = df_clean.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"✅ Split complete!\")\n",
        "print(f\"   Training set: {len(df_train)} records ({len(df_train)/len(df_clean)*100:.1f}%)\")\n",
        "print(f\"   Test set:     {len(df_test)} records ({len(df_test)/len(df_clean)*100:.1f}%)\")\n",
        "\n",
        "# Save test set for later evaluation\n",
        "df_test.to_csv('tla_test_set.csv', index=False)\n",
        "print(f\"\\n💾 Test set saved to: tla_test_set.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axmvNF_5CQqq",
        "outputId": "7798a876-72da-4475-e8b5-8ada086f43c6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 STEP 5: Creating train/test split (99.0%/1.0000000000000009%)\n",
            "======================================================================\n",
            "✅ Split complete!\n",
            "   Training set: 8997 records (99.0%)\n",
            "   Test set:     91 records (1.0%)\n",
            "\n",
            "💾 Test set saved to: tla_test_set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 7: Generate Embedding\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"\\n📥 Loading embedding model...\")\n",
        "# Load model (do this ONCE before the loop)\n",
        "embedding_model = SentenceTransformer('BAAI/bge-m3')\n",
        "print(f\"✅ Model loaded: BAAI/bge-m3\")\n",
        "\n",
        "def get_embedding_fast(text):\n",
        "    \"\"\"Generate embedding using sentence-transformers\"\"\"\n",
        "    try:\n",
        "        # Generate embedding\n",
        "        embedding = embedding_model.encode(text, normalize_embeddings=True)\n",
        "        return embedding.tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return np.random.randn(VECTOR_DIM).tolist()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"🔢 STEP 6: Generating embeddings for {len(df_train)} records\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n⚙️ Using model: BAAI/bge-m3\")\n",
        "print(f\"   Vector dimension: {VECTOR_DIM}\")\n",
        "\n",
        "# Generate embeddings in batches (MUCH faster!)\n",
        "batch_size = 32\n",
        "all_embeddings = []\n",
        "\n",
        "for i in tqdm(range(0, len(df_train), batch_size), desc=\"Generating embeddings\"):\n",
        "    batch_end = min(i + batch_size, len(df_train))\n",
        "    batch_texts = df_train.iloc[i:batch_end]['transliteration_normalized'].tolist()\n",
        "\n",
        "    try:\n",
        "        # Process entire batch at once (FAST!)\n",
        "        batch_embeddings = embedding_model.encode(\n",
        "            batch_texts,\n",
        "            normalize_embeddings=True,\n",
        "            show_progress_bar=False\n",
        "        )\n",
        "        all_embeddings.extend(batch_embeddings.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Batch error at {i}: {e}\")\n",
        "        # Fallback: process individually\n",
        "        for text in batch_texts:\n",
        "            all_embeddings.append(get_embedding_fast(text))\n",
        "\n",
        "df_train['embedding'] = all_embeddings\n",
        "\n",
        "print(f\"\\n✅ Embedding generation complete!\")\n",
        "print(f\"   Total: {len(all_embeddings)} embeddings\")\n",
        "print(f\"   Dimension: {len(all_embeddings[0])}\")\n",
        "\n",
        "# Verify\n",
        "sample_embedding = all_embeddings[0]\n",
        "print(f\"\\n📊 Sample embedding (first 10 values):\")\n",
        "print(f\"   {sample_embedding[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "73a5d0fd93964964803c5361405f1156",
            "765d653f084a4da9a47302e3c12f3ed7",
            "9d5e53c22de54c38be31268d5446f04e",
            "72eee6619b72496aae5f221bad35016f",
            "cd7c2c076c98468e875a2292ee26ae5e",
            "ec10cdf710ca43bc90a9f638e3fa4341",
            "98b8ce37c778440cae681ff674d6d063",
            "92fc8d423f6848f39798c15b3d8d1a67",
            "517856039dbb495cb8a2f9639539726b",
            "2e5f29ca6cd7426d9f0f8b5fdcebf232",
            "b7a0f5278cb94f409e44c47c5c1c54e8",
            "24c84e3482d44777a180feb7aa31aac4",
            "05019e6c708049b29ce841aedb872ac4",
            "3ce821c90f0f49d8ad686af56e1f4646",
            "1d6e5a0dec2548e787dbec43dbd23c81",
            "0bb8cfff416c4ec1a8828982d627ff46",
            "f844eae8b1ab47c4b57153e1142c1001",
            "ea9edbf032be4a11a3bfb770ce1dbc69",
            "d8957204a1c845cc8865eff5bae97661",
            "9afd3aa2840b4f26bf372eb5ceb8fab2",
            "598e4ad124a74568bd2498cfc4bab24e",
            "94b70bad084b444c8354a68877ef9b3c"
          ]
        },
        "id": "GxC1-gvOCXVI",
        "outputId": "78050843-c2b4-4eab-acdd-5c12959f38f9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📥 Loading embedding model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a5d0fd93964964803c5361405f1156"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded: BAAI/bge-m3\n",
            "\n",
            "======================================================================\n",
            "🔢 STEP 6: Generating embeddings for 8997 records\n",
            "======================================================================\n",
            "\n",
            "⚙️ Using model: BAAI/bge-m3\n",
            "   Vector dimension: 1024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24c84e3482d44777a180feb7aa31aac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Embedding generation complete!\n",
            "   Total: 8997 embeddings\n",
            "   Dimension: 1024\n",
            "\n",
            "📊 Sample embedding (first 10 values):\n",
            "   [0.009475680999457836, 0.012296928092837334, -0.03066054731607437, 0.0029091022443026304, -0.038571588695049286, -0.0011071120388805866, -0.002732239430770278, -0.013377217575907707, 0.02956884168088436, -0.00481629790738225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 8: Exract Lemmas from Lemmettizaton\n",
        "\n",
        "def extract_lemmas(lemmatization_text):\n",
        "    \"\"\"Extract lemma words from lemmatization field\"\"\"\n",
        "    if not isinstance(lemmatization_text, str):\n",
        "        return []\n",
        "\n",
        "    lemmas = []\n",
        "    parts = lemmatization_text.split()\n",
        "\n",
        "    for part in parts:\n",
        "        if '|' in part:\n",
        "            lemma_id, lemma_word = part.split('|', 1)\n",
        "            # Skip suffixes/particles\n",
        "            if not lemma_word.startswith('='):\n",
        "                lemmas.append(lemma_word)\n",
        "\n",
        "    return lemmas\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📝 STEP 7: Extracting lemmas\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_train['lemmas'] = df_train['lemmatization'].apply(extract_lemmas)\n",
        "\n",
        "print(f\"✅ Lemma extraction complete!\")\n",
        "print(f\"\\n📋 Sample lemmas:\")\n",
        "for i in range(min(3, len(df_train))):\n",
        "    lemmas = df_train.iloc[i]['lemmas']\n",
        "    print(f\"   {i+1}. {lemmas[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_10wqplYVZzG",
        "outputId": "4f003cb1-6dd5-463a-919f-d900ba556a93"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📝 STEP 7: Extracting lemmas\n",
            "======================================================================\n",
            "✅ Lemma extraction complete!\n",
            "\n",
            "📋 Sample lemmas:\n",
            "   1. ['ḥm-nṯr-Ḫwi̯=f-wꞽ', 'ḥr.ꞽ-sštꜣ']\n",
            "   2. ['zꜣ', 'sms.w', 'ꞽm.ꞽ-rʾ-zẖꜣ.ww-ꜥ-n-nswt', 'Sšm-nfr']\n",
            "   3. ['zbi̯', 'ṯw', 'm', 'ꜥḥꜥ.w', 'nfr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 9: Setup Qdrant Vector Database\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Setting up Qdrant database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize Qdrant (in-memory for development)\n",
        "# For production, use: QdrantClient(host=\"localhost\", port=6333)\n",
        "\n",
        "# Initialize persistent Qdrant (local)\n",
        "#qdrant = QdrantClient(path=\"qdrant_db\")\n",
        "\n",
        "# Initialize Qdrant (in-memory for development)\n",
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"✅ Qdrant client initialized (in-memory)\")\n",
        "\n",
        "# Create collection\n",
        "collection_name = \"egyptian_transliterations\"\n",
        "\n",
        "qdrant.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(\n",
        "        size=VECTOR_DIM,\n",
        "        distance=Distance.COSINE\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"✅ Collection created: {collection_name}\")\n",
        "print(f\"   Vector size: {VECTOR_DIM}\")\n",
        "print(f\"   Distance metric: COSINE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UG3AUbNCdQf",
        "outputId": "bd495370-4480-46b7-ea03-cfb40abfdda4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Setting up Qdrant database\n",
            "======================================================================\n",
            "✅ Qdrant client initialized (in-memory)\n",
            "✅ Collection created: egyptian_transliterations\n",
            "   Vector size: 1024\n",
            "   Distance metric: COSINE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 10: upload data to qdrant\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\" Uploading {len(df_train)} records to Qdrant\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare points\n",
        "points = []\n",
        "\n",
        "for idx, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Preparing points\"):\n",
        "    point = PointStruct(\n",
        "        id=idx,\n",
        "        vector=row['embedding'],\n",
        "        payload={\n",
        "            \"transliteration_original\": row['transliteration'],\n",
        "            \"transliteration_normalized\": row['transliteration_normalized'],\n",
        "            \"lemmas\": row['lemmas'],\n",
        "            \"UPOS\": row.get('UPOS', ''),\n",
        "            \"glossing\": row.get('glossing', ''),\n",
        "            \"translation_de\": row['translation']\n",
        "        }\n",
        "    )\n",
        "    points.append(point)\n",
        "\n",
        "# Upload in batches\n",
        "batch_size = 100\n",
        "print(f\"\\n📦 Uploading in batches of {batch_size}...\")\n",
        "\n",
        "for i in tqdm(range(0, len(points), batch_size), desc=\"Uploading batches\"):\n",
        "    batch = points[i:i+batch_size]\n",
        "    qdrant.upsert(\n",
        "        collection_name=collection_name,\n",
        "        points=batch\n",
        "    )\n",
        "\n",
        "print(f\"\\n✅ Upload complete!\")\n",
        "print(f\"   Total records in database: {len(points)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "8686f0e758484ff284f5f24d194dbd28",
            "91de986f271b4f28b67567f047f57072",
            "b473f14c71b44e288def6f8f7a7eadb0",
            "15ac88e6e2c14a0ba4bfcccd4e1ad489",
            "7fbc7d608ed544f3a9bbadd557dd15da",
            "cc651bff5a58412d992e90e107f7f7ed",
            "650a7c79009949ebbb73486b1a1b2d85",
            "0003ad52318a400fa454868557591e79",
            "c2c562e0f0be4d7b887f92085c7e603d",
            "d478ec1b0e3c4eb2b0d0847a67f20d47",
            "bffbab39736d42fb9ec40a0c5a5d520d",
            "e641200f42f64692a28352deebea03b9",
            "35a8b99381634533b6728d8487443451",
            "ba2fae734c944372a197662e25b65be9",
            "4497928f12764d98b58fbb8c99c95bc9",
            "67fd43595d6d4ddbac3c7d29bfc18ba2",
            "64daade5f673479890a227184e06adf9",
            "de799d547dfa454cbfacdf9f839d008d",
            "7fa859bad43b41148478d7831c5d4cdb",
            "0543ba0c4d544a8ea7dc04810f098cee",
            "17bf939b97b44af586d7657cf3449f0b",
            "d8bec7f18e54427d9867feb9f24e730e"
          ]
        },
        "id": "KX1tF45TCoj4",
        "outputId": "9a6507bd-5160-4be8-cd0c-1733d83e638b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Uploading 8997 records to Qdrant\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preparing points:   0%|          | 0/8997 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8686f0e758484ff284f5f24d194dbd28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Uploading in batches of 100...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading batches:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e641200f42f64692a28352deebea03b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Upload complete!\n",
            "   Total records in database: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 11 : verify Database\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ STEP 10: Verifying database\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "count_info = qdrant.count(\n",
        "    collection_name=collection_name,\n",
        "    exact=True\n",
        ")\n",
        "\n",
        "print(f\"📊 Collection statistics:\")\n",
        "print(f\"   Name: {collection_name}\")\n",
        "print(f\"   Points count: {count_info.count}\")\n",
        "\n",
        "# Test search\n",
        "print(f\"\\n🔍 Testing search functionality...\")\n",
        "\n",
        "test_query = df_train.iloc[0]['transliteration_normalized']\n",
        "test_embedding = df_train.iloc[0]['embedding']\n",
        "\n",
        "search_results = qdrant.query_points(\n",
        "    collection_name=collection_name,\n",
        "    query=test_embedding,\n",
        "    limit=3\n",
        ").points\n",
        "\n",
        "print(f\"\\n📝 Test query: {test_query}\")\n",
        "print(f\"\\n🎯 Top 3 search results:\")\n",
        "\n",
        "for i, result in enumerate(search_results, 1):\n",
        "    print(f\"\\n   {i}. Score: {result.score:.4f}\")\n",
        "    print(f\"      Transliteration: {result.payload['transliteration_normalized']}\")\n",
        "    print(f\"      Translation: {result.payload['translation_de'][:60]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMuTNW6qCulU",
        "outputId": "1af281da-8fd5-49ae-dd0c-e0a35bd34e50"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ STEP 10: Verifying database\n",
            "======================================================================\n",
            "📊 Collection statistics:\n",
            "   Name: egyptian_transliterations\n",
            "   Points count: 8997\n",
            "\n",
            "🔍 Testing search functionality...\n",
            "\n",
            "📝 Test query: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "\n",
            "🎯 Top 3 search results:\n",
            "\n",
            "   1. Score: 1.0000\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses....\n",
            "\n",
            "   2. Score: 0.9444\n",
            "      Transliteration: hm-ntjr-khwi=f-wi hr.i-sshta ka=i-n.i-nswt\n",
            "      Translation: Priester des Cheops und Hüter des Geheimnisses Kai-ni-nisut....\n",
            "\n",
            "   3. Score: 0.8495\n",
            "      Transliteration: wt.i hr.i-sshta\n",
            "      Translation: Balsamierer, Hüter des Geheimnisses...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🔮 PART 2: RAG Translation Pipeline\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 12: Install Additional Libraries"
      ],
      "metadata": {
        "id": "yvZqYFT0C9I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load Ollama API Key securely from Colab Secrets\n",
        "OLLAMA_API_KEY = userdata.get('OLLAMA_API_KEY')\n",
        "\n",
        "if OLLAMA_API_KEY is None:\n",
        "    raise ValueError(\"❌ OLLAMA_API_KEY not found in Colab Secrets\")\n",
        "\n",
        "# Set env var for libraries that expect it\n",
        "os.environ['OLLAMA_API_KEY'] = OLLAMA_API_KEY\n",
        "\n",
        "# Configuration\n",
        "LLM_MODEL = \"qwen3-vl:235b-instruct-cloud\" #\"gpt-oss:120b-cloud\" #\"qwen3-next:80b-cloud\" #\"qwen3-vl:235b-cloud\"\n",
        "TOP_K_RESULTS = 30\n",
        "\n",
        "print(\"🔧 RAG Pipeline Configuration:\")\n",
        "print(f\"   LLM Model: {LLM_MODEL}\")\n",
        "print(f\"   Top-K Results: {TOP_K_RESULTS}\")\n",
        "print(f\"   API Key: ✅ Loaded securely from Colab Secrets\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvesV_2PC5oN",
        "outputId": "96f9528b-8990-4898-ea61-f68181a5b3f4"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 RAG Pipeline Configuration:\n",
            "   LLM Model: qwen3-vl:235b-instruct-cloud\n",
            "   Top-K Results: 30\n",
            "   API Key: ✅ Loaded securely from Colab Secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miYKvim1EuUN",
        "outputId": "21cef0ba-734d-4352-bc23-f42192a53ee1"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank-bm25) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 14: prepare BM25 index for Sparce Search\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" Building BM25 index for sparse search\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Tokenize corpus for BM25\n",
        "corpus_texts = df_train['transliteration_normalized'].tolist()\n",
        "tokenized_corpus = [text.split() for text in corpus_texts]\n",
        "\n",
        "# Build BM25 index\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(f\"✅ BM25 index built!\")\n",
        "print(f\"   Documents indexed: {len(tokenized_corpus)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmx9860CDGEV",
        "outputId": "54ee2425-99c6-422e-a68c-c3d3d3c9a34f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " Building BM25 index for sparse search\n",
            "======================================================================\n",
            "✅ BM25 index built!\n",
            "   Documents indexed: 8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 15: Hybrid Search Function\n",
        "def hybrid_search(query_text, query_embedding, top_k=10, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Perform hybrid search: Dense (Vector) + Sparse (BM25)\n",
        "\n",
        "    Args:\n",
        "        query_text: Normalized transliteration query\n",
        "        query_embedding: Embedding vector of query\n",
        "        top_k: Number of results to return\n",
        "        alpha: Weight for dense search (1-alpha for sparse)\n",
        "\n",
        "    Returns:\n",
        "        List of search results with scores\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Dense Search (Vector Similarity)\n",
        "    dense_results = qdrant.query_points(\n",
        "        collection_name=collection_name,\n",
        "        query=query_embedding,\n",
        "        limit=top_k * 2\n",
        "    ).points\n",
        "\n",
        "\n",
        "    # 2. Sparse Search (BM25)\n",
        "    query_tokens = query_text.split()\n",
        "    bm25_scores = bm25.get_scores(query_tokens)\n",
        "\n",
        "    # Get top BM25 indices\n",
        "    top_bm25_indices = np.argsort(bm25_scores)[-top_k*2:][::-1]\n",
        "\n",
        "    # 3. Reciprocal Rank Fusion (RRF)\n",
        "    combined_scores = {}\n",
        "\n",
        "    # Add dense scores\n",
        "    for rank, result in enumerate(dense_results):\n",
        "        doc_id = result.id\n",
        "        rrf_score = 1 / (rank + 60)  # RRF formula\n",
        "        combined_scores[doc_id] = {\n",
        "            'rrf_score': rrf_score,\n",
        "            'dense_score': result.score,\n",
        "            'sparse_score': 0,\n",
        "            'payload': result.payload\n",
        "        }\n",
        "\n",
        "    # Add sparse scores\n",
        "    for rank, idx in enumerate(top_bm25_indices):\n",
        "        if idx in combined_scores:\n",
        "            combined_scores[idx]['rrf_score'] += 1 / (rank + 60)\n",
        "            combined_scores[idx]['sparse_score'] = bm25_scores[idx]\n",
        "        else:\n",
        "            # Retrieve payload from Qdrant\n",
        "            point = qdrant.retrieve(\n",
        "                collection_name=collection_name,\n",
        "                ids=[int(idx)]\n",
        "            )\n",
        "            if point:\n",
        "                combined_scores[idx] = {\n",
        "                    'rrf_score': 1 / (rank + 60),\n",
        "                    'dense_score': 0,\n",
        "                    'sparse_score': bm25_scores[idx],\n",
        "                    'payload': point[0].payload\n",
        "                }\n",
        "\n",
        "    # 4. Sort by combined RRF score\n",
        "    sorted_results = sorted(\n",
        "        combined_scores.items(),\n",
        "        key=lambda x: x[1]['rrf_score'],\n",
        "        reverse=True\n",
        "    )[:top_k]\n",
        "\n",
        "    # 5. Format results\n",
        "    final_results = []\n",
        "    for doc_id, scores in sorted_results:\n",
        "        final_results.append({\n",
        "            'id': doc_id,\n",
        "            'rrf_score': scores['rrf_score'],\n",
        "            'dense_score': scores['dense_score'],\n",
        "            'sparse_score': scores['sparse_score'],\n",
        "            'payload': scores['payload']\n",
        "        })\n",
        "\n",
        "    return final_results\n",
        "\n",
        "print(\"✅ Hybrid search function ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fcxk7HDOIe",
        "outputId": "ed46a996-a345-46ac-e2ee-01ed81d9ade6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid search function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 16: LLM Translation Function\n",
        "import requests\n",
        "OLLAMA_API_URL = \"https://ollama.com/api/chat\"\n",
        "\n",
        "def translate_with_llm(query_original, query_normalized, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Use LLM to translate Egyptian to German based on retrieved examples\n",
        "    \"\"\"\n",
        "\n",
        "    # Build examples context (same as before)\n",
        "    examples_text = \"\"\n",
        "    for i, example in enumerate(retrieved_examples, 1):\n",
        "        payload = example['payload']\n",
        "        examples_text += f\"\"\"\n",
        "Example {i}:\n",
        "- Original: {payload['transliteration_original']}\n",
        "- Normalized: {payload['transliteration_normalized']}\n",
        "- Lemmas: {', '.join(payload['lemmas'][:5]) if payload['lemmas'] else 'N/A'}\n",
        "- POS Tags: {payload['UPOS']}\n",
        "- Glossing: {payload['glossing']}\n",
        "- German: {payload['translation_de']}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    # Build prompt (same as before)\n",
        "    prompt = f\"\"\"You are a senior linguist specializing in Earlier Egyptian (Old Egyptian & Early Middle Egyptian),\n",
        "with strong expertise in morphology, syntax, and historical semantics.\n",
        "\n",
        "Your task is to translate an Earlier Egyptian transliteration into German\n",
        "using retrieved linguistic examples ONLY as structural and semantic guidance.\n",
        "\n",
        "=====================================\n",
        "QUERY TO TRANSLATE\n",
        "=====================================\n",
        "\n",
        "Normalized Transliteration:\n",
        "{query_normalized}\n",
        "\n",
        "=====================================\n",
        "RETRIEVED DATABASE EXAMPLES\n",
        "=====================================\n",
        "{examples_text}\n",
        "\n",
        "=====================================\n",
        "INSTRUCTIONS\n",
        "=====================================\n",
        "Follow these steps carefully:\n",
        "\n",
        "1. Linguistic Analysis\n",
        "   - Identify the grammatical category of each word (verb, noun, particle, suffix, etc.)\n",
        "   - Detect verb tense/aspect, suffix pronouns, and syntactic order (VSO, SVO, nominal clause).\n",
        "\n",
        "2. Morphological Alignment\n",
        "   - Compare suffixes, verb forms, and particles with the retrieved examples.\n",
        "   - Use lemma meanings as semantic hints, not literal translations.\n",
        "\n",
        "3. Translation Construction\n",
        "   - Produce a fluent and historically plausible German translation.\n",
        "   - Adapt word order to correct German syntax.\n",
        "   - Prefer linguistically conservative interpretations over speculative ones.\n",
        "\n",
        "4. Uncertainty Handling\n",
        "   - If multiple readings are possible, choose the most likely one.\n",
        "   - Briefly mention ambiguity only if it materially affects meaning.\n",
        "\n",
        "=====================================\n",
        "STRICT RULES\n",
        "=====================================\n",
        "- DO NOT copy any German translation from the examples.\n",
        "- DO NOT mention example numbers or quote them.\n",
        "- DO NOT add explanations unless uncertainty exists.\n",
        "- DO NOT hallucinate missing words.\n",
        "- Base your output strictly on Earlier Egyptian grammar.\n",
        "\n",
        "=====================================\n",
        "OUTPUT FORMAT (STRICT)\n",
        "=====================================\n",
        "German Translation: <one clear German sentence>\n",
        "Confidence: High | Medium | Low\n",
        "Notes: <only if confidence is Medium or Low>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Call Ollama Cloud API with CORRECT endpoint\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        # Use Ollama's native format (not OpenAI format)\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist specializing in translating Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            # Ollama format uses 'message' -> 'content'\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Extract German translation\n",
        "            import re\n",
        "            match = re.search(r'German Translation:\\s*(.+?)(?:\\n|$)', llm_output, re.IGNORECASE)\n",
        "            if match:\n",
        "                german_translation = match.group(1).strip()\n",
        "                return german_translation, llm_output\n",
        "            else:\n",
        "                return llm_output.split('\\n')[0].strip(), llm_output\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            print(f\"   Response: {response.text}\")\n",
        "            return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "B1hvYIFHE-0N"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## part 17: German to English Tranlslation\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading German→English translation model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load MarianMT model\n",
        "print(\"📥 Loading MarianMT model...\")\n",
        "de_en_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
        "de_en_tokenizer = MarianTokenizer.from_pretrained(de_en_model_name)\n",
        "de_en_model = MarianMTModel.from_pretrained(de_en_model_name)\n",
        "\n",
        "print(f\"✅ Model loaded: {de_en_model_name}\")\n",
        "\n",
        "def translate_german_to_english(german_text):\n",
        "    \"\"\"Translate German to English using MarianMT\"\"\"\n",
        "    try:\n",
        "        # Tokenize\n",
        "        inputs = de_en_tokenizer(\n",
        "            german_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Generate translation\n",
        "        outputs = de_en_model.generate(**inputs)\n",
        "\n",
        "        # Decode\n",
        "        english_text = de_en_tokenizer.decode(\n",
        "            outputs[0],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        return english_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ German→English translation ready!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "b587cf4e20f94b54be81fe1773069c2f",
            "839bd1a67dd344b4b435682aa23634ef",
            "fbc3705001a74630950185e0b331d000",
            "dc4a643beae24d01a6cb85395e16018e",
            "294161a48f03402484f59d55650ef83a",
            "5924cf34e9764ee6aeb728f97f60c1ac",
            "e06aa3af7b984bfb82196b64d00e6f2b",
            "ccba5a667e4d4377a6eac811745bb5f8",
            "22a9c521d7fa45d4bf4d3de158b92565",
            "eb858ac9ff4149d79330c9575e6fa385",
            "24caf66c0729402dad288892a171d739"
          ]
        },
        "id": "xMd-YxkhFE3l",
        "outputId": "1fcea965-1e82-4c09-d6a7-0e5db3ddde0d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Loading German→English translation model\n",
            "======================================================================\n",
            "📥 Loading MarianMT model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/258 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b587cf4e20f94b54be81fe1773069c2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded: Helsinki-NLP/opus-mt-de-en\n",
            "✅ German→English translation ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## part 18: Complete Translation pipeline\n",
        "\n",
        "def translate_egyptian_to_english(query_original, show_details=True):\n",
        "    \"\"\"\n",
        "    Complete pipeline: Egyptian → German → English\n",
        "\n",
        "    Args:\n",
        "        query_original: Original Egyptian transliteration\n",
        "        show_details: Print intermediate steps\n",
        "\n",
        "    Returns:\n",
        "        dict with results\n",
        "    \"\"\"\n",
        "\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"📝 TRANSLATING: {query_original}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Normalize query\n",
        "    query_normalized = normalize_transliteration(query_original)\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n1️⃣ Normalization:\")\n",
        "        print(f\"   Original:   {query_original}\")\n",
        "        print(f\"   Normalized: {query_normalized}\")\n",
        "\n",
        "    # Step 2: Generate embedding\n",
        "    query_embedding = embedding_model.encode(\n",
        "        query_normalized,\n",
        "        normalize_embeddings=True\n",
        "    ).tolist()\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"\\n2️⃣ Embedding generated (dim={len(query_embedding)})\")\n",
        "\n",
        "    # Step 3: Hybrid search\n",
        "    if show_details:\n",
        "        print(f\"\\n3️⃣ Hybrid search (Dense + BM25)...\")\n",
        "\n",
        "    search_results = hybrid_search(\n",
        "        query_text=query_normalized,\n",
        "        query_embedding=query_embedding,\n",
        "        top_k=TOP_K_RESULTS\n",
        "    )\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   ✅ Found {len(search_results)} results\")\n",
        "        print(f\"\\n   📊 Top 3 matches:\")\n",
        "        for i, result in enumerate(search_results[:3], 1):\n",
        "            print(f\"\\n   {i}. RRF Score: {result['rrf_score']:.4f}\")\n",
        "            print(f\"      Transliteration: {result['payload']['transliteration_normalized']}\")\n",
        "            print(f\"      German: {result['payload']['translation_de'][:50]}...\")\n",
        "\n",
        "    # Step 4: LLM Translation (German)\n",
        "    if show_details:\n",
        "        print(f\"\\n4️⃣ LLM Translation (Egyptian → German)...\")\n",
        "\n",
        "    german_translation, llm_full_output = translate_with_llm(\n",
        "        query_original=query_original,\n",
        "        query_normalized=query_normalized,\n",
        "        retrieved_examples=search_results\n",
        "    )\n",
        "\n",
        "    if not german_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'LLM translation failed'\n",
        "        }\n",
        "\n",
        "    if show_details:\n",
        "        print(f\"   🇩🇪 German: {german_translation}\")\n",
        "\n",
        "    # Step 5: German → English\n",
        "    if show_details:\n",
        "        print(f\"\\n5️⃣ Translation (German → English)...\")\n",
        "\n",
        "    english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "    if not english_translation:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'German→English translation failed'\n",
        "        }\n",
        "\n",
        "    # Final result\n",
        "    if show_details:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"✅ TRANSLATION COMPLETE\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"🏛️ Egyptian:  {query_original}\")\n",
        "        print(f\"🔤 Normalized: {query_normalized}\")\n",
        "        print(f\"🇩🇪 German:    {german_translation}\")\n",
        "        print(f\"🇬🇧 English:   {english_translation}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'query_original': query_original,\n",
        "        'query_normalized': query_normalized,\n",
        "        'german': german_translation,\n",
        "        'english': english_translation,\n",
        "        'llm_output': llm_full_output,\n",
        "        'top_matches': search_results[:3]\n",
        "    }\n",
        "\n",
        "print(\"✅ Complete translation pipeline ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlcLe4THFK2M",
        "outputId": "c6b7e4cf-a03a-4ff6-b712-d51f3b315044"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Complete translation pipeline ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 📊 EVALUATION METRICS FOR EGYPTIAN TRANSLITERATION RAG SYSTEM\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 📦 Part 24: Install Evaluation Libraries"
      ],
      "metadata": {
        "id": "ijT_2lAu0s24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_test))\n",
        "print(df_test.columns.tolist())\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "9031fae0-4e61-4f90-f1ea-a79da2655cad",
        "id": "Er9sILDF0s26"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91\n",
            "['transliteration', 'lemmatization', 'UPOS', 'glossing', 'translation', 'transliteration_normalized']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     transliteration  \\\n",
              "0  smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...   \n",
              "1  ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...   \n",
              "2  ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...   \n",
              "3                                    šdi̯.t kꜣ rḫ.yt   \n",
              "4  (w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...   \n",
              "\n",
              "                                       lemmatization  \\\n",
              "0  400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...   \n",
              "1  113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...   \n",
              "2  91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...   \n",
              "3                  158710|šdi̯ 162890|kꜣ 95820|rḫ.yt   \n",
              "4  49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...   \n",
              "\n",
              "                                                UPOS  \\\n",
              "0                               NOUN NOUN NOUN PROPN   \n",
              "1  NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...   \n",
              "2  VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...   \n",
              "3                                     VERB NOUN NOUN   \n",
              "4   NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON   \n",
              "\n",
              "                                            glossing  \\\n",
              "0                               TITL TITL TITL PERSN   \n",
              "1  N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....   \n",
              "2  V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...   \n",
              "3                                      V\\inf N.m N.f   \n",
              "4  TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...   \n",
              "\n",
              "                                         translation  \\\n",
              "0  Der Einzige Freund, der Vorlesepriester, der V...   \n",
              "1  Tausend an Geflügel, tausend an Geflügel, taus...   \n",
              "2  Sei gegrüßt, Min bei seinen Prozessionen, mit ...   \n",
              "3        Darbringen der Speisen (für die) Untertanen   \n",
              "4  Osiris Neith, nimm dir das Horusauge, zu dem e...   \n",
              "\n",
              "                          transliteration_normalized  \n",
              "0        smr-wa.ti khr.i-hab.t im.i-rʾ-iaw hr.w-khwi  \n",
              "1  kha apd kha apd kha mnkh.t kha ih kha tʾ hnq.t...  \n",
              "2  i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...  \n",
              "3                                   shdi.t ka rkh.yt  \n",
              "4                 wsr.w ni.t m n ir.t-hr.w shmi.t ir  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2b7843d-216c-4c00-8ae8-3ad4a66ad5dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transliteration</th>\n",
              "      <th>lemmatization</th>\n",
              "      <th>UPOS</th>\n",
              "      <th>glossing</th>\n",
              "      <th>translation</th>\n",
              "      <th>transliteration_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw...</td>\n",
              "      <td>400142|smr-wꜥ.tꞽ 124340|ẖr.ꞽ-ḥꜣb.t 400011|ꞽm.ꞽ...</td>\n",
              "      <td>NOUN NOUN NOUN PROPN</td>\n",
              "      <td>TITL TITL TITL PERSN</td>\n",
              "      <td>Der Einzige Freund, der Vorlesepriester, der V...</td>\n",
              "      <td>smr-wa.ti khr.i-hab.t im.i-rʾ-iaw hr.w-khwi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ḫꜣ ꜣpd ḫꜣ ꜣpd ḫꜣ mnḫ.t ḫꜣ ꞽḥ ḫꜣ tʾ ḥnq.t pꜣ.t ...</td>\n",
              "      <td>113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ 107|ꜣpd 113110|ḫꜣ ...</td>\n",
              "      <td>NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN NOUN N...</td>\n",
              "      <td>N.m N.m N.m N.m N.m N.f N.m N.m N.m N.m N.f N....</td>\n",
              "      <td>Tausend an Geflügel, tausend an Geflügel, taus...</td>\n",
              "      <td>kha apd kha apd kha mnkh.t kha ih kha tʾ hnq.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ꞽ:nḏ ḥr =k mnw m pr.t.PL =f qꜣ šw.tꞽ zꜣ wsꞽr m...</td>\n",
              "      <td>91190|nḏ+(ḥr) 107510|ḥr 10110|=k 70530|Mnw 643...</td>\n",
              "      <td>VERB NOUN PRON PROPN ADP NOUN PRON ADJ NOUN NO...</td>\n",
              "      <td>V N.m:stpr -2sg.m DIVN PREP N.f:pl:stpr -3sg.m...</td>\n",
              "      <td>Sei gegrüßt, Min bei seinen Prozessionen, mit ...</td>\n",
              "      <td>i:ndj hr mnw m pr.t.pl qa shw.ti za wsir msi.n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>šdi̯.t kꜣ rḫ.yt</td>\n",
              "      <td>158710|šdi̯ 162890|kꜣ 95820|rḫ.yt</td>\n",
              "      <td>VERB NOUN NOUN</td>\n",
              "      <td>V\\inf N.m N.f</td>\n",
              "      <td>Darbringen der Speisen (für die) Untertanen</td>\n",
              "      <td>shdi.t ka rkh.yt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(w)sr(.w) n(ꞽ).t m n =k ꞽr(.t)-ḥr.w šmi̯.t =f ...</td>\n",
              "      <td>49461|Wsꞽr 702960|Nꞽ.t 67780|mꞽ 400055|n 10110...</td>\n",
              "      <td>NOUN PROPN VERB ADP PRON NOUN VERB PRON ADP PRON</td>\n",
              "      <td>TITL PERSN V\\imp.sg PREP:stpr -2sg.m N.f V\\rel...</td>\n",
              "      <td>Osiris Neith, nimm dir das Horusauge, zu dem e...</td>\n",
              "      <td>wsr.w ni.t m n ir.t-hr.w shmi.t ir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b7843d-216c-4c00-8ae8-3ad4a66ad5dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2b7843d-216c-4c00-8ae8-3ad4a66ad5dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2b7843d-216c-4c00-8ae8-3ad4a66ad5dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 91,\n  \"fields\": [\n    {\n      \"column\": \"transliteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"m \\u1e25nb\\ua723b\\ua723.w \\u1e25r b\\ua723\\u1e96.t\",\n          \"\\u1e0f\\u1e0f.tw =s n p\\ua723y =\\ua7bd sn z\\ua723-nswt \\u1e25\\ua723.t\\ua7bd-\\ua725 sbk-n\\u1e2bt\",\n          \"(\\ua7bd)r(.\\ua7bdt-\\ua7bd)\\u1e2b(.t)-nswt n.\\ua7bd-s\\ua7bd-r\\u1e0fi\\u032f(.w)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatization\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"64410|m 882920|\\u1e25nb\\ua723b\\ua723 400090|\\u1e25r 53580|b\\ua723\\u1e96.t\",\n          \"96700|r\\u1e0fi\\u032f 10090|=s 400055|n 550021|p\\ua723y= 10030|=\\ua7bd 136230|sn 450223|z\\ua723-nswt 100520|\\u1e25\\ua723.t\\ua7bd-\\ua725 550004|Sbk-n\\u1e2bt.w\",\n          \"95750|\\ua7bdr.\\ua7bdt-\\ua7bd\\u1e2b.t-nswt 713172|N.\\ua7bd-s\\ua7bd-r\\u1e0f.w\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UPOS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83,\n        \"samples\": [\n          \"ADJ NOUN ADJ NOUN ADP PRON\",\n          \"NOUN NOUN NOUN PROPN\",\n          \"VERB ADP PRON PART PRON PROPN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glossing\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"N.m PREP-adjz:m.pl N.m PREP ROYLN dem.m.sg\",\n          \"TITL TITL TITL PERSN\",\n          \"V\\\\tam.act:stpr -2sg.m N.m:stpr -2sg.m V\\\\tam-pass:stpr -3sg.m PREP:stpr -2sg.m PREP V\\\\rel.f.sg:stpr -2sg.m ADJ:f.sg PREP N.m TITL V\\\\ptcp.pass.m.sg N.m:stpr -3sg.m ADV V\\\\ptcp.pass.m.sg:stpr -3sg.m PREP-adjz:m.sg N.f:stpr -3sg.m TITL PERSN N.m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"Schl\\u00e4ngel dich nicht auf das Gl\\u00e4nzende!\",\n          \"Es (=dieses Amt) ist meinem Bruder, dem K\\u00f6nigssohn und Grafen Sobeknacht zu geben.\",\n          \"Die Verwalterin des K\\u00f6nigsverm\\u00f6gens Ni-si-redju.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transliteration_normalized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"m hnbaba.w hr bakh.t\",\n          \"djdj.tw n pay =i sn za-nswt ha.ti-a sbk-nkht\",\n          \"ir.it-ikh.t-nswt n.i-si-rdji.w\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 19: Install Evaluation Libraries\n",
        "import sys\n",
        "print(\"\\n📦 Installing all evaluation libraries...\")\n",
        "eval_packages = [\n",
        "    'nltk',\n",
        "    'rouge-score',\n",
        "    'sacrebleu',\n",
        "]\n",
        "\n",
        "for package in eval_packages:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', package, '--break-system-packages', '-q'])\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from sacrebleu.metrics import CHRF\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data\n",
        "print(\"📥 Downloading NLTK data...\")\n",
        "try:\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "    print(\"✅ NLTK data ready!\")\n",
        "except:\n",
        "    print(\"⚠️ NLTK download warning (may still work)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4db8a5-deb8-454e-987f-bbaf1377453a",
        "id": "6rYtTR2g0s26"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Installing all evaluation libraries...\n",
            "📥 Downloading NLTK data...\n",
            "✅ NLTK data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 20: Define Evaluation Metrics\n",
        "\n",
        "# ============================================================================\n",
        "# TRANSLATION QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_bleu(reference, hypothesis):\n",
        "    \"\"\"Calculate BLEU score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        smoothing = SmoothingFunction()\n",
        "        bleu_score = sentence_bleu(\n",
        "            [reference_tokens],\n",
        "            hypothesis_tokens,\n",
        "            smoothing_function=smoothing.method1\n",
        "        )\n",
        "        return bleu_score * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_rouge(reference, hypothesis):\n",
        "    \"\"\"Calculate ROUGE scores\"\"\"\n",
        "    try:\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        scores = scorer.score(reference, hypothesis)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure * 100,\n",
        "            'rouge2': scores['rouge2'].fmeasure * 100,\n",
        "            'rougeL': scores['rougeL'].fmeasure * 100\n",
        "        }\n",
        "    except:\n",
        "        return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "def calculate_meteor(reference, hypothesis):\n",
        "    \"\"\"Calculate METEOR score (0-100)\"\"\"\n",
        "    try:\n",
        "        reference_tokens = reference.lower().split()\n",
        "        hypothesis_tokens = hypothesis.lower().split()\n",
        "        meteor = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "        return meteor * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_chrf(reference, hypothesis):\n",
        "    \"\"\"Calculate chrF score (0-100)\"\"\"\n",
        "    try:\n",
        "        chrf = CHRF()\n",
        "        score = chrf.sentence_score(hypothesis, [reference])\n",
        "        return score.score  # Already 0-100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_exact_match(reference, hypothesis):\n",
        "    \"\"\"Calculate exact match\"\"\"\n",
        "    return 100.0 if reference.strip().lower() == hypothesis.strip().lower() else 0.0\n",
        "\n",
        "def calculate_word_overlap(reference, hypothesis):\n",
        "    \"\"\"Calculate word-level overlap percentage\"\"\"\n",
        "    try:\n",
        "        ref_words = set(reference.lower().split())\n",
        "        hyp_words = set(hypothesis.lower().split())\n",
        "        if len(ref_words) == 0:\n",
        "            return 0.0\n",
        "        overlap = len(ref_words.intersection(hyp_words))\n",
        "        return (overlap / len(ref_words)) * 100\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# ============================================================================\n",
        "# RETRIEVAL QUALITY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Calculate Recall@K - checks if reference appears in top K results\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "        k_values: List of K values to calculate recall for\n",
        "\n",
        "    Returns:\n",
        "        Dict with Recall@K for each K\n",
        "    \"\"\"\n",
        "    recalls = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        found = False\n",
        "        for i, example in enumerate(retrieved_examples[:k]):\n",
        "            if i >= len(retrieved_examples):\n",
        "                break\n",
        "            retrieved_german = example['payload']['translation_de']\n",
        "            # Check if the reference matches (exact or high similarity)\n",
        "            if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        recalls[f'recall@{k}'] = 100.0 if found else 0.0\n",
        "\n",
        "    return recalls\n",
        "\n",
        "def calculate_mrr(reference_german, retrieved_examples):\n",
        "    \"\"\"\n",
        "    Calculate Mean Reciprocal Rank (MRR)\n",
        "\n",
        "    MRR = 1 / rank of first relevant result\n",
        "    If no relevant result found, MRR = 0\n",
        "\n",
        "    Args:\n",
        "        reference_german: The ground truth German translation\n",
        "        retrieved_examples: List of retrieved examples from RAG\n",
        "\n",
        "    Returns:\n",
        "        MRR score (0-100)\n",
        "    \"\"\"\n",
        "    for i, example in enumerate(retrieved_examples):\n",
        "        retrieved_german = example['payload']['translation_de']\n",
        "        # Check if this is a relevant result\n",
        "        if reference_german.strip().lower() == retrieved_german.strip().lower():\n",
        "            # Rank starts at 1, not 0\n",
        "            mrr = 1.0 / (i + 1)\n",
        "            return mrr * 100  # Convert to percentage\n",
        "\n",
        "    # No relevant result found\n",
        "    return 0.0\n",
        "\n",
        "def calculate_average_retrieval_score(retrieved_examples, top_k=10):\n",
        "    \"\"\"\n",
        "    Calculate average retrieval score from top K results\n",
        "\n",
        "    Args:\n",
        "        retrieved_examples: List of retrieved examples with scores\n",
        "        top_k: Number of top results to consider\n",
        "\n",
        "    Returns:\n",
        "        Average RRF score (0-100)\n",
        "    \"\"\"\n",
        "    if not retrieved_examples:\n",
        "        return 0.0\n",
        "\n",
        "    scores = [example['rrf_score'] for example in retrieved_examples[:top_k]]\n",
        "    avg_score = np.mean(scores) if scores else 0.0\n",
        "    return avg_score * 100  # Convert to percentage\n",
        "\n",
        "print(\"✅ All evaluation metrics defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c3972d-f154-44bd-fba9-8ef5f6413e83",
        "id": "6N026luY0s27"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All evaluation metrics defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🔄 Part 21: Process RAG Test Set with ALL Metrics\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING RAG TEST SET WITH ALL METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load test set\n",
        "print(\"\\n📥 Loading test set...\")\n",
        "df_test = pd.read_csv('tla_test_set.csv')\n",
        "print(f\"✅ Loaded {len(df_test)} test records\")\n",
        "\n",
        "# Initialize results storage\n",
        "test_results = []\n",
        "failed_translations = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} test samples...\")\n",
        "print(\"⏱️ Estimated time: ~{:.1f} minutes\\n\".format(len(df_test) * 3 / 60))\n",
        "\n",
        "# Process each test sample\n",
        "for idx in tqdm(range(len(df_test)), desc=\"RAG Translation\"):\n",
        "    try:\n",
        "        # Get query\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        # Translate Egyptian → German → English using RAG\n",
        "        result = translate_egyptian_to_english(\n",
        "            query_original=query_original,\n",
        "            show_details=False\n",
        "        )\n",
        "\n",
        "        if result['success']:\n",
        "            # Translate reference German → English\n",
        "            reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "            if reference_english:\n",
        "                # Store results (including retrieval info)\n",
        "                test_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'transliteration_normalized': result['query_normalized'],\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german': result['german'],\n",
        "                    'predicted_english': result['english'],\n",
        "                    'top_matches': result['top_matches']  # Store retrieval results\n",
        "                })\n",
        "            else:\n",
        "                failed_translations.append({\n",
        "                    'sample_id': idx,\n",
        "                    'reason': 'Reference translation to English failed'\n",
        "                })\n",
        "        else:\n",
        "            failed_translations.append({\n",
        "                'sample_id': idx,\n",
        "                'reason': result.get('error', 'RAG translation failed')\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_translations.append({\n",
        "            'sample_id': idx,\n",
        "            'reason': f'Exception: {str(e)}'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "# Create results DataFrame\n",
        "df_test_results = pd.DataFrame(test_results)\n",
        "\n",
        "print(f\"\\n✅ RAG Processing complete!\")\n",
        "print(f\"   Successful: {len(test_results)}\")\n",
        "print(f\"   Failed: {len(failed_translations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "f3bc6b79f4594974b69d3e011c2047bf",
            "6121002b0b7347bca164fbe8c1050f5b",
            "46f80f009cae473db9117e76850250bd",
            "c1356cc4b09247b4af0e4f91f1b035e2",
            "23a8cedf659d45ecb41c238a00ffe287",
            "bc12ff6a8a5e4d47bf24f302ac5fa1b1",
            "e0f892e57e9a4db6826f53eca12783cf",
            "ff99de2505f34a83a6db33491d3e6df5",
            "b7691d8cda054877a0a24e0ed446805a",
            "b0f53b53a7ae435aae317195bbc4e996",
            "09f2c3fef2ca40f5899d9bc346ea9228"
          ]
        },
        "outputId": "f6144ace-f9c4-4385-b416-06c7bebe6588",
        "id": "oAlpBXKv0s28"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING RAG TEST SET WITH ALL METRICS\n",
            "======================================================================\n",
            "\n",
            "📥 Loading test set...\n",
            "✅ Loaded 91 test records\n",
            "\n",
            "🔄 Processing 91 test samples...\n",
            "⏱️ Estimated time: ~4.5 minutes\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG Translation:   0%|          | 0/91 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3bc6b79f4594974b69d3e011c2047bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ RAG Processing complete!\n",
            "   Successful: 91\n",
            "   Failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 22: Calculate ALL Metrics (Translation + Retrieval)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING ALL METRICS FOR RAG SYSTEM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "metrics_list = []\n",
        "\n",
        "print(f\"\\n🔄 Computing all metrics for {len(df_test_results)} translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_test_results.iterrows(), total=len(df_test_results), desc=\"Computing all metrics\"):\n",
        "    reference_english = row['reference_english']\n",
        "    hypothesis_english = row['predicted_english']\n",
        "    reference_german = row['reference_german']\n",
        "    retrieved_examples = row['top_matches']\n",
        "\n",
        "    # Calculate translation quality metrics\n",
        "    rouge_scores = calculate_rouge(reference_english, hypothesis_english)\n",
        "\n",
        "    # Calculate retrieval quality metrics\n",
        "    recall_scores = calculate_recall_at_k(reference_german, retrieved_examples, k_values=[1, 3, 5, 10, 20])\n",
        "    mrr_score = calculate_mrr(reference_german, retrieved_examples)\n",
        "    avg_retrieval_score = calculate_average_retrieval_score(retrieved_examples, top_k=10)\n",
        "\n",
        "    # Combine all metrics\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference_english, hypothesis_english),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference_english, hypothesis_english),\n",
        "        'chrf': calculate_chrf(reference_english, hypothesis_english),\n",
        "        'exact_match': calculate_exact_match(reference_english, hypothesis_english),\n",
        "        'word_overlap': calculate_word_overlap(reference_english, hypothesis_english),\n",
        "        # Retrieval Quality Metrics\n",
        "        'recall@1': recall_scores['recall@1'],\n",
        "        'recall@3': recall_scores['recall@3'],\n",
        "        'recall@5': recall_scores['recall@5'],\n",
        "        'recall@10': recall_scores['recall@10'],\n",
        "        'recall@20': recall_scores['recall@20'],\n",
        "        'mrr': mrr_score,\n",
        "        'avg_retrieval_score': avg_retrieval_score\n",
        "    }\n",
        "\n",
        "    metrics_list.append(metrics)\n",
        "\n",
        "# Create metrics DataFrame\n",
        "df_metrics = pd.DataFrame(metrics_list)\n",
        "\n",
        "print(\"✅ All metrics calculation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "ae8d8622c02349b0b673c5930e02a9d9",
            "e818b1ad59a346bbab5c1f591a0c6840",
            "1d854b93c9384efaa780df9f1ee873ed",
            "02a7be90c5d2401f8c841be781c5d5f0",
            "f5eceb0b196249c3b48028ddb6003cd4",
            "46701253d9cb450ab3abcf7c75bef865",
            "eb81e8a7b7fc477fa0edfa2250ded902",
            "ef540f368b2b4cb1817dd72a7194b8a7",
            "d71e9bed46a94f2fb64e03a41dbc5c85",
            "ddae0e35f8af41f18afd273d62f5b1ab",
            "ede2a0037a3f46c6bad07bf1276446f9"
          ]
        },
        "outputId": "fed6ffa1-1712-4b5b-b2d4-ec2dbb237ebc",
        "id": "jMItc1vl0s28"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CALCULATING ALL METRICS FOR RAG SYSTEM\n",
            "======================================================================\n",
            "\n",
            "🔄 Computing all metrics for 91 translations...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing all metrics:   0%|          | 0/91 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae8d8622c02349b0b673c5930e02a9d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All metrics calculation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 📈 Part 23: Display Complete RAG System Summary\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for all metrics\n",
        "avg_metrics = {\n",
        "    # Translation Quality\n",
        "    'BLEU': df_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_metrics['meteor'].mean(),\n",
        "    'chrF': df_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_metrics['word_overlap'].mean(),\n",
        "    # Retrieval Quality\n",
        "    'Recall@1': df_metrics['recall@1'].mean(),\n",
        "    'Recall@3': df_metrics['recall@3'].mean(),\n",
        "    'Recall@5': df_metrics['recall@5'].mean(),\n",
        "    'Recall@10': df_metrics['recall@10'].mean(),\n",
        "    'Recall@20': df_metrics['recall@20'].mean(),\n",
        "    'MRR': df_metrics['mrr'].mean(),\n",
        "    'Avg Retrieval Score': df_metrics['avg_retrieval_score'].mean()\n",
        "}\n",
        "\n",
        "# Quality emoji function\n",
        "def get_quality_emoji(metric_name, score):\n",
        "    \"\"\"Get quality emoji based on metric and score\"\"\"\n",
        "    if metric_name in ['Recall@1', 'Recall@3', 'Exact Match']:\n",
        "        return '🟢' if score > 20 else '🟡' if score > 5 else '🔴'\n",
        "    elif 'Recall' in metric_name:\n",
        "        return '🟢' if score > 40 else '🟡' if score > 20 else '🔴'\n",
        "    elif metric_name == 'MRR':\n",
        "        return '🟢' if score > 30 else '🟡' if score > 15 else '🔴'\n",
        "    else:\n",
        "        return '🟢' if score > 50 else '🟡' if score > 30 else '🔴'\n",
        "\n",
        "print(\"\\n📊 TRANSLATION QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "translation_metrics = ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'METEOR', 'chrF', 'Exact Match', 'Word Overlap']\n",
        "for metric in translation_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n📊 RETRIEVAL QUALITY METRICS:\")\n",
        "print(\"─\" * 70)\n",
        "retrieval_metrics = ['Recall@1', 'Recall@3', 'Recall@5', 'Recall@10', 'Recall@20', 'MRR', 'Avg Retrieval Score']\n",
        "for metric in retrieval_metrics:\n",
        "    score = avg_metrics[metric]\n",
        "    emoji = get_quality_emoji(metric, score)\n",
        "    print(f\"   {emoji} {metric:20s}: {score:6.2f}%\")\n",
        "\n",
        "# Distribution statistics for key metrics\n",
        "print(\"\\n📈 KEY METRIC DISTRIBUTIONS:\")\n",
        "print(\"─\" * 70)\n",
        "\n",
        "for metric_name, metric_col in [('BLEU', 'bleu'), ('METEOR', 'meteor'), ('Recall@10', 'recall@10'), ('MRR', 'mrr')]:\n",
        "    scores = df_metrics[metric_col]\n",
        "    print(f\"\\n{metric_name}:\")\n",
        "    print(f\"   Min:    {scores.min():6.2f}%\")\n",
        "    print(f\"   25%:    {scores.quantile(0.25):6.2f}%\")\n",
        "    print(f\"   Median: {scores.median():6.2f}%\")\n",
        "    print(f\"   75%:    {scores.quantile(0.75):6.2f}%\")\n",
        "    print(f\"   Max:    {scores.max():6.2f}%\")\n",
        "    print(f\"   Std:    {scores.std():6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35941d8d-9cce-47bf-f5f3-2d564f279613",
        "id": "LPbKFNEM0s28"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 COMPLETE RAG SYSTEM EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "📊 TRANSLATION QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 BLEU                :  23.70%\n",
            "   🟢 ROUGE-1             :  53.93%\n",
            "   🟡 ROUGE-2             :  36.53%\n",
            "   🟢 ROUGE-L             :  52.31%\n",
            "   🟡 METEOR              :  39.32%\n",
            "   🟡 chrF                :  45.35%\n",
            "   🟡 Exact Match         :   9.89%\n",
            "   🟡 Word Overlap        :  43.36%\n",
            "\n",
            "📊 RETRIEVAL QUALITY METRICS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   🔴 Recall@1            :   2.20%\n",
            "   🔴 Recall@3            :   2.20%\n",
            "   🔴 Recall@5            :   2.20%\n",
            "   🔴 Recall@10           :   2.20%\n",
            "   🔴 Recall@20           :   2.20%\n",
            "   🔴 MRR                 :   2.20%\n",
            "   🔴 Avg Retrieval Score :   2.90%\n",
            "\n",
            "📈 KEY METRIC DISTRIBUTIONS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "\n",
            "BLEU:\n",
            "   Min:      0.00%\n",
            "   25%:      2.87%\n",
            "   Median:   8.31%\n",
            "   75%:     35.90%\n",
            "   Max:    100.00%\n",
            "   Std:     29.20%\n",
            "\n",
            "METEOR:\n",
            "   Min:      0.00%\n",
            "   25%:     10.11%\n",
            "   Median:  31.04%\n",
            "   75%:     59.91%\n",
            "   Max:     99.95%\n",
            "   Std:     32.32%\n",
            "\n",
            "Recall@10:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:    100.00%\n",
            "   Std:     14.74%\n",
            "\n",
            "MRR:\n",
            "   Min:      0.00%\n",
            "   25%:      0.00%\n",
            "   Median:   0.00%\n",
            "   75%:      0.00%\n",
            "   Max:    100.00%\n",
            "   Std:     14.74%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 24: Visual Comparison Charts\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 VISUAL METRIC COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Translation metrics\n",
        "print(\"\\n🎯 Translation Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[:8]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "# Retrieval metrics\n",
        "print(\"\\n🔍 Retrieval Quality:\")\n",
        "print(\"─\" * 70)\n",
        "for metric, score in list(avg_metrics.items())[8:]:\n",
        "    bar_length = int((score / 100) * 50)\n",
        "    bar = '█' * bar_length\n",
        "    print(f\"{metric:20s} {bar} {score:6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce81875-fccc-4334-9ea5-5eddb70b619b",
        "id": "Z7dY6VQL0s29"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 VISUAL METRIC COMPARISON\n",
            "======================================================================\n",
            "\n",
            "🎯 Translation Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "BLEU                 ███████████  23.70%\n",
            "ROUGE-1              ██████████████████████████  53.93%\n",
            "ROUGE-2              ██████████████████  36.53%\n",
            "ROUGE-L              ██████████████████████████  52.31%\n",
            "METEOR               ███████████████████  39.32%\n",
            "chrF                 ██████████████████████  45.35%\n",
            "Exact Match          ████   9.89%\n",
            "Word Overlap         █████████████████████  43.36%\n",
            "\n",
            "🔍 Retrieval Quality:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Recall@1             █   2.20%\n",
            "Recall@3             █   2.20%\n",
            "Recall@5             █   2.20%\n",
            "Recall@10            █   2.20%\n",
            "Recall@20            █   2.20%\n",
            "MRR                  █   2.20%\n",
            "Avg Retrieval Score  █   2.90%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 25: Process LLM-Only Test Set\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 PROCESSING LLM-ONLY TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# LLM-only translation function (simplified)\n",
        "\n",
        "def translate_with_llm_only(query_original, query_normalized):\n",
        "    \"\"\"\n",
        "    Direct LLM translation WITHOUT RAG retrieval\n",
        "    Only uses the LLM's knowledge\n",
        "    \"\"\"\n",
        "\n",
        "    # Simple prompt without retrieved examples\n",
        "    prompt = f\"\"\"You are an expert linguist specialized in Earlier Egyptian grammar and historical translation.\n",
        "\n",
        "Translate the following Earlier Egyptian transliteration into German.\n",
        "Use a conservative, grammar-based interpretation.\n",
        "Do not modernize meanings or add implied words.\n",
        "\n",
        "Egyptian Transliteration:\n",
        "{query_original}\n",
        "\n",
        "Output ONLY the German translation.\n",
        "Do not add explanations, comments, or alternative readings.\n",
        "\n",
        "German Translation:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {OLLAMA_API_KEY}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": LLM_MODEL,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert Ancient Egyptian linguist. Translate Earlier Egyptian to German.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            OLLAMA_API_URL,\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=240\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            llm_output = result['message']['content']\n",
        "\n",
        "            # Clean the response\n",
        "            german_translation = llm_output.strip()\n",
        "            # Remove \"German Translation:\" prefix if present\n",
        "            german_translation = re.sub(r'^German Translation:\\s*', '', german_translation, flags=re.IGNORECASE)\n",
        "\n",
        "            return german_translation.strip()\n",
        "        else:\n",
        "            print(f\"❌ API Error: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ LLM-only translation function ready!\")\n",
        "\n",
        "# Process LLM-only\n",
        "llm_only_results = []\n",
        "llm_only_failed = []\n",
        "\n",
        "print(f\"\\n🔄 Processing {len(df_test)} samples with LLM-only...\")\n",
        "\n",
        "for idx in tqdm(range(len(df_test)), desc=\"LLM-only translation\"):\n",
        "    try:\n",
        "        query_original = df_test.iloc[idx]['transliteration']\n",
        "        query_normalized = normalize_transliteration(query_original)\n",
        "        reference_german = df_test.iloc[idx]['translation']\n",
        "\n",
        "        german_translation = translate_with_llm_only(query_original, query_normalized)\n",
        "\n",
        "        if german_translation:\n",
        "            english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "            if english_translation:\n",
        "                # Get reference English from RAG results\n",
        "                if idx < len(df_test_results):\n",
        "                    reference_english = df_test_results.iloc[idx]['reference_english']\n",
        "                else:\n",
        "                    reference_english = translate_german_to_english(reference_german)\n",
        "\n",
        "                llm_only_results.append({\n",
        "                    'sample_id': idx,\n",
        "                    'transliteration': query_original,\n",
        "                    'reference_german': reference_german,\n",
        "                    'reference_english': reference_english,\n",
        "                    'predicted_german_llm': german_translation,\n",
        "                    'predicted_english_llm': english_translation\n",
        "                })\n",
        "            else:\n",
        "                llm_only_failed.append({'sample_id': idx, 'reason': 'English translation failed'})\n",
        "        else:\n",
        "            llm_only_failed.append({'sample_id': idx, 'reason': 'LLM translation failed'})\n",
        "\n",
        "    except Exception as e:\n",
        "        llm_only_failed.append({'sample_id': idx, 'reason': f'Exception: {str(e)}'})\n",
        "        continue\n",
        "\n",
        "df_llm_only = pd.DataFrame(llm_only_results)\n",
        "\n",
        "print(f\"\\n✅ LLM-only processing complete!\")\n",
        "print(f\"   Successful: {len(llm_only_results)}\")\n",
        "print(f\"   Failed: {len(llm_only_failed)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "1b507fc0f5db47d090fba9a590968379",
            "0a4968878482476b9ac17b10791767f0",
            "e7770ae1cd5e4e31a2b0af27394b2099",
            "90f58378642b4896b2a1ccc997346c65",
            "53e146cca61e408eb4b388bf72a79bdf",
            "ae6e2ad2b64b468692cd53e5a7cfebbb",
            "4d1998fd290d4ee3aa48c693420b9ba6",
            "2a8c4d36172b49d1b020a13293399c40",
            "ebc98733d13b46108a73024ade0de9f7",
            "89613000ddfe406e9a99526e331f5a05",
            "183c4c8e0e134ca7918c91f201e068a2"
          ]
        },
        "outputId": "5b581c8b-e08e-4435-8738-cdb80f457f23",
        "id": "cFAtBX6_0s29"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 PROCESSING LLM-ONLY TEST SET\n",
            "======================================================================\n",
            "✅ LLM-only translation function ready!\n",
            "\n",
            "🔄 Processing 91 samples with LLM-only...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LLM-only translation:   0%|          | 0/91 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b507fc0f5db47d090fba9a590968379"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ LLM Error: HTTPSConnectionPool(host='ollama.com', port=443): Read timed out. (read timeout=240)\n",
            "\n",
            "✅ LLM-only processing complete!\n",
            "   Successful: 90\n",
            "   Failed: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 🏆 Part 26: Calculate Metrics for LLM-Only\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CALCULATING METRICS FOR LLM-ONLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "llm_only_metrics = []\n",
        "\n",
        "print(f\"\\n🔄 Computing metrics for {len(df_llm_only)} LLM-only translations...\\n\")\n",
        "\n",
        "for idx, row in tqdm(df_llm_only.iterrows(), total=len(df_llm_only), desc=\"Computing LLM-only metrics\"):\n",
        "    reference = row['reference_english']\n",
        "    hypothesis = row['predicted_english_llm']\n",
        "\n",
        "    rouge_scores = calculate_rouge(reference, hypothesis)\n",
        "\n",
        "    # LLM-only has NO retrieval metrics (all 0)\n",
        "    metrics = {\n",
        "        'sample_id': row['sample_id'],\n",
        "        # Translation Quality Metrics\n",
        "        'bleu': calculate_bleu(reference, hypothesis),\n",
        "        'rouge1': rouge_scores['rouge1'],\n",
        "        'rouge2': rouge_scores['rouge2'],\n",
        "        'rougeL': rouge_scores['rougeL'],\n",
        "        'meteor': calculate_meteor(reference, hypothesis),\n",
        "        'chrf': calculate_chrf(reference, hypothesis),\n",
        "        'exact_match': calculate_exact_match(reference, hypothesis),\n",
        "        'word_overlap': calculate_word_overlap(reference, hypothesis),\n",
        "        # Retrieval metrics = 0 (no retrieval)\n",
        "        'recall@1': 0.0,\n",
        "        'recall@3': 0.0,\n",
        "        'recall@5': 0.0,\n",
        "        'recall@10': 0.0,\n",
        "        'recall@20': 0.0,\n",
        "        'mrr': 0.0,\n",
        "        'avg_retrieval_score': 0.0\n",
        "    }\n",
        "\n",
        "    llm_only_metrics.append(metrics)\n",
        "\n",
        "df_llm_only_metrics = pd.DataFrame(llm_only_metrics)\n",
        "\n",
        "print(\"✅ LLM-only metrics calculation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "f8d408464a20476faa89d553823f91e9",
            "dc64164e82084a72ba1a35678b0bd503",
            "7373147373144a4ab4e7f7743cdcdc83",
            "c730295bfd1b4affa3c4fa216752d0d1",
            "820cf64ae61e4005b4bf90c49ffe711a",
            "9c32168f42844d1d9215e5c6243a8887",
            "216e493d1d884d57a4a2d0239092ebf8",
            "61a9f423f9db4759b4e4928f658942c3",
            "0945a5439a6f44508c874d1dc34f8785",
            "1cae6de18ade4f7abccc24ea5ab1407b",
            "40bf43cd3693497aab182df95f63769a"
          ]
        },
        "id": "Czp1BFNL0s2-",
        "outputId": "8afbd31e-6a7e-48f9-c31a-405cf08ff685"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CALCULATING METRICS FOR LLM-ONLY\n",
            "======================================================================\n",
            "\n",
            "🔄 Computing metrics for 90 LLM-only translations...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing LLM-only metrics:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8d408464a20476faa89d553823f91e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM-only metrics calculation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  Part 27: COMPREHENSIVE COMPARISON\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🆚 COMPREHENSIVE RAG vs LLM-ONLY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate averages for LLM-only\n",
        "llm_only_averages = {\n",
        "    'BLEU': df_llm_only_metrics['bleu'].mean(),\n",
        "    'ROUGE-1': df_llm_only_metrics['rouge1'].mean(),\n",
        "    'ROUGE-2': df_llm_only_metrics['rouge2'].mean(),\n",
        "    'ROUGE-L': df_llm_only_metrics['rougeL'].mean(),\n",
        "    'METEOR': df_llm_only_metrics['meteor'].mean(),\n",
        "    'chrF': df_llm_only_metrics['chrf'].mean(),\n",
        "    'Exact Match': df_llm_only_metrics['exact_match'].mean(),\n",
        "    'Word Overlap': df_llm_only_metrics['word_overlap'].mean(),\n",
        "    'Recall@1': 0.0,\n",
        "    'Recall@3': 0.0,\n",
        "    'Recall@5': 0.0,\n",
        "    'Recall@10': 0.0,\n",
        "    'Recall@20': 0.0,\n",
        "    'MRR': 0.0,\n",
        "    'Avg Retrieval Score': 0.0\n",
        "}\n",
        "\n",
        "print(\"\\n📊 COMPLETE METRICS COMPARISON:\")\n",
        "print(\"─\" * 100)\n",
        "print(f\"{'Metric':<25} {'RAG System':<15} {'LLM-Only':<15} {'Difference':<15} {'Winner':<15}\")\n",
        "print(\"─\" * 100)\n",
        "\n",
        "for metric in avg_metrics.keys():\n",
        "    rag_score = avg_metrics[metric]\n",
        "    llm_score = llm_only_averages[metric]\n",
        "    diff = rag_score - llm_score\n",
        "\n",
        "    if 'Recall' in metric or metric == 'MRR' or metric == 'Avg Retrieval Score':\n",
        "        winner = \"🏆 RAG (only)\" if diff > 0 else \"N/A\"\n",
        "    else:\n",
        "        winner = \"🏆 RAG\" if diff > 0 else \"🏆 LLM\" if diff < 0 else \"🤝 Tie\"\n",
        "\n",
        "    print(f\"{metric:<25} {rag_score:>6.2f}%        {llm_score:>6.2f}%        {diff:>+6.2f}%       {winner:<15}\")\n",
        "\n",
        "print(\"─\" * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d-Syg5r0s2-",
        "outputId": "7bf4b2dc-384b-4682-dead-6e4fa408fea6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🆚 COMPREHENSIVE RAG vs LLM-ONLY COMPARISON\n",
            "======================================================================\n",
            "\n",
            "📊 COMPLETE METRICS COMPARISON:\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "Metric                    RAG System      LLM-Only        Difference      Winner         \n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "BLEU                       23.70%          3.22%        +20.48%       🏆 RAG          \n",
            "ROUGE-1                    53.93%         22.08%        +31.85%       🏆 RAG          \n",
            "ROUGE-2                    36.53%          5.51%        +31.02%       🏆 RAG          \n",
            "ROUGE-L                    52.31%         19.77%        +32.54%       🏆 RAG          \n",
            "METEOR                     39.32%         12.83%        +26.49%       🏆 RAG          \n",
            "chrF                       45.35%         17.34%        +28.01%       🏆 RAG          \n",
            "Exact Match                 9.89%          0.00%         +9.89%       🏆 RAG          \n",
            "Word Overlap               43.36%         18.43%        +24.93%       🏆 RAG          \n",
            "Recall@1                    2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "Recall@3                    2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "Recall@5                    2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "Recall@10                   2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "Recall@20                   2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "MRR                         2.20%          0.00%         +2.20%       🏆 RAG (only)   \n",
            "Avg Retrieval Score         2.90%          0.00%         +2.90%       🏆 RAG (only)   \n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📦 Part 29: Detailed Comparison Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 DETAILED COMPARISON ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Statistical comparison\n",
        "comparison_stats = []\n",
        "\n",
        "for metric_col in ['bleu', 'rouge1', 'meteor', 'chrf', 'recall@10', 'mrr']:\n",
        "    rag_scores = df_metrics[metric_col].values\n",
        "    llm_scores = df_llm_only_metrics[metric_col].values\n",
        "\n",
        "    stats = {\n",
        "        'Metric': metric_col.upper(),\n",
        "        'RAG_Mean': rag_scores.mean(),\n",
        "        'RAG_Median': np.median(rag_scores),\n",
        "        'RAG_Std': rag_scores.std(),\n",
        "        'LLM_Mean': llm_scores.mean(),\n",
        "        'LLM_Median': np.median(llm_scores),\n",
        "        'LLM_Std': llm_scores.std(),\n",
        "        'Mean_Diff': rag_scores.mean() - llm_scores.mean()\n",
        "    }\n",
        "\n",
        "    comparison_stats.append(stats)\n",
        "\n",
        "df_comparison_stats = pd.DataFrame(comparison_stats)\n",
        "\n",
        "print(\"\\n📊 Statistical Summary:\")\n",
        "print(\"─\" * 100)\n",
        "print(df_comparison_stats.to_string(index=False))\n",
        "print(\"─\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcAozYj70s2-",
        "outputId": "c5509ac6-cf12-4515-f7e4-88e81a1c185c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📈 DETAILED COMPARISON ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "📊 Statistical Summary:\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "   Metric  RAG_Mean  RAG_Median   RAG_Std  LLM_Mean  LLM_Median   LLM_Std  Mean_Diff\n",
            "     BLEU 23.698688    8.307018 29.041981  3.222177    2.148926  4.932439  20.476511\n",
            "   ROUGE1 53.933052   50.000000 29.284701 22.079377   22.222222 15.651336  31.853675\n",
            "   METEOR 39.316549   31.036655 32.146175 12.829438   10.362973 12.694291  26.487111\n",
            "     CHRF 45.349080   39.154244 29.904912 17.338532   15.498662 10.615826  28.010548\n",
            "RECALL@10  2.197802    0.000000 14.661169  0.000000    0.000000  0.000000   2.197802\n",
            "      MRR  2.197802    0.000000 14.661169  0.000000    0.000000  0.000000   2.197802\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 Part 30: Win/Loss Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🏆 SAMPLE-BY-SAMPLE WIN/LOSS ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "for metric in ['bleu', 'meteor', 'chrf']:\n",
        "    metric_wins = {'RAG': 0, 'LLM': 0, 'Tie': 0}\n",
        "\n",
        "    for i in range(min(len(df_metrics), len(df_llm_only_metrics))):\n",
        "        rag_score = df_metrics.iloc[i][metric]\n",
        "        llm_score = df_llm_only_metrics.iloc[i][metric]\n",
        "\n",
        "        if rag_score > llm_score:\n",
        "            metric_wins['RAG'] += 1\n",
        "            wins['RAG'] += 1\n",
        "        elif llm_score > rag_score:\n",
        "            metric_wins['LLM'] += 1\n",
        "            wins['LLM'] += 1\n",
        "        else:\n",
        "            metric_wins['Tie'] += 1\n",
        "            wins['Tie'] += 1\n",
        "\n",
        "    total = sum(metric_wins.values())\n",
        "    print(f\"\\n{metric.upper()} Wins:\")\n",
        "    print(f\"  RAG:      {metric_wins['RAG']:3d} ({metric_wins['RAG']/total*100:5.1f}%)\")\n",
        "    print(f\"  LLM-Only: {metric_wins['LLM']:3d} ({metric_wins['LLM']/total*100:5.1f}%)\")\n",
        "    print(f\"  Tie:      {metric_wins['Tie']:3d} ({metric_wins['Tie']/total*100:5.1f}%)\")\n",
        "\n",
        "total_comparisons = sum(wins.values())\n",
        "print(f\"\\n{'─' * 70}\")\n",
        "print(f\"Overall Wins (across all metrics):\")\n",
        "print(f\"  🏆 RAG:      {wins['RAG']:3d} ({wins['RAG']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🏆 LLM-Only: {wins['LLM']:3d} ({wins['LLM']/total_comparisons*100:5.1f}%)\")\n",
        "print(f\"  🤝 Tie:      {wins['Tie']:3d} ({wins['Tie']/total_comparisons*100:5.1f}%)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "## 💾 Part 32: Save All Results\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"💾 SAVING ALL RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save RAG comprehensive results\n",
        "df_test_results_full = df_test_results.copy()\n",
        "for metric in df_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_test_results_full[metric] = df_metrics[metric].values\n",
        "\n",
        "df_test_results_full.to_csv('rag_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ RAG comprehensive results saved to: rag_comprehensive_results.csv\")\n",
        "\n",
        "# Save LLM-only comprehensive results\n",
        "df_llm_only_full = df_llm_only.copy()\n",
        "for metric in df_llm_only_metrics.columns:\n",
        "    if metric != 'sample_id':\n",
        "        df_llm_only_full[metric] = df_llm_only_metrics[metric].values\n",
        "\n",
        "df_llm_only_full.to_csv('llm_only_comprehensive_results.csv', index=False)\n",
        "print(f\"✅ LLM-only comprehensive results saved to: llm_only_comprehensive_results.csv\")\n",
        "\n",
        "# Save comparison summary\n",
        "comparison_summary = pd.DataFrame([\n",
        "    {'System': 'RAG', **{f'{k}': v for k, v in avg_metrics.items()}},\n",
        "    {'System': 'LLM-Only', **{f'{k}': v for k, v in llm_only_averages.items()}},\n",
        "    {'System': 'Difference (RAG - LLM)', **{f'{k}': avg_metrics[k] - llm_only_averages[k] for k in avg_metrics.keys()}}\n",
        "])\n",
        "\n",
        "comparison_summary.to_csv('complete_comparison_summary.csv', index=False)\n",
        "print(f\"✅ Comparison summary saved to: complete_comparison_summary.csv\")\n",
        "\n",
        "# Save statistical comparison\n",
        "df_comparison_stats.to_csv('comparison_statistics.csv', index=False)\n",
        "print(f\"✅ Statistics saved to: comparison_statistics.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "## ✅ Part 33: FINAL COMPREHENSIVE REPORT\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FINAL COMPREHENSIVE EVALUATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Determine overall winner\n",
        "rag_total = sum(avg_metrics.values())\n",
        "llm_total = sum(llm_only_averages.values())\n",
        "overall_winner = \"RAG System 🏆\" if rag_total > llm_total else \"LLM-Only 🏆\" if llm_total > rag_total else \"Tie 🤝\"\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 System Performance Summary:\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "RAG SYSTEM (Hybrid Search + LLM):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {avg_metrics['BLEU']:.2f}%\n",
        "  • METEOR:       {avg_metrics['METEOR']:.2f}%\n",
        "  • chrF:         {avg_metrics['chrF']:.2f}%\n",
        "  • ROUGE-1:      {avg_metrics['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {avg_metrics['Exact Match']:.2f}%\n",
        "\n",
        "Retrieval Quality:\n",
        "  • Recall@1:     {avg_metrics['Recall@1']:.2f}%\n",
        "  • Recall@10:    {avg_metrics['Recall@10']:.2f}%\n",
        "  • MRR:          {avg_metrics['MRR']:.2f}%\n",
        "  • Avg Score:    {avg_metrics['Avg Retrieval Score']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "LLM-ONLY (No RAG):\n",
        "════════════════════════════════════════════════════════════════\n",
        "Total samples: {len(df_llm_only_metrics)}\n",
        "\n",
        "Translation Quality:\n",
        "  • BLEU:         {llm_only_averages['BLEU']:.2f}%\n",
        "  • METEOR:       {llm_only_averages['METEOR']:.2f}%\n",
        "  • chrF:         {llm_only_averages['chrF']:.2f}%\n",
        "  • ROUGE-1:      {llm_only_averages['ROUGE-1']:.2f}%\n",
        "  • Exact Match:  {llm_only_averages['Exact Match']:.2f}%\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "COMPARISON RESULTS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "🏆 Overall Winner: {overall_winner}\n",
        "\n",
        "Translation Improvement (RAG - LLM):\n",
        "  • BLEU:    {avg_metrics['BLEU'] - llm_only_averages['BLEU']:+.2f}%\n",
        "  • METEOR:  {avg_metrics['METEOR'] - llm_only_averages['METEOR']:+.2f}%\n",
        "  • chrF:    {avg_metrics['chrF'] - llm_only_averages['chrF']:+.2f}%\n",
        "\n",
        "Sample-wise Wins:\n",
        "  • RAG wins:      {wins['RAG']} ({wins['RAG']/total_comparisons*100:.1f}%)\n",
        "  • LLM-only wins: {wins['LLM']} ({wins['LLM']/total_comparisons*100:.1f}%)\n",
        "\n",
        "Retrieval Effectiveness:\n",
        "  • Recall@10:     {avg_metrics['Recall@10']:.1f}% (RAG finds relevant in top 10)\n",
        "  • MRR:           {avg_metrics['MRR']:.1f}% (Average rank quality)\n",
        "\n",
        "════════════════════════════════════════════════════════════════\n",
        "CONCLUSIONS:\n",
        "════════════════════════════════════════════════════════════════\n",
        "{\"✅ The RAG system significantly outperforms LLM-only approach.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] + 5 else\n",
        " \"🟡 The RAG system shows moderate improvement over LLM-only.\" if avg_metrics['BLEU'] > llm_only_averages['BLEU'] else\n",
        " \"❌ The LLM-only approach performs comparably or better than RAG.\"}\n",
        "\n",
        "{\"✅ Retrieval quality is good (Recall@10 > 40%).\" if avg_metrics['Recall@10'] > 40 else\n",
        " \"🟡 Retrieval quality is moderate (Recall@10 20-40%).\" if avg_metrics['Recall@10'] > 20 else\n",
        " \"❌ Retrieval quality needs improvement (Recall@10 < 20%).\"}\n",
        "\n",
        "📁 Output Files:\n",
        "1. rag_comprehensive_results.csv - RAG results with all metrics\n",
        "2. llm_only_comprehensive_results.csv - LLM-only results with all metrics\n",
        "3. complete_comparison_summary.csv - Full comparison table\n",
        "4. comparison_statistics.csv - Detailed statistical analysis\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\\n🎉 Complete evaluation finished!\")\n",
        "print(\"=\"*70 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12m67k8O0s2_",
        "outputId": "0c8d592c-abaa-4d55-ab2e-3e244756ae2e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🏆 SAMPLE-BY-SAMPLE WIN/LOSS ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "BLEU Wins:\n",
            "  RAG:       69 ( 76.7%)\n",
            "  LLM-Only:  11 ( 12.2%)\n",
            "  Tie:       10 ( 11.1%)\n",
            "\n",
            "METEOR Wins:\n",
            "  RAG:       73 ( 81.1%)\n",
            "  LLM-Only:   7 (  7.8%)\n",
            "  Tie:       10 ( 11.1%)\n",
            "\n",
            "CHRF Wins:\n",
            "  RAG:       78 ( 86.7%)\n",
            "  LLM-Only:  12 ( 13.3%)\n",
            "  Tie:        0 (  0.0%)\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "Overall Wins (across all metrics):\n",
            "  🏆 RAG:      220 ( 81.5%)\n",
            "  🏆 LLM-Only:  30 ( 11.1%)\n",
            "  🤝 Tie:       20 (  7.4%)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "💾 SAVING ALL RESULTS\n",
            "======================================================================\n",
            "✅ RAG comprehensive results saved to: rag_comprehensive_results.csv\n",
            "✅ LLM-only comprehensive results saved to: llm_only_comprehensive_results.csv\n",
            "✅ Comparison summary saved to: complete_comparison_summary.csv\n",
            "✅ Statistics saved to: comparison_statistics.csv\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "✅ FINAL COMPREHENSIVE EVALUATION REPORT\n",
            "======================================================================\n",
            "\n",
            "📊 System Performance Summary:\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "RAG SYSTEM (Hybrid Search + LLM):\n",
            "════════════════════════════════════════════════════════════════\n",
            "Total samples: 91\n",
            "\n",
            "Translation Quality:\n",
            "  • BLEU:         23.70%\n",
            "  • METEOR:       39.32%\n",
            "  • chrF:         45.35%\n",
            "  • ROUGE-1:      53.93%\n",
            "  • Exact Match:  9.89%\n",
            "\n",
            "Retrieval Quality:\n",
            "  • Recall@1:     2.20%\n",
            "  • Recall@10:    2.20%\n",
            "  • MRR:          2.20%\n",
            "  • Avg Score:    2.90%\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "LLM-ONLY (No RAG):\n",
            "════════════════════════════════════════════════════════════════\n",
            "Total samples: 90\n",
            "\n",
            "Translation Quality:\n",
            "  • BLEU:         3.22%\n",
            "  • METEOR:       12.83%\n",
            "  • chrF:         17.34%\n",
            "  • ROUGE-1:      22.08%\n",
            "  • Exact Match:  0.00%\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "COMPARISON RESULTS:\n",
            "════════════════════════════════════════════════════════════════\n",
            "🏆 Overall Winner: RAG System 🏆\n",
            "\n",
            "Translation Improvement (RAG - LLM):\n",
            "  • BLEU:    +20.48%\n",
            "  • METEOR:  +26.49%\n",
            "  • chrF:    +28.01%\n",
            "\n",
            "Sample-wise Wins:\n",
            "  • RAG wins:      220 (81.5%)\n",
            "  • LLM-only wins: 30 (11.1%)\n",
            "\n",
            "Retrieval Effectiveness:\n",
            "  • Recall@10:     2.2% (RAG finds relevant in top 10)\n",
            "  • MRR:           2.2% (Average rank quality)\n",
            "\n",
            "════════════════════════════════════════════════════════════════\n",
            "CONCLUSIONS:\n",
            "════════════════════════════════════════════════════════════════\n",
            "✅ The RAG system significantly outperforms LLM-only approach.\n",
            "\n",
            "❌ Retrieval quality needs improvement (Recall@10 < 20%).\n",
            "\n",
            "📁 Output Files:\n",
            "1. rag_comprehensive_results.csv - RAG results with all metrics\n",
            "2. llm_only_comprehensive_results.csv - LLM-only results with all metrics\n",
            "3. complete_comparison_summary.csv - Full comparison table\n",
            "4. comparison_statistics.csv - Detailed statistical analysis\n",
            "\n",
            "======================================================================\n",
            "\n",
            "🎉 Complete evaluation finished!\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDY6JWbtDRjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🔬 K-VALUE OPTIMIZATION ANALYSIS\n",
        "# Find the optimal TOP_K_RESULTS value by testing a single sentence\n",
        "# ═══════════════════════════════════════════════════════════════════"
      ],
      "metadata": {
        "id": "7T1EmIPFIXU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# 🔬 K-VALUE OPTIMIZATION ANALYSIS\n",
        "# Find the optimal TOP_K_RESULTS value by testing a single sentence\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "\n",
        "## 🎯 Part XX: K-Value Optimization for Single Sample\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔬 K-VALUE OPTIMIZATION ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select a test sample\n",
        "print(\"\\n📝 Selecting test sample...\")\n",
        "test_sample_idx = 0  # You can change this to test different samples\n",
        "test_query_original = df_test.iloc[test_sample_idx]['transliteration']\n",
        "test_reference_german = df_test.iloc[test_sample_idx]['translation']\n",
        "\n",
        "print(f\"✅ Test sample selected:\")\n",
        "print(f\"   Egyptian: {test_query_original}\")\n",
        "print(f\"   Reference (DE): {test_reference_german}\")\n",
        "\n",
        "# Translate reference to English (do this once)\n",
        "print(f\"\\n📖 Translating reference to English...\")\n",
        "test_reference_english = translate_german_to_english(test_reference_german)\n",
        "print(f\"   Reference (EN): {test_reference_english}\")\n",
        "\n",
        "# Normalize query\n",
        "test_query_normalized = normalize_transliteration(test_query_original)\n",
        "print(f\"   Normalized: {test_query_normalized}\")\n",
        "\n",
        "# Generate embedding (do this once)\n",
        "print(f\"\\n🔢 Generating embedding...\")\n",
        "test_query_embedding = embedding_model.encode(\n",
        "    test_query_normalized,\n",
        "    normalize_embeddings=True\n",
        ").tolist()\n",
        "print(f\"   ✅ Embedding generated (dim={len(test_query_embedding)})\")\n",
        "\n",
        "# Define K values to test\n",
        "k_values = list(range(5, 205, 5))  # K = 5, 10, 15, 20, ..., 200\n",
        "print(f\"\\n📊 Testing K values: {k_values[0]} to {k_values[-1]} (step=5)\")\n",
        "print(f\"   Total tests: {len(k_values)}\")\n",
        "print(f\"   Estimated time: ~{len(k_values) * 2 / 60:.1f} minutes\\n\")\n",
        "\n",
        "# Storage for results\n",
        "k_optimization_results = []\n",
        "\n",
        "# Test each K value\n",
        "for k in tqdm(k_values, desc=\"Testing K values\"):\n",
        "    try:\n",
        "        # Step 1: Retrieve top-K examples\n",
        "        search_results = hybrid_search(\n",
        "            query_text=test_query_normalized,\n",
        "            query_embedding=test_query_embedding,\n",
        "            top_k=k\n",
        "        )\n",
        "\n",
        "        # Step 2: Translate with LLM using these K examples\n",
        "        german_translation, llm_output = translate_with_llm(\n",
        "            query_original=test_query_original,\n",
        "            query_normalized=test_query_normalized,\n",
        "            retrieved_examples=search_results\n",
        "        )\n",
        "\n",
        "        if not german_translation:\n",
        "            print(f\"⚠️ Translation failed for K={k}\")\n",
        "            continue\n",
        "\n",
        "        # Step 3: Translate German to English\n",
        "        english_translation = translate_german_to_english(german_translation)\n",
        "\n",
        "        if not english_translation:\n",
        "            print(f\"⚠️ English translation failed for K={k}\")\n",
        "            continue\n",
        "\n",
        "        # Step 4: Calculate all metrics\n",
        "        rouge_scores = calculate_rouge(test_reference_english, english_translation)\n",
        "        recall_scores = calculate_recall_at_k(\n",
        "            test_reference_german,\n",
        "            search_results,\n",
        "            k_values=[1, 3, 5, 10, 20, 50, 100] if k >= 100 else [1, 3, 5, 10, 20, 50]\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        result = {\n",
        "            'k': k,\n",
        "            # Translation Quality Metrics\n",
        "            'bleu': calculate_bleu(test_reference_english, english_translation),\n",
        "            'rouge1': rouge_scores['rouge1'],\n",
        "            'rouge2': rouge_scores['rouge2'],\n",
        "            'rougeL': rouge_scores['rougeL'],\n",
        "            'meteor': calculate_meteor(test_reference_english, english_translation),\n",
        "            'chrf': calculate_chrf(test_reference_english, english_translation),\n",
        "            'exact_match': calculate_exact_match(test_reference_english, english_translation),\n",
        "            'word_overlap': calculate_word_overlap(test_reference_english, english_translation),\n",
        "            # Retrieval Quality Metrics\n",
        "            'recall@1': recall_scores.get('recall@1', 0.0),\n",
        "            'recall@3': recall_scores.get('recall@3', 0.0),\n",
        "            'recall@5': recall_scores.get('recall@5', 0.0),\n",
        "            'recall@10': recall_scores.get('recall@10', 0.0),\n",
        "            'recall@20': recall_scores.get('recall@20', 0.0),\n",
        "            'recall@50': recall_scores.get('recall@50', 0.0),\n",
        "            'recall@100': recall_scores.get('recall@100', 0.0) if k >= 100 else 0.0,\n",
        "            'mrr': calculate_mrr(test_reference_german, search_results),\n",
        "            'avg_retrieval_score': calculate_average_retrieval_score(search_results, top_k=min(k, 10)),\n",
        "            # Translations\n",
        "            'predicted_german': german_translation,\n",
        "            'predicted_english': english_translation\n",
        "        }\n",
        "\n",
        "        k_optimization_results.append(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error at K={k}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Create results DataFrame\n",
        "df_k_optimization = pd.DataFrame(k_optimization_results)\n",
        "\n",
        "print(f\"\\n✅ K-value testing complete!\")\n",
        "print(f\"   Successful tests: {len(df_k_optimization)}/{len(k_values)}\")\n",
        "\n",
        "## 📊 Part XX+1: Analysis and Visualization\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 K-VALUE OPTIMIZATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find best K for each metric\n",
        "best_k_results = {}\n",
        "metrics_to_analyze = ['bleu', 'rouge1', 'meteor', 'chrf', 'recall@10', 'mrr']\n",
        "\n",
        "print(\"\\n🏆 BEST K VALUE FOR EACH METRIC:\")\n",
        "print(\"─\" * 70)\n",
        "\n",
        "for metric in metrics_to_analyze:\n",
        "    best_idx = df_k_optimization[metric].idxmax()\n",
        "    best_k = df_k_optimization.iloc[best_idx]['k']\n",
        "    best_score = df_k_optimization.iloc[best_idx][metric]\n",
        "\n",
        "    best_k_results[metric] = {\n",
        "        'k': best_k,\n",
        "        'score': best_score\n",
        "    }\n",
        "\n",
        "    print(f\"   {metric.upper():15s}: K={best_k:3.0f} → Score={best_score:6.2f}%\")\n",
        "\n",
        "# Overall best K (average across all metrics)\n",
        "print(\"\\n🎯 OVERALL BEST K (Average Performance):\")\n",
        "print(\"─\" * 70)\n",
        "\n",
        "# Normalize metrics to 0-100 scale and average\n",
        "df_k_optimization['avg_score'] = df_k_optimization[metrics_to_analyze].mean(axis=1)\n",
        "best_overall_idx = df_k_optimization['avg_score'].idxmax()\n",
        "best_overall_k = df_k_optimization.iloc[best_overall_idx]['k']\n",
        "best_overall_score = df_k_optimization.iloc[best_overall_idx]['avg_score']\n",
        "\n",
        "print(f\"   Best K: {best_overall_k}\")\n",
        "print(f\"   Average Score: {best_overall_score:.2f}%\")\n",
        "print(f\"\\n   Individual scores at K={best_overall_k}:\")\n",
        "for metric in metrics_to_analyze:\n",
        "    score = df_k_optimization.iloc[best_overall_idx][metric]\n",
        "    print(f\"      {metric.upper():15s}: {score:6.2f}%\")\n",
        "\n",
        "## 📈 Part XX+2: Detailed Performance Analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📈 PERFORMANCE TRENDS ACROSS K VALUES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate statistics for each metric\n",
        "print(\"\\nMetric Performance Summary:\")\n",
        "print(\"─\" * 90)\n",
        "print(f\"{'Metric':<15} {'Min K':<10} {'Max K':<10} {'Best K':<10} {'Min Score':<12} {'Max Score':<12} {'Variance':<10}\")\n",
        "print(\"─\" * 90)\n",
        "\n",
        "for metric in metrics_to_analyze:\n",
        "    min_score = df_k_optimization[metric].min()\n",
        "    max_score = df_k_optimization[metric].max()\n",
        "    min_k = df_k_optimization.loc[df_k_optimization[metric].idxmin(), 'k']\n",
        "    max_k = df_k_optimization.loc[df_k_optimization[metric].idxmax(), 'k']\n",
        "    variance = df_k_optimization[metric].std()\n",
        "\n",
        "    print(f\"{metric.upper():<15} {min_k:<10.0f} {max_k:<10.0f} {best_k_results[metric]['k']:<10.0f} \"\n",
        "          f\"{min_score:<12.2f} {max_score:<12.2f} {variance:<10.2f}\")\n",
        "\n",
        "print(\"─\" * 90)\n",
        "\n",
        "## 📉 Part XX+3: Visual Trend Charts\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📉 METRIC TRENDS (Visual)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show trends for key metrics\n",
        "for metric in ['bleu', 'meteor', 'chrf']:\n",
        "    print(f\"\\n{metric.upper()} Score by K:\")\n",
        "    print(\"─\" * 70)\n",
        "\n",
        "    # Sample every 10 K values for readability\n",
        "    sample_indices = df_k_optimization[df_k_optimization['k'] % 20 == 0].index\n",
        "\n",
        "    for idx in sample_indices:\n",
        "        k = df_k_optimization.loc[idx, 'k']\n",
        "        score = df_k_optimization.loc[idx, metric]\n",
        "        bar_length = int((score / 100) * 40)\n",
        "        bar = '█' * bar_length\n",
        "\n",
        "        # Mark if this is the best K\n",
        "        marker = \" 🏆 BEST\" if k == best_k_results[metric]['k'] else \"\"\n",
        "\n",
        "        print(f\"  K={k:3.0f}: {bar} {score:5.2f}%{marker}\")\n",
        "\n",
        "## 🔍 Part XX+4: Translation Quality at Different K Values\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔍 TRANSLATION EXAMPLES AT KEY K VALUES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show translations at K = 5, 30, 100, 200 (if available)\n",
        "example_k_values = [5, 30, 100, 200]\n",
        "\n",
        "for k in example_k_values:\n",
        "    if k in df_k_optimization['k'].values:\n",
        "        row = df_k_optimization[df_k_optimization['k'] == k].iloc[0]\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"K = {k}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Egyptian:     {test_query_original}\")\n",
        "        print(f\"Reference:    {test_reference_english}\")\n",
        "        print(f\"Predicted:    {row['predicted_english']}\")\n",
        "        print(f\"\\nScores:\")\n",
        "        print(f\"  BLEU:   {row['bleu']:6.2f}%\")\n",
        "        print(f\"  METEOR: {row['meteor']:6.2f}%\")\n",
        "        print(f\"  chrF:   {row['chrf']:6.2f}%\")\n",
        "        print(f\"  ROUGE-1:{row['rouge1']:6.2f}%\")\n",
        "\n",
        "## 💾 Part XX+5: Save K Optimization Results\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"💾 SAVING K OPTIMIZATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save detailed results\n",
        "df_k_optimization.to_csv('k_optimization_detailed.csv', index=False)\n",
        "print(f\"✅ Detailed results saved to: k_optimization_detailed.csv\")\n",
        "\n",
        "# Save summary\n",
        "summary_data = {\n",
        "    'Metric': metrics_to_analyze,\n",
        "    'Best_K': [best_k_results[m]['k'] for m in metrics_to_analyze],\n",
        "    'Best_Score': [best_k_results[m]['score'] for m in metrics_to_analyze],\n",
        "    'Min_Score': [df_k_optimization[m].min() for m in metrics_to_analyze],\n",
        "    'Max_Score': [df_k_optimization[m].max() for m in metrics_to_analyze],\n",
        "    'Avg_Score': [df_k_optimization[m].mean() for m in metrics_to_analyze],\n",
        "    'Std_Score': [df_k_optimization[m].std() for m in metrics_to_analyze]\n",
        "}\n",
        "\n",
        "df_k_summary = pd.DataFrame(summary_data)\n",
        "df_k_summary.to_csv('k_optimization_summary.csv', index=False)\n",
        "print(f\"✅ Summary saved to: k_optimization_summary.csv\")\n",
        "\n",
        "## ✅ Part XX+6: Recommendations\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ K-VALUE OPTIMIZATION RECOMMENDATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 Analysis Summary:\n",
        "   • Test Sample: {test_query_original}\n",
        "   • K Values Tested: {k_values[0]} to {k_values[-1]} (step=5)\n",
        "   • Successful Tests: {len(df_k_optimization)}/{len(k_values)}\n",
        "\n",
        "🏆 Optimal K Values by Metric:\n",
        "   • BLEU:       K = {best_k_results['bleu']['k']} (Score: {best_k_results['bleu']['score']:.2f}%)\n",
        "   • METEOR:     K = {best_k_results['meteor']['k']} (Score: {best_k_results['meteor']['score']:.2f}%)\n",
        "   • chrF:       K = {best_k_results['chrf']['k']} (Score: {best_k_results['chrf']['score']:.2f}%)\n",
        "   • ROUGE-1:    K = {best_k_results['rouge1']['k']} (Score: {best_k_results['rouge1']['score']:.2f}%)\n",
        "   • Recall@10:  K = {best_k_results['recall@10']['k']} (Score: {best_k_results['recall@10']['score']:.2f}%)\n",
        "   • MRR:        K = {best_k_results['mrr']['k']} (Score: {best_k_results['mrr']['score']:.2f}%)\n",
        "\n",
        "🎯 OVERALL RECOMMENDATION:\n",
        "   • Best Overall K: {best_overall_k}\n",
        "   • Average Performance: {best_overall_score:.2f}%\n",
        "\n",
        "💡 Interpretation:\n",
        "\"\"\")\n",
        "\n",
        "# Analyze trends\n",
        "k_range = df_k_optimization['k'].max() - df_k_optimization['k'].min()\n",
        "bleu_variance = df_k_optimization['bleu'].std()\n",
        "\n",
        "if bleu_variance < 5:\n",
        "    print(\"   ✅ Performance is STABLE across different K values\")\n",
        "    print(f\"   → You can use any K between {k_values[0]} and {k_values[-1]}\")\n",
        "    print(f\"   → Recommended: K = {best_overall_k} (best overall performance)\")\n",
        "elif bleu_variance < 15:\n",
        "    print(\"   🟡 Performance VARIES moderately with K\")\n",
        "    print(f\"   → Recommended: K = {best_overall_k} for best results\")\n",
        "    print(f\"   → Alternative: K = {best_k_results['bleu']['k']} for highest BLEU\")\n",
        "else:\n",
        "    print(\"   🔴 Performance is HIGHLY SENSITIVE to K\")\n",
        "    print(f\"   → CRITICAL: Use K = {best_overall_k}\")\n",
        "    print(f\"   → Avoid K < {k_values[int(len(k_values)*0.2)]} (low performance)\")\n",
        "\n",
        "# Performance trend analysis\n",
        "if df_k_optimization['bleu'].iloc[-1] > df_k_optimization['bleu'].iloc[0]:\n",
        "    print(\"\\n   📈 Trend: Performance IMPROVES with larger K\")\n",
        "    print(f\"   → Consider testing K > {k_values[-1]} for potential gains\")\n",
        "elif df_k_optimization['bleu'].iloc[-1] < df_k_optimization['bleu'].iloc[0]:\n",
        "    print(\"\\n   📉 Trend: Performance DECREASES with larger K\")\n",
        "    print(f\"   → Use smaller K values (K < {best_overall_k})\")\n",
        "else:\n",
        "    print(\"\\n   ➡️ Trend: Performance is FLAT across K range\")\n",
        "    print(f\"   → Use K = {k_values[int(len(k_values)*0.3)]} for efficiency\")\n",
        "\n",
        "print(f\"\"\"\n",
        "📁 Output Files:\n",
        "   1. k_optimization_detailed.csv - All K values with all metrics\n",
        "   2. k_optimization_summary.csv - Summary statistics per metric\n",
        "\n",
        "🚀 Next Steps:\n",
        "   1. Update TOP_K_RESULTS = {best_overall_k} in your main code\n",
        "   2. Re-run evaluation with optimized K value\n",
        "   3. Compare performance improvement\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\\n🎉 K-value optimization analysis complete!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "## 📊 Part XX+7: Quick Performance Comparison\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 PERFORMANCE COMPARISON: Current vs Optimal K\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get current K performance\n",
        "current_k = TOP_K_RESULTS\n",
        "if current_k in df_k_optimization['k'].values:\n",
        "    current_row = df_k_optimization[df_k_optimization['k'] == current_k].iloc[0]\n",
        "    optimal_row = df_k_optimization.iloc[best_overall_idx]\n",
        "\n",
        "    print(f\"\\nCurrent Configuration (K={current_k}):\")\n",
        "    print(\"─\" * 70)\n",
        "    for metric in metrics_to_analyze:\n",
        "        current_score = current_row[metric]\n",
        "        print(f\"   {metric.upper():15s}: {current_score:6.2f}%\")\n",
        "\n",
        "    print(f\"\\nOptimal Configuration (K={best_overall_k}):\")\n",
        "    print(\"─\" * 70)\n",
        "    for metric in metrics_to_analyze:\n",
        "        optimal_score = optimal_row[metric]\n",
        "        diff = optimal_score - current_row[metric]\n",
        "        arrow = \"📈\" if diff > 0 else \"📉\" if diff < 0 else \"➡️\"\n",
        "        print(f\"   {metric.upper():15s}: {optimal_score:6.2f}% {arrow} ({diff:+.2f}%)\")\n",
        "\n",
        "    improvement = optimal_row['avg_score'] - current_row['avg_score']\n",
        "    if improvement > 5:\n",
        "        print(f\"\\n✅ Switching to K={best_overall_k} will improve performance by {improvement:.2f}%\")\n",
        "    elif improvement > 0:\n",
        "        print(f\"\\n🟡 Switching to K={best_overall_k} will slightly improve performance by {improvement:.2f}%\")\n",
        "    else:\n",
        "        print(f\"\\n✅ Current K={current_k} is already optimal!\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ Current K={current_k} not tested in this analysis\")\n",
        "    print(f\"   Recommended K: {best_overall_k}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09ecd3a261f549fc876c00ec8b5a9dfc",
            "d08cf5a0a82842f095313d2b5c842a34",
            "4cabe24b5cac4c608d30fd7740533392",
            "66772bf866a34d01a70a191cb3f73a26",
            "25dfd17faaeb4e7285aad9e4a68548d3",
            "e1caa466edad4dd494d1f3490fc2b482",
            "10d9491b93384fc89e4291ac33d34000",
            "b4b6d7dc0f68489bbfa14b52aeaa9fdc",
            "a11fd13c09914a1689eb808a40ad8354",
            "381c0bd04ac241198bf426da6e9be04e",
            "3d8f1cab77e64955b5a79579163c4abf"
          ]
        },
        "id": "ZzbkdSROITCw",
        "outputId": "7881ebfa-3a6b-47d3-ca09-20abb4a34239"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🔬 K-VALUE OPTIMIZATION ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "📝 Selecting test sample...\n",
            "✅ Test sample selected:\n",
            "   Egyptian: smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "   Reference (DE): Der Einzige Freund, der Vorlesepriester, der Vorsteher der fremdsprachigen Truppe, Harchuf.\n",
            "\n",
            "📖 Translating reference to English...\n",
            "   Reference (EN): The only friend, the presiding priest, the leader of the foreign language troupe, Harchuf.\n",
            "   Normalized: smr-wa.ti khr.i-hab.t im.i-rʾ-iaw hr.w-khwi\n",
            "\n",
            "🔢 Generating embedding...\n",
            "   ✅ Embedding generated (dim=1024)\n",
            "\n",
            "📊 Testing K values: 5 to 200 (step=5)\n",
            "   Total tests: 40\n",
            "   Estimated time: ~1.3 minutes\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing K values:   0%|          | 0/40 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09ecd3a261f549fc876c00ec8b5a9dfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ K-value testing complete!\n",
            "   Successful tests: 40/40\n",
            "\n",
            "======================================================================\n",
            "📊 K-VALUE OPTIMIZATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "🏆 BEST K VALUE FOR EACH METRIC:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   BLEU           : K= 85 → Score= 78.25%\n",
            "   ROUGE1         : K= 10 → Score= 96.30%\n",
            "   METEOR         : K= 85 → Score= 92.69%\n",
            "   CHRF           : K= 85 → Score= 91.02%\n",
            "   RECALL@10      : K=  5 → Score=  0.00%\n",
            "   MRR            : K=  5 → Score=  0.00%\n",
            "\n",
            "🎯 OVERALL BEST K (Average Performance):\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   Best K: 85\n",
            "   Average Score: 59.14%\n",
            "\n",
            "   Individual scores at K=85:\n",
            "      BLEU           :  78.25%\n",
            "      ROUGE1         :  92.86%\n",
            "      METEOR         :  92.69%\n",
            "      CHRF           :  91.02%\n",
            "      RECALL@10      :   0.00%\n",
            "      MRR            :   0.00%\n",
            "\n",
            "======================================================================\n",
            "📈 PERFORMANCE TRENDS ACROSS K VALUES\n",
            "======================================================================\n",
            "\n",
            "Metric Performance Summary:\n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "Metric          Min K      Max K      Best K     Min Score    Max Score    Variance  \n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "BLEU            175        85         85         2.84         78.25        19.06     \n",
            "ROUGE1          175        10         10         47.62        96.30        11.68     \n",
            "METEOR          175        85         85         11.28        92.69        14.13     \n",
            "CHRF            5          85         85         35.33        91.02        12.47     \n",
            "RECALL@10       5          5          5          0.00         0.00         0.00      \n",
            "MRR             5          5          5          0.00         0.00         0.00      \n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "======================================================================\n",
            "📉 METRIC TRENDS (Visual)\n",
            "======================================================================\n",
            "\n",
            "BLEU Score by K:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  K= 20: ███████████████████████████ 68.32%\n",
            "  K= 40: ███████████████████████████ 68.32%\n",
            "  K= 60: ███████████████████████████ 68.32%\n",
            "  K= 80: ███████████████████████████ 68.32%\n",
            "  K=100: ██████████████ 36.16%\n",
            "  K=120: ███████████████████████████ 68.32%\n",
            "  K=140: ███████████████████████████ 68.32%\n",
            "  K=160: ███████████████████████████ 68.32%\n",
            "  K=180: ███████████████████████████ 68.32%\n",
            "  K=200: ███████████████████████████ 68.32%\n",
            "\n",
            "METEOR Score by K:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  K= 20: ████████████████████████████ 72.43%\n",
            "  K= 40: ████████████████████████████ 72.43%\n",
            "  K= 60: ████████████████████████████ 72.43%\n",
            "  K= 80: ████████████████████████████ 72.43%\n",
            "  K=100: ███████████████████████████ 69.96%\n",
            "  K=120: ████████████████████████████ 72.43%\n",
            "  K=140: ████████████████████████████ 72.43%\n",
            "  K=160: ████████████████████████████ 72.43%\n",
            "  K=180: ████████████████████████████ 72.43%\n",
            "  K=200: ████████████████████████████ 72.43%\n",
            "\n",
            "CHRF Score by K:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  K= 20: ██████████████████████████████████ 86.34%\n",
            "  K= 40: ██████████████████████████████████ 86.34%\n",
            "  K= 60: ██████████████████████████████████ 86.34%\n",
            "  K= 80: ██████████████████████████████████ 86.34%\n",
            "  K=100: ██████████████████████████████ 77.24%\n",
            "  K=120: ██████████████████████████████████ 86.34%\n",
            "  K=140: ██████████████████████████████████ 86.34%\n",
            "  K=160: ██████████████████████████████████ 86.34%\n",
            "  K=180: ██████████████████████████████████ 86.34%\n",
            "  K=200: ██████████████████████████████████ 86.34%\n",
            "\n",
            "======================================================================\n",
            "🔍 TRANSLATION EXAMPLES AT KEY K VALUES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "K = 5\n",
            "======================================================================\n",
            "Egyptian:     smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "Reference:    The only friend, the presiding priest, the leader of the foreign language troupe, Harchuf.\n",
            "Predicted:    The only friend, the ritualist, Harchuf.\n",
            "\n",
            "Scores:\n",
            "  BLEU:    14.16%\n",
            "  METEOR:  28.18%\n",
            "  chrF:    35.33%\n",
            "  ROUGE-1: 50.00%\n",
            "\n",
            "======================================================================\n",
            "K = 30\n",
            "======================================================================\n",
            "Egyptian:     smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "Reference:    The only friend, the presiding priest, the leader of the foreign language troupe, Harchuf.\n",
            "Predicted:    The only friend, the presiding priest, the leader of the foreign-language troupe.\n",
            "\n",
            "Scores:\n",
            "  BLEU:    68.32%\n",
            "  METEOR:  72.43%\n",
            "  chrF:    86.34%\n",
            "  ROUGE-1: 96.30%\n",
            "\n",
            "======================================================================\n",
            "K = 100\n",
            "======================================================================\n",
            "Egyptian:     smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "Reference:    The only friend, the presiding priest, the leader of the foreign language troupe, Harchuf.\n",
            "Predicted:    The only friend (the king), the presiding priest, the ruler of the foreign language troupe.\n",
            "\n",
            "Scores:\n",
            "  BLEU:    36.16%\n",
            "  METEOR:  69.96%\n",
            "  chrF:    77.24%\n",
            "  ROUGE-1: 82.76%\n",
            "\n",
            "======================================================================\n",
            "K = 200\n",
            "======================================================================\n",
            "Egyptian:     smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "Reference:    The only friend, the presiding priest, the leader of the foreign language troupe, Harchuf.\n",
            "Predicted:    The only friend, the presiding priest, the leader of the foreign-language troupe.\n",
            "\n",
            "Scores:\n",
            "  BLEU:    68.32%\n",
            "  METEOR:  72.43%\n",
            "  chrF:    86.34%\n",
            "  ROUGE-1: 96.30%\n",
            "\n",
            "======================================================================\n",
            "💾 SAVING K OPTIMIZATION RESULTS\n",
            "======================================================================\n",
            "✅ Detailed results saved to: k_optimization_detailed.csv\n",
            "✅ Summary saved to: k_optimization_summary.csv\n",
            "\n",
            "======================================================================\n",
            "✅ K-VALUE OPTIMIZATION RECOMMENDATIONS\n",
            "======================================================================\n",
            "\n",
            "📊 Analysis Summary:\n",
            "   • Test Sample: smr-wꜥ.tꞽ ẖr(.ꞽ)-ḥ(ꜣ)b(.t) (ꞽ)m(.ꞽ)-r(ʾ)-(ꞽ)ꜥw ḥr(.w)-ḫwi̯=f\n",
            "   • K Values Tested: 5 to 200 (step=5)\n",
            "   • Successful Tests: 40/40\n",
            "\n",
            "🏆 Optimal K Values by Metric:\n",
            "   • BLEU:       K = 85 (Score: 78.25%)\n",
            "   • METEOR:     K = 85 (Score: 92.69%)\n",
            "   • chrF:       K = 85 (Score: 91.02%)\n",
            "   • ROUGE-1:    K = 10 (Score: 96.30%)\n",
            "   • Recall@10:  K = 5 (Score: 0.00%)\n",
            "   • MRR:        K = 5 (Score: 0.00%)\n",
            "\n",
            "🎯 OVERALL RECOMMENDATION:\n",
            "   • Best Overall K: 85\n",
            "   • Average Performance: 59.14%\n",
            "\n",
            "💡 Interpretation:\n",
            "\n",
            "   🔴 Performance is HIGHLY SENSITIVE to K\n",
            "   → CRITICAL: Use K = 85\n",
            "   → Avoid K < 45 (low performance)\n",
            "\n",
            "   📈 Trend: Performance IMPROVES with larger K\n",
            "   → Consider testing K > 200 for potential gains\n",
            "\n",
            "📁 Output Files:\n",
            "   1. k_optimization_detailed.csv - All K values with all metrics\n",
            "   2. k_optimization_summary.csv - Summary statistics per metric\n",
            "\n",
            "🚀 Next Steps:\n",
            "   1. Update TOP_K_RESULTS = 85 in your main code\n",
            "   2. Re-run evaluation with optimized K value\n",
            "   3. Compare performance improvement\n",
            "\n",
            "======================================================================\n",
            "\n",
            "🎉 K-value optimization analysis complete!\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "📊 PERFORMANCE COMPARISON: Current vs Optimal K\n",
            "======================================================================\n",
            "\n",
            "Current Configuration (K=30):\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   BLEU           :  68.32%\n",
            "   ROUGE1         :  96.30%\n",
            "   METEOR         :  72.43%\n",
            "   CHRF           :  86.34%\n",
            "   RECALL@10      :   0.00%\n",
            "   MRR            :   0.00%\n",
            "\n",
            "Optimal Configuration (K=85):\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "   BLEU           :  78.25% 📈 (+9.94%)\n",
            "   ROUGE1         :  92.86% 📉 (-3.44%)\n",
            "   METEOR         :  92.69% 📈 (+20.26%)\n",
            "   CHRF           :  91.02% 📈 (+4.67%)\n",
            "   RECALL@10      :   0.00% ➡️ (+0.00%)\n",
            "   MRR            :   0.00% ➡️ (+0.00%)\n",
            "\n",
            "✅ Switching to K=85 will improve performance by 5.24%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJZyZoeiIaqM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}